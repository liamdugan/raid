{
  "_autogen_note": "This file is automatically generated by the RAID leaderboard submission script. Do not edit this file manually or include it in new submissions' PRs.",
  "_submission_hash": "7a6416fd6f2fb6975eecb1afa706242eb796d44f0fe12ac169e6a5360556126c",
  "_results_hash": "99e8d7fec69a58200a323ea57969918570a6ffcb8f881f6e14a75c72ddbd733d",
  "date_released": "2025-05-17",
  "detector_name": "luminar_classifier_RAID_none_PrismAI",
  "contact_info": "k.boenisch@outlook.com",
  "website": "https://www.texttechnologylab.org/",
  "paper_link": "",
  "huggingface_link": "",
  "github_link": "https://github.com/TheItCrOw/PrismAI",
  "additional_metadata": null,
  "score_agg": {
    "all": {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6780346200980393
    },
    "no_adversarial": {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7476455269607843
    }
  },
  "scores": [
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        },
        "0.01": null
      },
      "auroc": 0.9308333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        },
        "0.01": null
      },
      "auroc": 0.8858333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 334,
          "fn": 66,
          "accuracy": 0.835
        },
        "0.01": null
      },
      "auroc": 0.9083333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 172,
          "fn": 28,
          "accuracy": 0.86
        },
        "0.01": null
      },
      "auroc": 0.9208333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 146,
          "fn": 54,
          "accuracy": 0.73
        },
        "0.01": null
      },
      "auroc": 0.8558333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 318,
          "fn": 82,
          "accuracy": 0.795
        },
        "0.01": null
      },
      "auroc": 0.8883333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 348,
          "fn": 52,
          "accuracy": 0.87
        },
        "0.01": null
      },
      "auroc": 0.9258333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 304,
          "fn": 96,
          "accuracy": 0.76
        },
        "0.01": null
      },
      "auroc": 0.8708333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 652,
          "fn": 148,
          "accuracy": 0.815
        },
        "0.01": null
      },
      "auroc": 0.8983333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": null
      },
      "auroc": 0.6633333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 326,
          "accuracy": 0.185
        },
        "0.01": null
      },
      "auroc": 0.5833333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": null
      },
      "auroc": 0.5683333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        },
        "0.01": null
      },
      "auroc": 0.5458333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 300,
          "accuracy": 0.25
        },
        "0.01": null
      },
      "auroc": 0.6158333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 382,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 118,
          "fn": 682,
          "accuracy": 0.1475
        },
        "0.01": null
      },
      "auroc": 0.5645833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        },
        "0.01": null
      },
      "auroc": 0.8108333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 135,
          "accuracy": 0.325
        },
        "0.01": null
      },
      "auroc": 0.6533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 193,
          "fn": 207,
          "accuracy": 0.4825
        },
        "0.01": null
      },
      "auroc": 0.7320833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 141,
          "fn": 59,
          "accuracy": 0.705
        },
        "0.01": null
      },
      "auroc": 0.8433333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": null
      },
      "auroc": 0.5533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 234,
          "accuracy": 0.415
        },
        "0.01": null
      },
      "auroc": 0.6983333333333335
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 269,
          "fn": 131,
          "accuracy": 0.6725
        },
        "0.01": null
      },
      "auroc": 0.8270833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 310,
          "accuracy": 0.225
        },
        "0.01": null
      },
      "auroc": 0.6033333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 359,
          "fn": 441,
          "accuracy": 0.44875
        },
        "0.01": null
      },
      "auroc": 0.7152083333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": null
      },
      "auroc": 0.5608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": null
      },
      "auroc": 0.6558333333333335
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 94,
          "fn": 306,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 52,
          "fn": 148,
          "accuracy": 0.26
        },
        "0.01": null
      },
      "auroc": 0.6208333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        },
        "0.01": null
      },
      "auroc": 0.5720833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 320,
          "accuracy": 0.2
        },
        "0.01": null
      },
      "auroc": 0.5908333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        },
        "0.01": null
      },
      "auroc": 0.5895833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 159,
          "fn": 641,
          "accuracy": 0.19875
        },
        "0.01": null
      },
      "auroc": 0.5902083333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": null
      },
      "auroc": 0.6583333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": null
      },
      "auroc": 0.5183333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 322,
          "accuracy": 0.195
        },
        "0.01": null
      },
      "auroc": 0.5883333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": null
      },
      "auroc": 0.5633333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        },
        "0.01": null
      },
      "auroc": 0.5320833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 96,
          "fn": 304,
          "accuracy": 0.24
        },
        "0.01": null
      },
      "auroc": 0.6108333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 385,
          "accuracy": 0.0375
        },
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 689,
          "accuracy": 0.13875
        },
        "0.01": null
      },
      "auroc": 0.5602083333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": null
      },
      "auroc": 0.7583333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 185,
          "fn": 215,
          "accuracy": 0.4625
        },
        "0.01": null
      },
      "auroc": 0.7220833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": null
      },
      "auroc": 0.7233333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 42,
          "fn": 158,
          "accuracy": 0.21
        },
        "0.01": null
      },
      "auroc": 0.5958333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 135,
          "fn": 265,
          "accuracy": 0.3375
        },
        "0.01": null
      },
      "auroc": 0.6595833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 200,
          "fn": 200,
          "accuracy": 0.5
        },
        "0.01": null
      },
      "auroc": 0.7408333333333335
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 280,
          "accuracy": 0.3
        },
        "0.01": null
      },
      "auroc": 0.6408333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 320,
          "fn": 480,
          "accuracy": 0.4
        },
        "0.01": null
      },
      "auroc": 0.6908333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 116,
          "fn": 84,
          "accuracy": 0.58
        },
        "0.01": null
      },
      "auroc": 0.7808333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 116,
          "fn": 84,
          "accuracy": 0.58
        },
        "0.01": null
      },
      "auroc": 0.7808333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": null
      },
      "auroc": 0.7733333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": null
      },
      "auroc": 0.7733333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 229,
          "fn": 171,
          "accuracy": 0.5725
        },
        "0.01": null
      },
      "auroc": 0.7770833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 229,
          "fn": 171,
          "accuracy": 0.5725
        },
        "0.01": null
      },
      "auroc": 0.7770833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        },
        "0.01": null
      },
      "auroc": 0.6333333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        },
        "0.01": null
      },
      "auroc": 0.6333333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 52,
          "fn": 148,
          "accuracy": 0.26
        },
        "0.01": null
      },
      "auroc": 0.6208333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 52,
          "fn": 148,
          "accuracy": 0.26
        },
        "0.01": null
      },
      "auroc": 0.6208333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 291,
          "accuracy": 0.2725
        },
        "0.01": null
      },
      "auroc": 0.6270833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 291,
          "accuracy": 0.2725
        },
        "0.01": null
      },
      "auroc": 0.6270833333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        },
        "0.01": null
      },
      "auroc": 0.7358333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        },
        "0.01": null
      },
      "auroc": 0.7358333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": null
      },
      "auroc": 0.6908333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": null
      },
      "auroc": 0.6908333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        },
        "0.01": null
      },
      "auroc": 0.7133333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        },
        "0.01": null
      },
      "auroc": 0.7133333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": null
      },
      "auroc": 0.7733333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": null
      },
      "auroc": 0.7733333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": null
      },
      "auroc": 0.5983333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": null
      },
      "auroc": 0.5983333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 244,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 244,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 95,
          "fn": 105,
          "accuracy": 0.475
        },
        "0.01": null
      },
      "auroc": 0.7283333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 95,
          "fn": 105,
          "accuracy": 0.475
        },
        "0.01": null
      },
      "auroc": 0.7283333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": null
      },
      "auroc": 0.6908333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": null
      },
      "auroc": 0.6908333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 175,
          "fn": 225,
          "accuracy": 0.4375
        },
        "0.01": null
      },
      "auroc": 0.7095833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 175,
          "fn": 225,
          "accuracy": 0.4375
        },
        "0.01": null
      },
      "auroc": 0.7095833333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1054,
          "fn": 1146,
          "accuracy": 0.47909090909090907
        },
        "0.01": null
      },
      "auroc": 0.7303787878787878
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 383,
          "fn": 817,
          "accuracy": 0.31916666666666665
        },
        "0.01": null
      },
      "auroc": 0.6504166666666666
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1437,
          "fn": 1963,
          "accuracy": 0.42264705882352943
        },
        "0.01": null
      },
      "auroc": 0.702156862745098
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 886,
          "fn": 1314,
          "accuracy": 0.4027272727272727
        },
        "0.01": null
      },
      "auroc": 0.6921969696969698
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 243,
          "fn": 957,
          "accuracy": 0.2025
        },
        "0.01": null
      },
      "auroc": 0.5920833333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1129,
          "fn": 2271,
          "accuracy": 0.33205882352941174
        },
        "0.01": null
      },
      "auroc": 0.6568627450980392
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1940,
          "fn": 2460,
          "accuracy": 0.4409090909090909
        },
        "0.01": null
      },
      "auroc": 0.7112878787878789
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 626,
          "fn": 1774,
          "accuracy": 0.2608333333333333
        },
        "0.01": null
      },
      "auroc": 0.62125
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 2566,
          "fn": 4234,
          "accuracy": 0.3773529411764706
        },
        "0.01": null
      },
      "auroc": 0.6795098039215687
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        },
        "0.01": null
      },
      "auroc": 0.8533333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        },
        "0.01": null
      },
      "auroc": 0.8258333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 279,
          "fn": 121,
          "accuracy": 0.6975
        },
        "0.01": null
      },
      "auroc": 0.8395833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 140,
          "fn": 60,
          "accuracy": 0.7
        },
        "0.01": null
      },
      "auroc": 0.8408333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 114,
          "fn": 86,
          "accuracy": 0.57
        },
        "0.01": null
      },
      "auroc": 0.7758333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 254,
          "fn": 146,
          "accuracy": 0.635
        },
        "0.01": null
      },
      "auroc": 0.8083333333333335
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 285,
          "fn": 115,
          "accuracy": 0.7125
        },
        "0.01": null
      },
      "auroc": 0.8470833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 248,
          "fn": 152,
          "accuracy": 0.62
        },
        "0.01": null
      },
      "auroc": 0.8008333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 533,
          "fn": 267,
          "accuracy": 0.66625
        },
        "0.01": null
      },
      "auroc": 0.8239583333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        },
        "0.01": null
      },
      "auroc": 0.6033333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 351,
          "accuracy": 0.1225
        },
        "0.01": null
      },
      "auroc": 0.5520833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        },
        "0.01": null
      },
      "auroc": 0.5208333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": null
      },
      "auroc": 0.5158333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 378,
          "accuracy": 0.055
        },
        "0.01": null
      },
      "auroc": 0.5183333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 343,
          "accuracy": 0.1425
        },
        "0.01": null
      },
      "auroc": 0.5620833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 386,
          "accuracy": 0.035
        },
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 729,
          "accuracy": 0.08875
        },
        "0.01": null
      },
      "auroc": 0.5352083333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": null
      },
      "auroc": 0.5708333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": null
      },
      "auroc": 0.5108333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        },
        "0.01": null
      },
      "auroc": 0.5408333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 38,
          "fn": 162,
          "accuracy": 0.19
        },
        "0.01": null
      },
      "auroc": 0.5858333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 42,
          "fn": 358,
          "accuracy": 0.105
        },
        "0.01": null
      },
      "auroc": 0.5433333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        },
        "0.01": null
      },
      "auroc": 0.5783333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 388,
          "accuracy": 0.03
        },
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 718,
          "accuracy": 0.1025
        },
        "0.01": null
      },
      "auroc": 0.5420833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": null
      },
      "auroc": 0.5608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 363,
          "accuracy": 0.0925
        },
        "0.01": null
      },
      "auroc": 0.5370833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": null
      },
      "auroc": 0.5633333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 38,
          "fn": 362,
          "accuracy": 0.095
        },
        "0.01": null
      },
      "auroc": 0.5383333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 343,
          "accuracy": 0.1425
        },
        "0.01": null
      },
      "auroc": 0.5620833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 382,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 75,
          "fn": 725,
          "accuracy": 0.09375
        },
        "0.01": null
      },
      "auroc": 0.5377083333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        },
        "0.01": null
      },
      "auroc": 0.5933333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 357,
          "accuracy": 0.1075
        },
        "0.01": null
      },
      "auroc": 0.5445833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": null
      },
      "auroc": 0.5158333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 386,
          "accuracy": 0.035
        },
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        },
        "0.01": null
      },
      "auroc": 0.5545833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 394,
          "accuracy": 0.015
        },
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 743,
          "accuracy": 0.07125
        },
        "0.01": null
      },
      "auroc": 0.5264583333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": null
      },
      "auroc": 0.5733333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": null
      },
      "auroc": 0.5533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 58,
          "fn": 342,
          "accuracy": 0.145
        },
        "0.01": null
      },
      "auroc": 0.5633333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        },
        "0.01": null
      },
      "auroc": 0.5933333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        },
        "0.01": null
      },
      "auroc": 0.5358333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 341,
          "accuracy": 0.1475
        },
        "0.01": null
      },
      "auroc": 0.5645833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 326,
          "accuracy": 0.185
        },
        "0.01": null
      },
      "auroc": 0.5833333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 357,
          "accuracy": 0.1075
        },
        "0.01": null
      },
      "auroc": 0.5445833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 683,
          "accuracy": 0.14625
        },
        "0.01": null
      },
      "auroc": 0.5639583333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": null
      },
      "auroc": 0.6408333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": null
      },
      "auroc": 0.6408333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": null
      },
      "auroc": 0.5758333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": null
      },
      "auroc": 0.5758333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 94,
          "fn": 306,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 94,
          "fn": 306,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        },
        "0.01": null
      },
      "auroc": 0.5358333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        },
        "0.01": null
      },
      "auroc": 0.5358333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        },
        "0.01": null
      },
      "auroc": 0.5295833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        },
        "0.01": null
      },
      "auroc": 0.5295833333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        },
        "0.01": null
      },
      "auroc": 0.5208333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        },
        "0.01": null
      },
      "auroc": 0.5208333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 379,
          "accuracy": 0.0525
        },
        "0.01": null
      },
      "auroc": 0.5170833333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 379,
          "accuracy": 0.0525
        },
        "0.01": null
      },
      "auroc": 0.5170833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        },
        "0.01": null
      },
      "auroc": 0.5358333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        },
        "0.01": null
      },
      "auroc": 0.5358333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 19,
          "fn": 381,
          "accuracy": 0.0475
        },
        "0.01": null
      },
      "auroc": 0.5145833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 19,
          "fn": 381,
          "accuracy": 0.0475
        },
        "0.01": null
      },
      "auroc": 0.5145833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": null
      },
      "auroc": 0.5733333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": null
      },
      "auroc": 0.5733333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": null
      },
      "auroc": 0.5458333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": null
      },
      "auroc": 0.5458333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        },
        "0.01": null
      },
      "auroc": 0.5595833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        },
        "0.01": null
      },
      "auroc": 0.5595833333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 465,
          "fn": 1735,
          "accuracy": 0.21136363636363636
        },
        "0.01": null
      },
      "auroc": 0.5965151515151516
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 182,
          "fn": 1018,
          "accuracy": 0.15166666666666667
        },
        "0.01": null
      },
      "auroc": 0.5666666666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 647,
          "fn": 2753,
          "accuracy": 0.19029411764705884
        },
        "0.01": null
      },
      "auroc": 0.5859803921568628
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 349,
          "fn": 1851,
          "accuracy": 0.15863636363636363
        },
        "0.01": null
      },
      "auroc": 0.5701515151515152
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 159,
          "fn": 1041,
          "accuracy": 0.1325
        },
        "0.01": null
      },
      "auroc": 0.5570833333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 508,
          "fn": 2892,
          "accuracy": 0.14941176470588236
        },
        "0.01": null
      },
      "auroc": 0.5655392156862745
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 814,
          "fn": 3586,
          "accuracy": 0.185
        },
        "0.01": null
      },
      "auroc": 0.5833333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 341,
          "fn": 2059,
          "accuracy": 0.14208333333333334
        },
        "0.01": null
      },
      "auroc": 0.561875
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 1155,
          "fn": 5645,
          "accuracy": 0.1698529411764706
        },
        "0.01": null
      },
      "auroc": 0.5757598039215687
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        },
        "0.01": null
      },
      "auroc": 0.9108333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 146,
          "fn": 54,
          "accuracy": 0.73
        },
        "0.01": null
      },
      "auroc": 0.8558333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        },
        "0.01": null
      },
      "auroc": 0.8833333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        },
        "0.01": null
      },
      "auroc": 0.8933333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 64,
          "accuracy": 0.68
        },
        "0.01": null
      },
      "auroc": 0.8308333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 297,
          "fn": 103,
          "accuracy": 0.7425
        },
        "0.01": null
      },
      "auroc": 0.8620833333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        },
        "0.01": null
      },
      "auroc": 0.9020833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 282,
          "fn": 118,
          "accuracy": 0.705
        },
        "0.01": null
      },
      "auroc": 0.8433333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 611,
          "fn": 189,
          "accuracy": 0.76375
        },
        "0.01": null
      },
      "auroc": 0.8727083333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        },
        "0.01": null
      },
      "auroc": 0.6383333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        },
        "0.01": null
      },
      "auroc": 0.5708333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": null
      },
      "auroc": 0.5508333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        },
        "0.01": null
      },
      "auroc": 0.5283333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 361,
          "accuracy": 0.0975
        },
        "0.01": null
      },
      "auroc": 0.5395833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 317,
          "accuracy": 0.2075
        },
        "0.01": null
      },
      "auroc": 0.5945833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 20,
          "fn": 380,
          "accuracy": 0.05
        },
        "0.01": null
      },
      "auroc": 0.5158333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 697,
          "accuracy": 0.12875
        },
        "0.01": null
      },
      "auroc": 0.5552083333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 106,
          "fn": 94,
          "accuracy": 0.53
        },
        "0.01": null
      },
      "auroc": 0.7558333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 153,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 153,
          "fn": 247,
          "accuracy": 0.3825
        },
        "0.01": null
      },
      "auroc": 0.6820833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        },
        "0.01": null
      },
      "auroc": 0.7908333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 267,
          "accuracy": 0.3325
        },
        "0.01": null
      },
      "auroc": 0.6570833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 226,
          "fn": 174,
          "accuracy": 0.565
        },
        "0.01": null
      },
      "auroc": 0.7733333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 340,
          "accuracy": 0.15
        },
        "0.01": null
      },
      "auroc": 0.5658333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 286,
          "fn": 514,
          "accuracy": 0.3575
        },
        "0.01": null
      },
      "auroc": 0.6695833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": null
      },
      "auroc": 0.5733333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        },
        "0.01": null
      },
      "auroc": 0.6108333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 319,
          "accuracy": 0.2025
        },
        "0.01": null
      },
      "auroc": 0.5920833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": null
      },
      "auroc": 0.5983333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        },
        "0.01": null
      },
      "auroc": 0.5208333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        },
        "0.01": null
      },
      "auroc": 0.5595833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 76,
          "fn": 324,
          "accuracy": 0.19
        },
        "0.01": null
      },
      "auroc": 0.5858333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 340,
          "accuracy": 0.15
        },
        "0.01": null
      },
      "auroc": 0.5658333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 664,
          "accuracy": 0.17
        },
        "0.01": null
      },
      "auroc": 0.5758333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 61,
          "fn": 139,
          "accuracy": 0.305
        },
        "0.01": null
      },
      "auroc": 0.6433333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        },
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 333,
          "accuracy": 0.1675
        },
        "0.01": null
      },
      "auroc": 0.5745833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": null
      },
      "auroc": 0.5633333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        },
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 368,
          "accuracy": 0.08
        },
        "0.01": null
      },
      "auroc": 0.5308333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 310,
          "accuracy": 0.225
        },
        "0.01": null
      },
      "auroc": 0.6033333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 391,
          "accuracy": 0.0225
        },
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 99,
          "fn": 701,
          "accuracy": 0.12375
        },
        "0.01": null
      },
      "auroc": 0.5527083333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": null
      },
      "auroc": 0.6958333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 149,
          "accuracy": 0.255
        },
        "0.01": null
      },
      "auroc": 0.6183333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 267,
          "accuracy": 0.3325
        },
        "0.01": null
      },
      "auroc": 0.6570833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 126,
          "accuracy": 0.37
        },
        "0.01": null
      },
      "auroc": 0.6758333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": null
      },
      "auroc": 0.5758333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": null
      },
      "auroc": 0.6258333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 244,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 315,
          "accuracy": 0.2125
        },
        "0.01": null
      },
      "auroc": 0.5970833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 241,
          "fn": 559,
          "accuracy": 0.30125
        },
        "0.01": null
      },
      "auroc": 0.6414583333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": null
      },
      "auroc": 0.7608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": null
      },
      "auroc": 0.7608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        },
        "0.01": null
      },
      "auroc": 0.7108333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        },
        "0.01": null
      },
      "auroc": 0.7108333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 196,
          "fn": 204,
          "accuracy": 0.49
        },
        "0.01": null
      },
      "auroc": 0.7358333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 196,
          "fn": 204,
          "accuracy": 0.49
        },
        "0.01": null
      },
      "auroc": 0.7358333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        },
        "0.01": null
      },
      "auroc": 0.5883333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        },
        "0.01": null
      },
      "auroc": 0.5883333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 38,
          "fn": 162,
          "accuracy": 0.19
        },
        "0.01": null
      },
      "auroc": 0.5858333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 38,
          "fn": 162,
          "accuracy": 0.19
        },
        "0.01": null
      },
      "auroc": 0.5858333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 77,
          "fn": 323,
          "accuracy": 0.1925
        },
        "0.01": null
      },
      "auroc": 0.5870833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 77,
          "fn": 323,
          "accuracy": 0.1925
        },
        "0.01": null
      },
      "auroc": 0.5870833333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": null
      },
      "auroc": 0.6633333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": null
      },
      "auroc": 0.6633333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        },
        "0.01": null
      },
      "auroc": 0.6383333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        },
        "0.01": null
      },
      "auroc": 0.6383333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 272,
          "accuracy": 0.32
        },
        "0.01": null
      },
      "auroc": 0.6508333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 272,
          "accuracy": 0.32
        },
        "0.01": null
      },
      "auroc": 0.6508333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        },
        "0.01": null
      },
      "auroc": 0.7158333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        },
        "0.01": null
      },
      "auroc": 0.7158333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        },
        "0.01": null
      },
      "auroc": 0.5658333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        },
        "0.01": null
      },
      "auroc": 0.5658333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 280,
          "accuracy": 0.3
        },
        "0.01": null
      },
      "auroc": 0.6408333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 280,
          "accuracy": 0.3
        },
        "0.01": null
      },
      "auroc": 0.6408333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 121,
          "accuracy": 0.395
        },
        "0.01": null
      },
      "auroc": 0.6883333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 121,
          "accuracy": 0.395
        },
        "0.01": null
      },
      "auroc": 0.6883333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": null
      },
      "auroc": 0.6408333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": null
      },
      "auroc": 0.6408333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        },
        "0.01": null
      },
      "auroc": 0.6645833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        },
        "0.01": null
      },
      "auroc": 0.6645833333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 894,
          "fn": 1306,
          "accuracy": 0.40636363636363637
        },
        "0.01": null
      },
      "auroc": 0.6940151515151515
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 303,
          "fn": 897,
          "accuracy": 0.2525
        },
        "0.01": null
      },
      "auroc": 0.6170833333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 1197,
          "fn": 2203,
          "accuracy": 0.35205882352941176
        },
        "0.01": null
      },
      "auroc": 0.6668627450980392
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 726,
          "fn": 1474,
          "accuracy": 0.33
        },
        "0.01": null
      },
      "auroc": 0.6558333333333335
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 213,
          "fn": 987,
          "accuracy": 0.1775
        },
        "0.01": null
      },
      "auroc": 0.5795833333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 939,
          "fn": 2461,
          "accuracy": 0.2761764705882353
        },
        "0.01": null
      },
      "auroc": 0.628921568627451
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 1620,
          "fn": 2780,
          "accuracy": 0.36818181818181817
        },
        "0.01": null
      },
      "auroc": 0.6749242424242424
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 516,
          "fn": 1884,
          "accuracy": 0.215
        },
        "0.01": null
      },
      "auroc": 0.5983333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 2136,
          "fn": 4664,
          "accuracy": 0.31411764705882356
        },
        "0.01": null
      },
      "auroc": 0.6478921568627451
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 177,
          "fn": 23,
          "accuracy": 0.885
        },
        "0.01": null
      },
      "auroc": 0.9333333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 50,
          "accuracy": 0.75
        },
        "0.01": null
      },
      "auroc": 0.8658333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 327,
          "fn": 73,
          "accuracy": 0.8175
        },
        "0.01": null
      },
      "auroc": 0.8995833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 167,
          "fn": 33,
          "accuracy": 0.835
        },
        "0.01": null
      },
      "auroc": 0.9083333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 135,
          "fn": 65,
          "accuracy": 0.675
        },
        "0.01": null
      },
      "auroc": 0.8283333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 302,
          "fn": 98,
          "accuracy": 0.755
        },
        "0.01": null
      },
      "auroc": 0.8683333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 344,
          "fn": 56,
          "accuracy": 0.86
        },
        "0.01": null
      },
      "auroc": 0.9208333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 285,
          "fn": 115,
          "accuracy": 0.7125
        },
        "0.01": null
      },
      "auroc": 0.8470833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 629,
          "fn": 171,
          "accuracy": 0.78625
        },
        "0.01": null
      },
      "auroc": 0.8839583333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        },
        "0.01": null
      },
      "auroc": 0.6383333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        },
        "0.01": null
      },
      "auroc": 0.5708333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": null
      },
      "auroc": 0.5508333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 363,
          "accuracy": 0.0925
        },
        "0.01": null
      },
      "auroc": 0.5370833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 317,
          "accuracy": 0.2075
        },
        "0.01": null
      },
      "auroc": 0.5945833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 382,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 699,
          "accuracy": 0.12625
        },
        "0.01": null
      },
      "auroc": 0.5539583333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": null
      },
      "auroc": 0.7583333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 44,
          "fn": 156,
          "accuracy": 0.22
        },
        "0.01": null
      },
      "auroc": 0.6008333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 151,
          "fn": 249,
          "accuracy": 0.3775
        },
        "0.01": null
      },
      "auroc": 0.6795833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": null
      },
      "auroc": 0.7608333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        },
        "0.01": null
      },
      "auroc": 0.5408333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 272,
          "accuracy": 0.32
        },
        "0.01": null
      },
      "auroc": 0.6508333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 215,
          "fn": 185,
          "accuracy": 0.5375
        },
        "0.01": null
      },
      "auroc": 0.7595833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        },
        "0.01": null
      },
      "auroc": 0.5708333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 279,
          "fn": 521,
          "accuracy": 0.34875
        },
        "0.01": null
      },
      "auroc": 0.6652083333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": null
      },
      "auroc": 0.5583333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 154,
          "accuracy": 0.23
        },
        "0.01": null
      },
      "auroc": 0.6058333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        },
        "0.01": null
      },
      "auroc": 0.5820833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 44,
          "fn": 156,
          "accuracy": 0.22
        },
        "0.01": null
      },
      "auroc": 0.6008333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 343,
          "accuracy": 0.1425
        },
        "0.01": null
      },
      "auroc": 0.5620833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 329,
          "accuracy": 0.1775
        },
        "0.01": null
      },
      "auroc": 0.5795833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 341,
          "accuracy": 0.1475
        },
        "0.01": null
      },
      "auroc": 0.5645833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 670,
          "accuracy": 0.1625
        },
        "0.01": null
      },
      "auroc": 0.5720833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": null
      },
      "auroc": 0.6558333333333335
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 329,
          "accuracy": 0.1775
        },
        "0.01": null
      },
      "auroc": 0.5795833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": null
      },
      "auroc": 0.5533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        },
        "0.01": null
      },
      "auroc": 0.5283333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        },
        "0.01": null
      },
      "auroc": 0.6045833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 390,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 699,
          "accuracy": 0.12625
        },
        "0.01": null
      },
      "auroc": 0.5539583333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": null
      },
      "auroc": 0.6933333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 149,
          "accuracy": 0.255
        },
        "0.01": null
      },
      "auroc": 0.6183333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 132,
          "fn": 268,
          "accuracy": 0.33
        },
        "0.01": null
      },
      "auroc": 0.6558333333333335
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        },
        "0.01": null
      },
      "auroc": 0.5658333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": null
      },
      "auroc": 0.6258333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 159,
          "fn": 241,
          "accuracy": 0.3975
        },
        "0.01": null
      },
      "auroc": 0.6895833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 319,
          "accuracy": 0.2025
        },
        "0.01": null
      },
      "auroc": 0.5920833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 240,
          "fn": 560,
          "accuracy": 0.3
        },
        "0.01": null
      },
      "auroc": 0.6408333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        },
        "0.01": null
      },
      "auroc": 0.7908333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        },
        "0.01": null
      },
      "auroc": 0.7908333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 102,
          "fn": 98,
          "accuracy": 0.51
        },
        "0.01": null
      },
      "auroc": 0.7458333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 102,
          "fn": 98,
          "accuracy": 0.51
        },
        "0.01": null
      },
      "auroc": 0.7458333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 222,
          "fn": 178,
          "accuracy": 0.555
        },
        "0.01": null
      },
      "auroc": 0.7683333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 222,
          "fn": 178,
          "accuracy": 0.555
        },
        "0.01": null
      },
      "auroc": 0.7683333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        },
        "0.01": null
      },
      "auroc": 0.6108333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        },
        "0.01": null
      },
      "auroc": 0.6108333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 153,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 153,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 95,
          "fn": 305,
          "accuracy": 0.2375
        },
        "0.01": null
      },
      "auroc": 0.6095833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 95,
          "fn": 305,
          "accuracy": 0.2375
        },
        "0.01": null
      },
      "auroc": 0.6095833333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": null
      },
      "auroc": 0.6583333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": null
      },
      "auroc": 0.6583333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        },
        "0.01": null
      },
      "auroc": 0.6383333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        },
        "0.01": null
      },
      "auroc": 0.6383333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 126,
          "fn": 274,
          "accuracy": 0.315
        },
        "0.01": null
      },
      "auroc": 0.6483333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 126,
          "fn": 274,
          "accuracy": 0.315
        },
        "0.01": null
      },
      "auroc": 0.6483333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 77,
          "fn": 123,
          "accuracy": 0.385
        },
        "0.01": null
      },
      "auroc": 0.6833333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 77,
          "fn": 123,
          "accuracy": 0.385
        },
        "0.01": null
      },
      "auroc": 0.6833333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": null
      },
      "auroc": 0.5608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": null
      },
      "auroc": 0.5608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 295,
          "accuracy": 0.2625
        },
        "0.01": null
      },
      "auroc": 0.6220833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 295,
          "accuracy": 0.2625
        },
        "0.01": null
      },
      "auroc": 0.6220833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 75,
          "fn": 125,
          "accuracy": 0.375
        },
        "0.01": null
      },
      "auroc": 0.6783333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 75,
          "fn": 125,
          "accuracy": 0.375
        },
        "0.01": null
      },
      "auroc": 0.6783333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        },
        "0.01": null
      },
      "auroc": 0.6458333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        },
        "0.01": null
      },
      "auroc": 0.6458333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 137,
          "fn": 263,
          "accuracy": 0.3425
        },
        "0.01": null
      },
      "auroc": 0.6620833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 137,
          "fn": 263,
          "accuracy": 0.3425
        },
        "0.01": null
      },
      "auroc": 0.6620833333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 904,
          "fn": 1296,
          "accuracy": 0.4109090909090909
        },
        "0.01": null
      },
      "auroc": 0.6962878787878788
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 301,
          "fn": 899,
          "accuracy": 0.25083333333333335
        },
        "0.01": null
      },
      "auroc": 0.6162500000000001
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 1205,
          "fn": 2195,
          "accuracy": 0.35441176470588237
        },
        "0.01": null
      },
      "auroc": 0.6680392156862746
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 744,
          "fn": 1456,
          "accuracy": 0.3381818181818182
        },
        "0.01": null
      },
      "auroc": 0.6599242424242424
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 216,
          "fn": 984,
          "accuracy": 0.18
        },
        "0.01": null
      },
      "auroc": 0.5808333333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 960,
          "fn": 2440,
          "accuracy": 0.2823529411764706
        },
        "0.01": null
      },
      "auroc": 0.6320098039215686
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 1648,
          "fn": 2752,
          "accuracy": 0.37454545454545457
        },
        "0.01": null
      },
      "auroc": 0.6781060606060606
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 517,
          "fn": 1883,
          "accuracy": 0.21541666666666667
        },
        "0.01": null
      },
      "auroc": 0.5985416666666666
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 2165,
          "fn": 4635,
          "accuracy": 0.31838235294117645
        },
        "0.01": null
      },
      "auroc": 0.6500245098039216
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 174,
          "fn": 26,
          "accuracy": 0.87
        },
        "0.01": null
      },
      "auroc": 0.9258333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 43,
          "accuracy": 0.785
        },
        "0.01": null
      },
      "auroc": 0.8833333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 331,
          "fn": 69,
          "accuracy": 0.8275
        },
        "0.01": null
      },
      "auroc": 0.9045833333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        },
        "0.01": null
      },
      "auroc": 0.9183333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 146,
          "fn": 54,
          "accuracy": 0.73
        },
        "0.01": null
      },
      "auroc": 0.8558333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 317,
          "fn": 83,
          "accuracy": 0.7925
        },
        "0.01": null
      },
      "auroc": 0.8870833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 345,
          "fn": 55,
          "accuracy": 0.8625
        },
        "0.01": null
      },
      "auroc": 0.9220833333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 303,
          "fn": 97,
          "accuracy": 0.7575
        },
        "0.01": null
      },
      "auroc": 0.8695833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 648,
          "fn": 152,
          "accuracy": 0.81
        },
        "0.01": null
      },
      "auroc": 0.8958333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 135,
          "accuracy": 0.325
        },
        "0.01": null
      },
      "auroc": 0.6533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        },
        "0.01": null
      },
      "auroc": 0.5783333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": null
      },
      "auroc": 0.5633333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 42,
          "fn": 358,
          "accuracy": 0.105
        },
        "0.01": null
      },
      "auroc": 0.5433333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 94,
          "fn": 306,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 382,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 688,
          "accuracy": 0.14
        },
        "0.01": null
      },
      "auroc": 0.5608333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        },
        "0.01": null
      },
      "auroc": 0.8008333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 135,
          "accuracy": 0.325
        },
        "0.01": null
      },
      "auroc": 0.6533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 189,
          "fn": 211,
          "accuracy": 0.4725
        },
        "0.01": null
      },
      "auroc": 0.7270833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 137,
          "fn": 63,
          "accuracy": 0.685
        },
        "0.01": null
      },
      "auroc": 0.8333333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": null
      },
      "auroc": 0.5533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 162,
          "fn": 238,
          "accuracy": 0.405
        },
        "0.01": null
      },
      "auroc": 0.6933333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 261,
          "fn": 139,
          "accuracy": 0.6525
        },
        "0.01": null
      },
      "auroc": 0.8170833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 310,
          "accuracy": 0.225
        },
        "0.01": null
      },
      "auroc": 0.6033333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 351,
          "fn": 449,
          "accuracy": 0.43875
        },
        "0.01": null
      },
      "auroc": 0.7102083333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": null
      },
      "auroc": 0.5683333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 63,
          "fn": 137,
          "accuracy": 0.315
        },
        "0.01": null
      },
      "auroc": 0.6483333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 94,
          "fn": 306,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 50,
          "fn": 150,
          "accuracy": 0.25
        },
        "0.01": null
      },
      "auroc": 0.6158333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        },
        "0.01": null
      },
      "auroc": 0.5695833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 319,
          "accuracy": 0.2025
        },
        "0.01": null
      },
      "auroc": 0.5920833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 76,
          "fn": 324,
          "accuracy": 0.19
        },
        "0.01": null
      },
      "auroc": 0.5858333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 643,
          "accuracy": 0.19625
        },
        "0.01": null
      },
      "auroc": 0.5889583333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        },
        "0.01": null
      },
      "auroc": 0.6508333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        },
        "0.01": null
      },
      "auroc": 0.5820833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": null
      },
      "auroc": 0.5608333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 368,
          "accuracy": 0.08
        },
        "0.01": null
      },
      "auroc": 0.5308333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 308,
          "accuracy": 0.23
        },
        "0.01": null
      },
      "auroc": 0.6058333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 387,
          "accuracy": 0.0325
        },
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 695,
          "accuracy": 0.13125
        },
        "0.01": null
      },
      "auroc": 0.5564583333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 99,
          "fn": 101,
          "accuracy": 0.495
        },
        "0.01": null
      },
      "auroc": 0.7383333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 177,
          "fn": 223,
          "accuracy": 0.4425
        },
        "0.01": null
      },
      "auroc": 0.7120833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 89,
          "fn": 111,
          "accuracy": 0.445
        },
        "0.01": null
      },
      "auroc": 0.7133333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        },
        "0.01": null
      },
      "auroc": 0.5933333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 270,
          "accuracy": 0.325
        },
        "0.01": null
      },
      "auroc": 0.6533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 188,
          "fn": 212,
          "accuracy": 0.47
        },
        "0.01": null
      },
      "auroc": 0.7258333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 281,
          "accuracy": 0.2975
        },
        "0.01": null
      },
      "auroc": 0.6395833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 307,
          "fn": 493,
          "accuracy": 0.38375
        },
        "0.01": null
      },
      "auroc": 0.6827083333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 115,
          "fn": 85,
          "accuracy": 0.575
        },
        "0.01": null
      },
      "auroc": 0.7783333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 115,
          "fn": 85,
          "accuracy": 0.575
        },
        "0.01": null
      },
      "auroc": 0.7783333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": null
      },
      "auroc": 0.7733333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": null
      },
      "auroc": 0.7733333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 228,
          "fn": 172,
          "accuracy": 0.57
        },
        "0.01": null
      },
      "auroc": 0.7758333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 228,
          "fn": 172,
          "accuracy": 0.57
        },
        "0.01": null
      },
      "auroc": 0.7758333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 54,
          "fn": 146,
          "accuracy": 0.27
        },
        "0.01": null
      },
      "auroc": 0.6258333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 54,
          "fn": 146,
          "accuracy": 0.27
        },
        "0.01": null
      },
      "auroc": 0.6258333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        },
        "0.01": null
      },
      "auroc": 0.6033333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        },
        "0.01": null
      },
      "auroc": 0.6033333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 99,
          "fn": 301,
          "accuracy": 0.2475
        },
        "0.01": null
      },
      "auroc": 0.6145833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 99,
          "fn": 301,
          "accuracy": 0.2475
        },
        "0.01": null
      },
      "auroc": 0.6145833333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": null
      },
      "auroc": 0.7233333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": null
      },
      "auroc": 0.7233333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 75,
          "fn": 125,
          "accuracy": 0.375
        },
        "0.01": null
      },
      "auroc": 0.6783333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 75,
          "fn": 125,
          "accuracy": 0.375
        },
        "0.01": null
      },
      "auroc": 0.6783333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 232,
          "accuracy": 0.42
        },
        "0.01": null
      },
      "auroc": 0.7008333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 232,
          "accuracy": 0.42
        },
        "0.01": null
      },
      "auroc": 0.7008333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": null
      },
      "auroc": 0.7608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": null
      },
      "auroc": 0.7608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": null
      },
      "auroc": 0.5983333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": null
      },
      "auroc": 0.5983333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 151,
          "fn": 249,
          "accuracy": 0.3775
        },
        "0.01": null
      },
      "auroc": 0.6795833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 151,
          "fn": 249,
          "accuracy": 0.3775
        },
        "0.01": null
      },
      "auroc": 0.6795833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": null
      },
      "auroc": 0.7183333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": null
      },
      "auroc": 0.7183333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 169,
          "fn": 231,
          "accuracy": 0.4225
        },
        "0.01": null
      },
      "auroc": 0.7020833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 169,
          "fn": 231,
          "accuracy": 0.4225
        },
        "0.01": null
      },
      "auroc": 0.7020833333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1018,
          "fn": 1182,
          "accuracy": 0.4627272727272727
        },
        "0.01": null
      },
      "auroc": 0.7221969696969697
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 377,
          "fn": 823,
          "accuracy": 0.31416666666666665
        },
        "0.01": null
      },
      "auroc": 0.6479166666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1395,
          "fn": 2005,
          "accuracy": 0.4102941176470588
        },
        "0.01": null
      },
      "auroc": 0.6959803921568627
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 858,
          "fn": 1342,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 242,
          "fn": 958,
          "accuracy": 0.20166666666666666
        },
        "0.01": null
      },
      "auroc": 0.5916666666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1100,
          "fn": 2300,
          "accuracy": 0.3235294117647059
        },
        "0.01": null
      },
      "auroc": 0.6525980392156863
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1876,
          "fn": 2524,
          "accuracy": 0.4263636363636364
        },
        "0.01": null
      },
      "auroc": 0.7040151515151515
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 619,
          "fn": 1781,
          "accuracy": 0.2579166666666667
        },
        "0.01": null
      },
      "auroc": 0.6197916666666666
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 2495,
          "fn": 4305,
          "accuracy": 0.3669117647058823
        },
        "0.01": null
      },
      "auroc": 0.6742892156862745
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        },
        "0.01": null
      },
      "auroc": 0.6508333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 129,
          "accuracy": 0.355
        },
        "0.01": null
      },
      "auroc": 0.6683333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 135,
          "fn": 265,
          "accuracy": 0.3375
        },
        "0.01": null
      },
      "auroc": 0.6595833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 68,
          "fn": 132,
          "accuracy": 0.34
        },
        "0.01": null
      },
      "auroc": 0.6608333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": null
      },
      "auroc": 0.6633333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 137,
          "fn": 263,
          "accuracy": 0.3425
        },
        "0.01": null
      },
      "auroc": 0.6620833333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 132,
          "fn": 268,
          "accuracy": 0.33
        },
        "0.01": null
      },
      "auroc": 0.6558333333333335
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 140,
          "fn": 260,
          "accuracy": 0.35
        },
        "0.01": null
      },
      "auroc": 0.6658333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 272,
          "fn": 528,
          "accuracy": 0.34
        },
        "0.01": null
      },
      "auroc": 0.6608333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        },
        "0.01": null
      },
      "auroc": 0.5933333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 16,
          "fn": 184,
          "accuracy": 0.08
        },
        "0.01": null
      },
      "auroc": 0.5308333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 343,
          "accuracy": 0.1425
        },
        "0.01": null
      },
      "auroc": 0.5620833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        },
        "0.01": null
      },
      "auroc": 0.5783333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        },
        "0.01": null
      },
      "auroc": 0.5658333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        },
        "0.01": null
      },
      "auroc": 0.5720833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 76,
          "fn": 324,
          "accuracy": 0.19
        },
        "0.01": null
      },
      "auroc": 0.5858333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 354,
          "accuracy": 0.115
        },
        "0.01": null
      },
      "auroc": 0.5483333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 678,
          "accuracy": 0.1525
        },
        "0.01": null
      },
      "auroc": 0.5670833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 137,
          "fn": 63,
          "accuracy": 0.685
        },
        "0.01": null
      },
      "auroc": 0.8333333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        },
        "0.01": null
      },
      "auroc": 0.7958333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        },
        "0.01": null
      },
      "auroc": 0.8145833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 142,
          "fn": 58,
          "accuracy": 0.71
        },
        "0.01": null
      },
      "auroc": 0.8458333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 89,
          "fn": 111,
          "accuracy": 0.445
        },
        "0.01": null
      },
      "auroc": 0.7133333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 231,
          "fn": 169,
          "accuracy": 0.5775
        },
        "0.01": null
      },
      "auroc": 0.7795833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 279,
          "fn": 121,
          "accuracy": 0.6975
        },
        "0.01": null
      },
      "auroc": 0.8395833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 211,
          "fn": 189,
          "accuracy": 0.5275
        },
        "0.01": null
      },
      "auroc": 0.7545833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 490,
          "fn": 310,
          "accuracy": 0.6125
        },
        "0.01": null
      },
      "auroc": 0.7970833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": null
      },
      "auroc": 0.5683333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": null
      },
      "auroc": 0.6933333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 288,
          "accuracy": 0.28
        },
        "0.01": null
      },
      "auroc": 0.6308333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        },
        "0.01": null
      },
      "auroc": 0.6108333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        },
        "0.01": null
      },
      "auroc": 0.5483333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 329,
          "accuracy": 0.1775
        },
        "0.01": null
      },
      "auroc": 0.5795833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        },
        "0.01": null
      },
      "auroc": 0.5895833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 104,
          "fn": 296,
          "accuracy": 0.26
        },
        "0.01": null
      },
      "auroc": 0.6208333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 183,
          "fn": 617,
          "accuracy": 0.22875
        },
        "0.01": null
      },
      "auroc": 0.6052083333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 52,
          "fn": 148,
          "accuracy": 0.26
        },
        "0.01": null
      },
      "auroc": 0.6208333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        },
        "0.01": null
      },
      "auroc": 0.5883333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        },
        "0.01": null
      },
      "auroc": 0.6045833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        },
        "0.01": null
      },
      "auroc": 0.5833333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 16,
          "fn": 184,
          "accuracy": 0.08
        },
        "0.01": null
      },
      "auroc": 0.5308333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 53,
          "fn": 347,
          "accuracy": 0.1325
        },
        "0.01": null
      },
      "auroc": 0.5570833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 89,
          "fn": 311,
          "accuracy": 0.2225
        },
        "0.01": null
      },
      "auroc": 0.6020833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        },
        "0.01": null
      },
      "auroc": 0.5595833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 144,
          "fn": 656,
          "accuracy": 0.18
        },
        "0.01": null
      },
      "auroc": 0.5808333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 96,
          "fn": 104,
          "accuracy": 0.48
        },
        "0.01": null
      },
      "auroc": 0.7308333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": null
      },
      "auroc": 0.6908333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 224,
          "accuracy": 0.44
        },
        "0.01": null
      },
      "auroc": 0.7108333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 126,
          "accuracy": 0.37
        },
        "0.01": null
      },
      "auroc": 0.6758333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": null
      },
      "auroc": 0.5983333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 283,
          "accuracy": 0.2925
        },
        "0.01": null
      },
      "auroc": 0.6370833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 230,
          "accuracy": 0.425
        },
        "0.01": null
      },
      "auroc": 0.7033333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 277,
          "accuracy": 0.3075
        },
        "0.01": null
      },
      "auroc": 0.6445833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 293,
          "fn": 507,
          "accuracy": 0.36625
        },
        "0.01": null
      },
      "auroc": 0.6739583333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 141,
          "fn": 59,
          "accuracy": 0.705
        },
        "0.01": null
      },
      "auroc": 0.8433333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 141,
          "fn": 59,
          "accuracy": 0.705
        },
        "0.01": null
      },
      "auroc": 0.8433333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 125,
          "fn": 75,
          "accuracy": 0.625
        },
        "0.01": null
      },
      "auroc": 0.8033333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 125,
          "fn": 75,
          "accuracy": 0.625
        },
        "0.01": null
      },
      "auroc": 0.8033333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        },
        "0.01": null
      },
      "auroc": 0.8233333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        },
        "0.01": null
      },
      "auroc": 0.8233333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": null
      },
      "auroc": 0.6558333333333335
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": null
      },
      "auroc": 0.6558333333333335
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": null
      },
      "auroc": 0.6633333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": null
      },
      "auroc": 0.6633333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 135,
          "fn": 265,
          "accuracy": 0.3375
        },
        "0.01": null
      },
      "auroc": 0.6595833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 135,
          "fn": 265,
          "accuracy": 0.3375
        },
        "0.01": null
      },
      "auroc": 0.6595833333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 102,
          "fn": 98,
          "accuracy": 0.51
        },
        "0.01": null
      },
      "auroc": 0.7458333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 102,
          "fn": 98,
          "accuracy": 0.51
        },
        "0.01": null
      },
      "auroc": 0.7458333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 94,
          "fn": 106,
          "accuracy": 0.47
        },
        "0.01": null
      },
      "auroc": 0.7258333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 94,
          "fn": 106,
          "accuracy": 0.47
        },
        "0.01": null
      },
      "auroc": 0.7258333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 196,
          "fn": 204,
          "accuracy": 0.49
        },
        "0.01": null
      },
      "auroc": 0.7358333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 196,
          "fn": 204,
          "accuracy": 0.49
        },
        "0.01": null
      },
      "auroc": 0.7358333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": null
      },
      "auroc": 0.7708333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": null
      },
      "auroc": 0.7708333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": null
      },
      "auroc": 0.6958333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": null
      },
      "auroc": 0.6958333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 194,
          "fn": 206,
          "accuracy": 0.485
        },
        "0.01": null
      },
      "auroc": 0.7333333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 194,
          "fn": 206,
          "accuracy": 0.485
        },
        "0.01": null
      },
      "auroc": 0.7333333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 127,
          "accuracy": 0.365
        },
        "0.01": null
      },
      "auroc": 0.6733333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 127,
          "accuracy": 0.365
        },
        "0.01": null
      },
      "auroc": 0.6733333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": null
      },
      "auroc": 0.6633333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": null
      },
      "auroc": 0.6633333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 142,
          "fn": 258,
          "accuracy": 0.355
        },
        "0.01": null
      },
      "auroc": 0.6683333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 142,
          "fn": 258,
          "accuracy": 0.355
        },
        "0.01": null
      },
      "auroc": 0.6683333333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 915,
          "fn": 1285,
          "accuracy": 0.4159090909090909
        },
        "0.01": null
      },
      "auroc": 0.6987878787878788
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 409,
          "fn": 791,
          "accuracy": 0.3408333333333333
        },
        "0.01": null
      },
      "auroc": 0.66125
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 1324,
          "fn": 2076,
          "accuracy": 0.38941176470588235
        },
        "0.01": null
      },
      "auroc": 0.6855392156862745
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 843,
          "fn": 1357,
          "accuracy": 0.3831818181818182
        },
        "0.01": null
      },
      "auroc": 0.6824242424242425
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 270,
          "fn": 930,
          "accuracy": 0.225
        },
        "0.01": null
      },
      "auroc": 0.6033333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 1113,
          "fn": 2287,
          "accuracy": 0.32735294117647057
        },
        "0.01": null
      },
      "auroc": 0.6545098039215687
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 1758,
          "fn": 2642,
          "accuracy": 0.39954545454545454
        },
        "0.01": null
      },
      "auroc": 0.6906060606060606
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 679,
          "fn": 1721,
          "accuracy": 0.28291666666666665
        },
        "0.01": null
      },
      "auroc": 0.6322916666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 2437,
          "fn": 4363,
          "accuracy": 0.3583823529411765
        },
        "0.01": null
      },
      "auroc": 0.6700245098039216
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        },
        "0.01": null
      },
      "auroc": 0.9308333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 43,
          "accuracy": 0.785
        },
        "0.01": null
      },
      "auroc": 0.8833333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 333,
          "fn": 67,
          "accuracy": 0.8325
        },
        "0.01": null
      },
      "auroc": 0.9070833333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": null
      },
      "auroc": 0.9233333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 146,
          "fn": 54,
          "accuracy": 0.73
        },
        "0.01": null
      },
      "auroc": 0.8558333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 319,
          "fn": 81,
          "accuracy": 0.7975
        },
        "0.01": null
      },
      "auroc": 0.8895833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 349,
          "fn": 51,
          "accuracy": 0.8725
        },
        "0.01": null
      },
      "auroc": 0.9270833333333335
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 303,
          "fn": 97,
          "accuracy": 0.7575
        },
        "0.01": null
      },
      "auroc": 0.8695833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 652,
          "fn": 148,
          "accuracy": 0.815
        },
        "0.01": null
      },
      "auroc": 0.8983333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 68,
          "fn": 132,
          "accuracy": 0.34
        },
        "0.01": null
      },
      "auroc": 0.6608333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        },
        "0.01": null
      },
      "auroc": 0.5820833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": null
      },
      "auroc": 0.5708333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        },
        "0.01": null
      },
      "auroc": 0.5258333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 354,
          "accuracy": 0.115
        },
        "0.01": null
      },
      "auroc": 0.5483333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 300,
          "accuracy": 0.25
        },
        "0.01": null
      },
      "auroc": 0.6158333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 19,
          "fn": 381,
          "accuracy": 0.0475
        },
        "0.01": null
      },
      "auroc": 0.5145833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 681,
          "accuracy": 0.14875
        },
        "0.01": null
      },
      "auroc": 0.5652083333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        },
        "0.01": null
      },
      "auroc": 0.8108333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 135,
          "accuracy": 0.325
        },
        "0.01": null
      },
      "auroc": 0.6533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 193,
          "fn": 207,
          "accuracy": 0.4825
        },
        "0.01": null
      },
      "auroc": 0.7320833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 141,
          "fn": 59,
          "accuracy": 0.705
        },
        "0.01": null
      },
      "auroc": 0.8433333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": null
      },
      "auroc": 0.5533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 234,
          "accuracy": 0.415
        },
        "0.01": null
      },
      "auroc": 0.6983333333333335
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 269,
          "fn": 131,
          "accuracy": 0.6725
        },
        "0.01": null
      },
      "auroc": 0.8270833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 310,
          "accuracy": 0.225
        },
        "0.01": null
      },
      "auroc": 0.6033333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 359,
          "fn": 441,
          "accuracy": 0.44875
        },
        "0.01": null
      },
      "auroc": 0.7152083333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": null
      },
      "auroc": 0.5608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": null
      },
      "auroc": 0.6558333333333335
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 94,
          "fn": 306,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 149,
          "accuracy": 0.255
        },
        "0.01": null
      },
      "auroc": 0.6183333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        },
        "0.01": null
      },
      "auroc": 0.5708333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        },
        "0.01": null
      },
      "auroc": 0.5895833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        },
        "0.01": null
      },
      "auroc": 0.5895833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 158,
          "fn": 642,
          "accuracy": 0.1975
        },
        "0.01": null
      },
      "auroc": 0.5895833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": null
      },
      "auroc": 0.6583333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": null
      },
      "auroc": 0.5183333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 322,
          "accuracy": 0.195
        },
        "0.01": null
      },
      "auroc": 0.5883333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": null
      },
      "auroc": 0.5633333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        },
        "0.01": null
      },
      "auroc": 0.5320833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 96,
          "fn": 304,
          "accuracy": 0.24
        },
        "0.01": null
      },
      "auroc": 0.6108333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 385,
          "accuracy": 0.0375
        },
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 689,
          "accuracy": 0.13875
        },
        "0.01": null
      },
      "auroc": 0.5602083333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": null
      },
      "auroc": 0.7608333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 214,
          "accuracy": 0.465
        },
        "0.01": null
      },
      "auroc": 0.7233333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 94,
          "fn": 106,
          "accuracy": 0.47
        },
        "0.01": null
      },
      "auroc": 0.7258333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 42,
          "fn": 158,
          "accuracy": 0.21
        },
        "0.01": null
      },
      "auroc": 0.5958333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 264,
          "accuracy": 0.34
        },
        "0.01": null
      },
      "auroc": 0.6608333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 202,
          "fn": 198,
          "accuracy": 0.505
        },
        "0.01": null
      },
      "auroc": 0.7433333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 280,
          "accuracy": 0.3
        },
        "0.01": null
      },
      "auroc": 0.6408333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 322,
          "fn": 478,
          "accuracy": 0.4025
        },
        "0.01": null
      },
      "auroc": 0.6920833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 115,
          "fn": 85,
          "accuracy": 0.575
        },
        "0.01": null
      },
      "auroc": 0.7783333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 115,
          "fn": 85,
          "accuracy": 0.575
        },
        "0.01": null
      },
      "auroc": 0.7783333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": null
      },
      "auroc": 0.7708333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": null
      },
      "auroc": 0.7708333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 227,
          "fn": 173,
          "accuracy": 0.5675
        },
        "0.01": null
      },
      "auroc": 0.7745833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 227,
          "fn": 173,
          "accuracy": 0.5675
        },
        "0.01": null
      },
      "auroc": 0.7745833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 144,
          "accuracy": 0.28
        },
        "0.01": null
      },
      "auroc": 0.6308333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 144,
          "accuracy": 0.28
        },
        "0.01": null
      },
      "auroc": 0.6308333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 52,
          "fn": 148,
          "accuracy": 0.26
        },
        "0.01": null
      },
      "auroc": 0.6208333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 52,
          "fn": 148,
          "accuracy": 0.26
        },
        "0.01": null
      },
      "auroc": 0.6208333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": null
      },
      "auroc": 0.6258333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": null
      },
      "auroc": 0.6258333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        },
        "0.01": null
      },
      "auroc": 0.7358333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        },
        "0.01": null
      },
      "auroc": 0.7358333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": null
      },
      "auroc": 0.6908333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": null
      },
      "auroc": 0.6908333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        },
        "0.01": null
      },
      "auroc": 0.7133333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        },
        "0.01": null
      },
      "auroc": 0.7133333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": null
      },
      "auroc": 0.7733333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": null
      },
      "auroc": 0.7733333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": null
      },
      "auroc": 0.5983333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": null
      },
      "auroc": 0.5983333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 244,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 244,
          "accuracy": 0.39
        },
        "0.01": null
      },
      "auroc": 0.6858333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 95,
          "fn": 105,
          "accuracy": 0.475
        },
        "0.01": null
      },
      "auroc": 0.7283333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 95,
          "fn": 105,
          "accuracy": 0.475
        },
        "0.01": null
      },
      "auroc": 0.7283333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": null
      },
      "auroc": 0.6933333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": null
      },
      "auroc": 0.6933333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 224,
          "accuracy": 0.44
        },
        "0.01": null
      },
      "auroc": 0.7108333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 224,
          "accuracy": 0.44
        },
        "0.01": null
      },
      "auroc": 0.7108333333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1052,
          "fn": 1148,
          "accuracy": 0.4781818181818182
        },
        "0.01": null
      },
      "auroc": 0.7299242424242425
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 382,
          "fn": 818,
          "accuracy": 0.31833333333333336
        },
        "0.01": null
      },
      "auroc": 0.65
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1434,
          "fn": 1966,
          "accuracy": 0.42176470588235293
        },
        "0.01": null
      },
      "auroc": 0.70171568627451
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 888,
          "fn": 1312,
          "accuracy": 0.4036363636363636
        },
        "0.01": null
      },
      "auroc": 0.6926515151515151
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 244,
          "fn": 956,
          "accuracy": 0.20333333333333334
        },
        "0.01": null
      },
      "auroc": 0.5925
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1132,
          "fn": 2268,
          "accuracy": 0.33294117647058824
        },
        "0.01": null
      },
      "auroc": 0.6573039215686275
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1940,
          "fn": 2460,
          "accuracy": 0.4409090909090909
        },
        "0.01": null
      },
      "auroc": 0.7112878787878789
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 626,
          "fn": 1774,
          "accuracy": 0.2608333333333333
        },
        "0.01": null
      },
      "auroc": 0.62125
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 2566,
          "fn": 4234,
          "accuracy": 0.3773529411764706
        },
        "0.01": null
      },
      "auroc": 0.6795098039215687
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 162,
          "fn": 38,
          "accuracy": 0.81
        },
        "0.01": null
      },
      "auroc": 0.8958333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 43,
          "accuracy": 0.785
        },
        "0.01": null
      },
      "auroc": 0.8833333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 319,
          "fn": 81,
          "accuracy": 0.7975
        },
        "0.01": null
      },
      "auroc": 0.8895833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        },
        "0.01": null
      },
      "auroc": 0.9108333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 162,
          "fn": 38,
          "accuracy": 0.81
        },
        "0.01": null
      },
      "auroc": 0.8958333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 330,
          "fn": 70,
          "accuracy": 0.825
        },
        "0.01": null
      },
      "auroc": 0.9033333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 330,
          "fn": 70,
          "accuracy": 0.825
        },
        "0.01": null
      },
      "auroc": 0.9033333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 319,
          "fn": 81,
          "accuracy": 0.7975
        },
        "0.01": null
      },
      "auroc": 0.8895833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 649,
          "fn": 151,
          "accuracy": 0.81125
        },
        "0.01": null
      },
      "auroc": 0.8964583333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": null
      },
      "auroc": 0.6933333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": null
      },
      "auroc": 0.5508333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 295,
          "accuracy": 0.2625
        },
        "0.01": null
      },
      "auroc": 0.6220833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 135,
          "accuracy": 0.325
        },
        "0.01": null
      },
      "auroc": 0.6533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 26,
          "fn": 174,
          "accuracy": 0.13
        },
        "0.01": null
      },
      "auroc": 0.5558333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        },
        "0.01": null
      },
      "auroc": 0.6045833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 146,
          "fn": 254,
          "accuracy": 0.365
        },
        "0.01": null
      },
      "auroc": 0.6733333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 50,
          "fn": 350,
          "accuracy": 0.125
        },
        "0.01": null
      },
      "auroc": 0.5533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 196,
          "fn": 604,
          "accuracy": 0.245
        },
        "0.01": null
      },
      "auroc": 0.6133333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 177,
          "fn": 23,
          "accuracy": 0.885
        },
        "0.01": null
      },
      "auroc": 0.9333333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 142,
          "fn": 58,
          "accuracy": 0.71
        },
        "0.01": null
      },
      "auroc": 0.8458333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 319,
          "fn": 81,
          "accuracy": 0.7975
        },
        "0.01": null
      },
      "auroc": 0.8895833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        },
        "0.01": null
      },
      "auroc": 0.9358333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 97,
          "fn": 103,
          "accuracy": 0.485
        },
        "0.01": null
      },
      "auroc": 0.7333333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 275,
          "fn": 125,
          "accuracy": 0.6875
        },
        "0.01": null
      },
      "auroc": 0.8345833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 355,
          "fn": 45,
          "accuracy": 0.8875
        },
        "0.01": null
      },
      "auroc": 0.9345833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 239,
          "fn": 161,
          "accuracy": 0.5975
        },
        "0.01": null
      },
      "auroc": 0.7895833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 594,
          "fn": 206,
          "accuracy": 0.7425
        },
        "0.01": null
      },
      "auroc": 0.8620833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 151,
          "accuracy": 0.245
        },
        "0.01": null
      },
      "auroc": 0.6133333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        },
        "0.01": null
      },
      "auroc": 0.9058333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 215,
          "fn": 185,
          "accuracy": 0.5375
        },
        "0.01": null
      },
      "auroc": 0.7595833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        },
        "0.01": null
      },
      "auroc": 0.7408333333333335
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 63,
          "fn": 137,
          "accuracy": 0.315
        },
        "0.01": null
      },
      "auroc": 0.6483333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 163,
          "fn": 237,
          "accuracy": 0.4075
        },
        "0.01": null
      },
      "auroc": 0.6945833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 149,
          "fn": 251,
          "accuracy": 0.3725
        },
        "0.01": null
      },
      "auroc": 0.6770833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 229,
          "fn": 171,
          "accuracy": 0.5725
        },
        "0.01": null
      },
      "auroc": 0.7770833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 378,
          "fn": 422,
          "accuracy": 0.4725
        },
        "0.01": null
      },
      "auroc": 0.7270833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 89,
          "fn": 111,
          "accuracy": 0.445
        },
        "0.01": null
      },
      "auroc": 0.7133333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        },
        "0.01": null
      },
      "auroc": 0.7533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 194,
          "fn": 206,
          "accuracy": 0.485
        },
        "0.01": null
      },
      "auroc": 0.7333333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        },
        "0.01": null
      },
      "auroc": 0.6383333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": null
      },
      "auroc": 0.5758333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 307,
          "accuracy": 0.2325
        },
        "0.01": null
      },
      "auroc": 0.6070833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 148,
          "fn": 252,
          "accuracy": 0.37
        },
        "0.01": null
      },
      "auroc": 0.6758333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        },
        "0.01": null
      },
      "auroc": 0.6645833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 287,
          "fn": 513,
          "accuracy": 0.35875
        },
        "0.01": null
      },
      "auroc": 0.6702083333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 159,
          "fn": 41,
          "accuracy": 0.795
        },
        "0.01": null
      },
      "auroc": 0.8883333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 146,
          "fn": 54,
          "accuracy": 0.73
        },
        "0.01": null
      },
      "auroc": 0.8558333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 305,
          "fn": 95,
          "accuracy": 0.7625
        },
        "0.01": null
      },
      "auroc": 0.8720833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 147,
          "fn": 53,
          "accuracy": 0.735
        },
        "0.01": null
      },
      "auroc": 0.8583333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 114,
          "fn": 86,
          "accuracy": 0.57
        },
        "0.01": null
      },
      "auroc": 0.7758333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 261,
          "fn": 139,
          "accuracy": 0.6525
        },
        "0.01": null
      },
      "auroc": 0.8170833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 306,
          "fn": 94,
          "accuracy": 0.765
        },
        "0.01": null
      },
      "auroc": 0.8733333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 260,
          "fn": 140,
          "accuracy": 0.65
        },
        "0.01": null
      },
      "auroc": 0.8158333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 566,
          "fn": 234,
          "accuracy": 0.7075
        },
        "0.01": null
      },
      "auroc": 0.8445833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 164,
          "fn": 36,
          "accuracy": 0.82
        },
        "0.01": null
      },
      "auroc": 0.9008333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 164,
          "fn": 36,
          "accuracy": 0.82
        },
        "0.01": null
      },
      "auroc": 0.9008333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 152,
          "fn": 48,
          "accuracy": 0.76
        },
        "0.01": null
      },
      "auroc": 0.8708333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 152,
          "fn": 48,
          "accuracy": 0.76
        },
        "0.01": null
      },
      "auroc": 0.8708333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 316,
          "fn": 84,
          "accuracy": 0.79
        },
        "0.01": null
      },
      "auroc": 0.8858333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 316,
          "fn": 84,
          "accuracy": 0.79
        },
        "0.01": null
      },
      "auroc": 0.8858333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 151,
          "fn": 49,
          "accuracy": 0.755
        },
        "0.01": null
      },
      "auroc": 0.8683333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 151,
          "fn": 49,
          "accuracy": 0.755
        },
        "0.01": null
      },
      "auroc": 0.8683333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 64,
          "accuracy": 0.68
        },
        "0.01": null
      },
      "auroc": 0.8308333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 64,
          "accuracy": 0.68
        },
        "0.01": null
      },
      "auroc": 0.8308333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 287,
          "fn": 113,
          "accuracy": 0.7175
        },
        "0.01": null
      },
      "auroc": 0.8495833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 287,
          "fn": 113,
          "accuracy": 0.7175
        },
        "0.01": null
      },
      "auroc": 0.8495833333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 164,
          "fn": 36,
          "accuracy": 0.82
        },
        "0.01": null
      },
      "auroc": 0.9008333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 164,
          "fn": 36,
          "accuracy": 0.82
        },
        "0.01": null
      },
      "auroc": 0.9008333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        },
        "0.01": null
      },
      "auroc": 0.9033333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        },
        "0.01": null
      },
      "auroc": 0.9033333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        },
        "0.01": null
      },
      "auroc": 0.9020833333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        },
        "0.01": null
      },
      "auroc": 0.9020833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 174,
          "fn": 26,
          "accuracy": 0.87
        },
        "0.01": null
      },
      "auroc": 0.9258333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 174,
          "fn": 26,
          "accuracy": 0.87
        },
        "0.01": null
      },
      "auroc": 0.9258333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 153,
          "fn": 47,
          "accuracy": 0.765
        },
        "0.01": null
      },
      "auroc": 0.8733333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 153,
          "fn": 47,
          "accuracy": 0.765
        },
        "0.01": null
      },
      "auroc": 0.8733333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 327,
          "fn": 73,
          "accuracy": 0.8175
        },
        "0.01": null
      },
      "auroc": 0.8995833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 327,
          "fn": 73,
          "accuracy": 0.8175
        },
        "0.01": null
      },
      "auroc": 0.8995833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        },
        "0.01": null
      },
      "auroc": 0.8858333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        },
        "0.01": null
      },
      "auroc": 0.8858333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 149,
          "fn": 51,
          "accuracy": 0.745
        },
        "0.01": null
      },
      "auroc": 0.8633333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 149,
          "fn": 51,
          "accuracy": 0.745
        },
        "0.01": null
      },
      "auroc": 0.8633333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 307,
          "fn": 93,
          "accuracy": 0.7675
        },
        "0.01": null
      },
      "auroc": 0.8745833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 307,
          "fn": 93,
          "accuracy": 0.7675
        },
        "0.01": null
      },
      "auroc": 0.8745833333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 1528,
          "fn": 672,
          "accuracy": 0.6945454545454546
        },
        "0.01": null
      },
      "auroc": 0.8381060606060606
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 740,
          "fn": 460,
          "accuracy": 0.6166666666666667
        },
        "0.01": null
      },
      "auroc": 0.7991666666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 2268,
          "fn": 1132,
          "accuracy": 0.6670588235294118
        },
        "0.01": null
      },
      "auroc": 0.8243627450980392
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 1472,
          "fn": 728,
          "accuracy": 0.6690909090909091
        },
        "0.01": null
      },
      "auroc": 0.8253787878787878
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 496,
          "fn": 704,
          "accuracy": 0.41333333333333333
        },
        "0.01": null
      },
      "auroc": 0.6975
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 1968,
          "fn": 1432,
          "accuracy": 0.5788235294117647
        },
        "0.01": null
      },
      "auroc": 0.7802450980392157
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 3000,
          "fn": 1400,
          "accuracy": 0.6818181818181818
        },
        "0.01": null
      },
      "auroc": 0.8317424242424242
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 1236,
          "fn": 1164,
          "accuracy": 0.515
        },
        "0.01": null
      },
      "auroc": 0.7483333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 4236,
          "fn": 2564,
          "accuracy": 0.6229411764705882
        },
        "0.01": null
      },
      "auroc": 0.8023039215686275
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        },
        "0.01": null
      },
      "auroc": 0.4995833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        },
        "0.01": null
      },
      "auroc": 0.4995833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 791,
          "accuracy": 0.01125
        },
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        },
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        },
        "0.01": null
      },
      "auroc": 0.4995833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 394,
          "accuracy": 0.015
        },
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 793,
          "accuracy": 0.00875
        },
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 799,
          "accuracy": 0.00125
        },
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 799,
          "accuracy": 0.00125
        },
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        },
        "0.01": null
      },
      "auroc": 0.4945833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        },
        "0.01": null
      },
      "auroc": 0.4945833333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 2198,
          "accuracy": 0.0009090909090909091
        },
        "0.01": null
      },
      "auroc": 0.49128787878787883
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 1198,
          "accuracy": 0.0016666666666666668
        },
        "0.01": null
      },
      "auroc": 0.4916666666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 3396,
          "accuracy": 0.001176470588235294
        },
        "0.01": null
      },
      "auroc": 0.491421568627451
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 2195,
          "accuracy": 0.0022727272727272726
        },
        "0.01": null
      },
      "auroc": 0.49196969696969695
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 1188,
          "accuracy": 0.01
        },
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 3383,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 4393,
          "accuracy": 0.001590909090909091
        },
        "0.01": null
      },
      "auroc": 0.49162878787878794
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 2386,
          "accuracy": 0.005833333333333334
        },
        "0.01": null
      },
      "auroc": 0.49375
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 6779,
          "accuracy": 0.003088235294117647
        },
        "0.01": null
      },
      "auroc": 0.4923774509803922
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        },
        "0.01": null
      },
      "auroc": 0.9108333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 146,
          "fn": 54,
          "accuracy": 0.73
        },
        "0.01": null
      },
      "auroc": 0.8558333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        },
        "0.01": null
      },
      "auroc": 0.8833333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 43,
          "accuracy": 0.785
        },
        "0.01": null
      },
      "auroc": 0.8833333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 129,
          "fn": 71,
          "accuracy": 0.645
        },
        "0.01": null
      },
      "auroc": 0.8133333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 286,
          "fn": 114,
          "accuracy": 0.715
        },
        "0.01": null
      },
      "auroc": 0.8483333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 325,
          "fn": 75,
          "accuracy": 0.8125
        },
        "0.01": null
      },
      "auroc": 0.8970833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 275,
          "fn": 125,
          "accuracy": 0.6875
        },
        "0.01": null
      },
      "auroc": 0.8345833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 600,
          "fn": 200,
          "accuracy": 0.75
        },
        "0.01": null
      },
      "auroc": 0.8658333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 52,
          "fn": 148,
          "accuracy": 0.26
        },
        "0.01": null
      },
      "auroc": 0.6208333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 343,
          "accuracy": 0.1425
        },
        "0.01": null
      },
      "auroc": 0.5620833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": null
      },
      "auroc": 0.5458333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 365,
          "accuracy": 0.0875
        },
        "0.01": null
      },
      "auroc": 0.5345833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 326,
          "accuracy": 0.185
        },
        "0.01": null
      },
      "auroc": 0.5833333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 382,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 708,
          "accuracy": 0.115
        },
        "0.01": null
      },
      "auroc": 0.5483333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 96,
          "fn": 104,
          "accuracy": 0.48
        },
        "0.01": null
      },
      "auroc": 0.7308333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 54,
          "fn": 146,
          "accuracy": 0.27
        },
        "0.01": null
      },
      "auroc": 0.6258333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        },
        "0.01": null
      },
      "auroc": 0.6783333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        },
        "0.01": null
      },
      "auroc": 0.7358333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 16,
          "fn": 184,
          "accuracy": 0.08
        },
        "0.01": null
      },
      "auroc": 0.5308333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 114,
          "fn": 286,
          "accuracy": 0.285
        },
        "0.01": null
      },
      "auroc": 0.6333333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 194,
          "fn": 206,
          "accuracy": 0.485
        },
        "0.01": null
      },
      "auroc": 0.7333333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        },
        "0.01": null
      },
      "auroc": 0.5783333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 264,
          "fn": 536,
          "accuracy": 0.33
        },
        "0.01": null
      },
      "auroc": 0.6558333333333335
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": null
      },
      "auroc": 0.5683333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": null
      },
      "auroc": 0.5983333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 326,
          "accuracy": 0.185
        },
        "0.01": null
      },
      "auroc": 0.5833333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": null
      },
      "auroc": 0.5808333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 351,
          "accuracy": 0.1225
        },
        "0.01": null
      },
      "auroc": 0.5520833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 333,
          "accuracy": 0.1675
        },
        "0.01": null
      },
      "auroc": 0.5745833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        },
        "0.01": null
      },
      "auroc": 0.5608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 677,
          "accuracy": 0.15375
        },
        "0.01": null
      },
      "auroc": 0.5677083333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 52,
          "fn": 148,
          "accuracy": 0.26
        },
        "0.01": null
      },
      "auroc": 0.6208333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 343,
          "accuracy": 0.1425
        },
        "0.01": null
      },
      "auroc": 0.5620833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        },
        "0.01": null
      },
      "auroc": 0.5483333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 373,
          "accuracy": 0.0675
        },
        "0.01": null
      },
      "auroc": 0.5245833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 75,
          "fn": 325,
          "accuracy": 0.1875
        },
        "0.01": null
      },
      "auroc": 0.5845833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 391,
          "accuracy": 0.0225
        },
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 716,
          "accuracy": 0.105
        },
        "0.01": null
      },
      "auroc": 0.5433333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 68,
          "fn": 132,
          "accuracy": 0.34
        },
        "0.01": null
      },
      "auroc": 0.6608333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 144,
          "accuracy": 0.28
        },
        "0.01": null
      },
      "auroc": 0.6308333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 124,
          "fn": 276,
          "accuracy": 0.31
        },
        "0.01": null
      },
      "auroc": 0.6458333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 129,
          "accuracy": 0.355
        },
        "0.01": null
      },
      "auroc": 0.6683333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 26,
          "fn": 174,
          "accuracy": 0.13
        },
        "0.01": null
      },
      "auroc": 0.5558333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 97,
          "fn": 303,
          "accuracy": 0.2425
        },
        "0.01": null
      },
      "auroc": 0.6120833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        },
        "0.01": null
      },
      "auroc": 0.6645833333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 318,
          "accuracy": 0.205
        },
        "0.01": null
      },
      "auroc": 0.5933333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 221,
          "fn": 579,
          "accuracy": 0.27625
        },
        "0.01": null
      },
      "auroc": 0.6289583333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": null
      },
      "auroc": 0.7233333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": null
      },
      "auroc": 0.7233333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        },
        "0.01": null
      },
      "auroc": 0.6983333333333335
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        },
        "0.01": null
      },
      "auroc": 0.6983333333333335
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 224,
          "accuracy": 0.44
        },
        "0.01": null
      },
      "auroc": 0.7108333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 224,
          "accuracy": 0.44
        },
        "0.01": null
      },
      "auroc": 0.7108333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        },
        "0.01": null
      },
      "auroc": 0.5833333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        },
        "0.01": null
      },
      "auroc": 0.5833333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": null
      },
      "auroc": 0.5808333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": null
      },
      "auroc": 0.5808333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        },
        "0.01": null
      },
      "auroc": 0.5820833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        },
        "0.01": null
      },
      "auroc": 0.5820833333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        },
        "0.01": null
      },
      "auroc": 0.6108333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        },
        "0.01": null
      },
      "auroc": 0.6108333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        },
        "0.01": null
      },
      "auroc": 0.5908333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        },
        "0.01": null
      },
      "auroc": 0.5908333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 312,
          "accuracy": 0.22
        },
        "0.01": null
      },
      "auroc": 0.6008333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 312,
          "accuracy": 0.22
        },
        "0.01": null
      },
      "auroc": 0.6008333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": null
      },
      "auroc": 0.6583333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": null
      },
      "auroc": 0.6583333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        },
        "0.01": null
      },
      "auroc": 0.5333333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        },
        "0.01": null
      },
      "auroc": 0.5333333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 316,
          "accuracy": 0.21
        },
        "0.01": null
      },
      "auroc": 0.5958333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 316,
          "accuracy": 0.21
        },
        "0.01": null
      },
      "auroc": 0.5958333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 61,
          "fn": 139,
          "accuracy": 0.305
        },
        "0.01": null
      },
      "auroc": 0.6433333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 61,
          "fn": 139,
          "accuracy": 0.305
        },
        "0.01": null
      },
      "auroc": 0.6433333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 153,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 153,
          "accuracy": 0.235
        },
        "0.01": null
      },
      "auroc": 0.6083333333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": null
      },
      "auroc": 0.6258333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": null
      },
      "auroc": 0.6258333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 773,
          "fn": 1427,
          "accuracy": 0.3513636363636364
        },
        "0.01": null
      },
      "auroc": 0.6665151515151515
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 309,
          "fn": 891,
          "accuracy": 0.2575
        },
        "0.01": null
      },
      "auroc": 0.6195833333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1082,
          "fn": 2318,
          "accuracy": 0.31823529411764706
        },
        "0.01": null
      },
      "auroc": 0.6499509803921569
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 630,
          "fn": 1570,
          "accuracy": 0.2863636363636364
        },
        "0.01": null
      },
      "auroc": 0.6340151515151515
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 201,
          "fn": 999,
          "accuracy": 0.1675
        },
        "0.01": null
      },
      "auroc": 0.5745833333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 831,
          "fn": 2569,
          "accuracy": 0.24441176470588236
        },
        "0.01": null
      },
      "auroc": 0.6130392156862745
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1403,
          "fn": 2997,
          "accuracy": 0.31886363636363635
        },
        "0.01": null
      },
      "auroc": 0.6502651515151515
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 510,
          "fn": 1890,
          "accuracy": 0.2125
        },
        "0.01": null
      },
      "auroc": 0.5970833333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1913,
          "fn": 4887,
          "accuracy": 0.2813235294117647
        },
        "0.01": null
      },
      "auroc": 0.6314950980392157
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        },
        "0.01": null
      },
      "auroc": 0.9283333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 43,
          "accuracy": 0.785
        },
        "0.01": null
      },
      "auroc": 0.8833333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 332,
          "fn": 68,
          "accuracy": 0.83
        },
        "0.01": null
      },
      "auroc": 0.9058333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": null
      },
      "auroc": 0.9233333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        },
        "0.01": null
      },
      "auroc": 0.8508333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 317,
          "fn": 83,
          "accuracy": 0.7925
        },
        "0.01": null
      },
      "auroc": 0.8870833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 348,
          "fn": 52,
          "accuracy": 0.87
        },
        "0.01": null
      },
      "auroc": 0.9258333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        },
        "0.01": null
      },
      "auroc": 0.8670833333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 649,
          "fn": 151,
          "accuracy": 0.81125
        },
        "0.01": null
      },
      "auroc": 0.8964583333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": null
      },
      "auroc": 0.6583333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 72,
          "fn": 328,
          "accuracy": 0.18
        },
        "0.01": null
      },
      "auroc": 0.5808333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": null
      },
      "auroc": 0.5633333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 42,
          "fn": 358,
          "accuracy": 0.105
        },
        "0.01": null
      },
      "auroc": 0.5433333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 96,
          "fn": 304,
          "accuracy": 0.24
        },
        "0.01": null
      },
      "auroc": 0.6108333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 382,
          "accuracy": 0.045
        },
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 114,
          "fn": 686,
          "accuracy": 0.1425
        },
        "0.01": null
      },
      "auroc": 0.5620833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 127,
          "fn": 73,
          "accuracy": 0.635
        },
        "0.01": null
      },
      "auroc": 0.8083333333333335
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 135,
          "accuracy": 0.325
        },
        "0.01": null
      },
      "auroc": 0.6533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 192,
          "fn": 208,
          "accuracy": 0.48
        },
        "0.01": null
      },
      "auroc": 0.7308333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 139,
          "fn": 61,
          "accuracy": 0.695
        },
        "0.01": null
      },
      "auroc": 0.8383333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": null
      },
      "auroc": 0.5508333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 163,
          "fn": 237,
          "accuracy": 0.4075
        },
        "0.01": null
      },
      "auroc": 0.6945833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        },
        "0.01": null
      },
      "auroc": 0.8233333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 89,
          "fn": 311,
          "accuracy": 0.2225
        },
        "0.01": null
      },
      "auroc": 0.6020833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 355,
          "fn": 445,
          "accuracy": 0.44375
        },
        "0.01": null
      },
      "auroc": 0.7127083333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": null
      },
      "auroc": 0.5583333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        },
        "0.01": null
      },
      "auroc": 0.6508333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        },
        "0.01": null
      },
      "auroc": 0.6045833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 50,
          "fn": 150,
          "accuracy": 0.25
        },
        "0.01": null
      },
      "auroc": 0.6158333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": null
      },
      "auroc": 0.5233333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        },
        "0.01": null
      },
      "auroc": 0.5695833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 77,
          "fn": 323,
          "accuracy": 0.1925
        },
        "0.01": null
      },
      "auroc": 0.5870833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 77,
          "fn": 323,
          "accuracy": 0.1925
        },
        "0.01": null
      },
      "auroc": 0.5870833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 154,
          "fn": 646,
          "accuracy": 0.1925
        },
        "0.01": null
      },
      "auroc": 0.5870833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": null
      },
      "auroc": 0.6558333333333335
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": null
      },
      "auroc": 0.5158333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 76,
          "fn": 324,
          "accuracy": 0.19
        },
        "0.01": null
      },
      "auroc": 0.5858333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": null
      },
      "auroc": 0.5583333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        },
        "0.01": null
      },
      "auroc": 0.5295833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 307,
          "accuracy": 0.2325
        },
        "0.01": null
      },
      "auroc": 0.6070833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 386,
          "accuracy": 0.035
        },
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 693,
          "accuracy": 0.13375
        },
        "0.01": null
      },
      "auroc": 0.5577083333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 102,
          "fn": 98,
          "accuracy": 0.51
        },
        "0.01": null
      },
      "auroc": 0.7458333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 126,
          "accuracy": 0.37
        },
        "0.01": null
      },
      "auroc": 0.6758333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 224,
          "accuracy": 0.44
        },
        "0.01": null
      },
      "auroc": 0.7108333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        },
        "0.01": null
      },
      "auroc": 0.7158333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        },
        "0.01": null
      },
      "auroc": 0.5908333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 270,
          "accuracy": 0.325
        },
        "0.01": null
      },
      "auroc": 0.6533333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 192,
          "fn": 208,
          "accuracy": 0.48
        },
        "0.01": null
      },
      "auroc": 0.7308333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 114,
          "fn": 286,
          "accuracy": 0.285
        },
        "0.01": null
      },
      "auroc": 0.6333333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 306,
          "fn": 494,
          "accuracy": 0.3825
        },
        "0.01": null
      },
      "auroc": 0.6820833333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": null
      },
      "auroc": 0.7708333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": null
      },
      "auroc": 0.7708333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": null
      },
      "auroc": 0.7583333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": null
      },
      "auroc": 0.7583333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 219,
          "fn": 181,
          "accuracy": 0.5475
        },
        "0.01": null
      },
      "auroc": 0.7645833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 219,
          "fn": 181,
          "accuracy": 0.5475
        },
        "0.01": null
      },
      "auroc": 0.7645833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 144,
          "accuracy": 0.28
        },
        "0.01": null
      },
      "auroc": 0.6308333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 144,
          "accuracy": 0.28
        },
        "0.01": null
      },
      "auroc": 0.6308333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 151,
          "accuracy": 0.245
        },
        "0.01": null
      },
      "auroc": 0.6133333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 151,
          "accuracy": 0.245
        },
        "0.01": null
      },
      "auroc": 0.6133333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 295,
          "accuracy": 0.2625
        },
        "0.01": null
      },
      "auroc": 0.6220833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 295,
          "accuracy": 0.2625
        },
        "0.01": null
      },
      "auroc": 0.6220833333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": null
      },
      "auroc": 0.7183333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": null
      },
      "auroc": 0.7183333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 77,
          "fn": 123,
          "accuracy": 0.385
        },
        "0.01": null
      },
      "auroc": 0.6833333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 77,
          "fn": 123,
          "accuracy": 0.385
        },
        "0.01": null
      },
      "auroc": 0.6833333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 232,
          "accuracy": 0.42
        },
        "0.01": null
      },
      "auroc": 0.7008333333333333
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 232,
          "accuracy": 0.42
        },
        "0.01": null
      },
      "auroc": 0.7008333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": null
      },
      "auroc": 0.7608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": null
      },
      "auroc": 0.7608333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        },
        "0.01": null
      },
      "auroc": 0.5783333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        },
        "0.01": null
      },
      "auroc": 0.5783333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 143,
          "fn": 257,
          "accuracy": 0.3575
        },
        "0.01": null
      },
      "auroc": 0.6695833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 143,
          "fn": 257,
          "accuracy": 0.3575
        },
        "0.01": null
      },
      "auroc": 0.6695833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": null
      },
      "auroc": 0.7183333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": null
      },
      "auroc": 0.7183333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        },
        "0.01": null
      },
      "auroc": 0.6658333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        },
        "0.01": null
      },
      "auroc": 0.6658333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 161,
          "fn": 239,
          "accuracy": 0.4025
        },
        "0.01": null
      },
      "auroc": 0.6920833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 161,
          "fn": 239,
          "accuracy": 0.4025
        },
        "0.01": null
      },
      "auroc": 0.6920833333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1022,
          "fn": 1178,
          "accuracy": 0.46454545454545454
        },
        "0.01": null
      },
      "auroc": 0.7231060606060606
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 375,
          "fn": 825,
          "accuracy": 0.3125
        },
        "0.01": null
      },
      "auroc": 0.6470833333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1397,
          "fn": 2003,
          "accuracy": 0.4108823529411765
        },
        "0.01": null
      },
      "auroc": 0.6962745098039216
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 846,
          "fn": 1354,
          "accuracy": 0.3845454545454545
        },
        "0.01": null
      },
      "auroc": 0.6831060606060606
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 238,
          "fn": 962,
          "accuracy": 0.19833333333333333
        },
        "0.01": null
      },
      "auroc": 0.59
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1084,
          "fn": 2316,
          "accuracy": 0.31882352941176473
        },
        "0.01": null
      },
      "auroc": 0.6502450980392157
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1868,
          "fn": 2532,
          "accuracy": 0.42454545454545456
        },
        "0.01": null
      },
      "auroc": 0.7031060606060606
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 613,
          "fn": 1787,
          "accuracy": 0.2554166666666667
        },
        "0.01": null
      },
      "auroc": 0.6185416666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 2481,
          "fn": 4319,
          "accuracy": 0.3648529411764706
        },
        "0.01": null
      },
      "auroc": 0.6732598039215686
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        },
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        },
        "0.01": null
      },
      "auroc": 0.4945833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        },
        "0.01": null
      },
      "auroc": 0.4945833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 797,
          "accuracy": 0.00375
        },
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 396,
          "accuracy": 0.01
        },
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 396,
          "accuracy": 0.01
        },
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 796,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 799,
          "accuracy": 0.00125
        },
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 2200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 1200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 3400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 2200,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 1192,
          "accuracy": 0.006666666666666667
        },
        "0.01": null
      },
      "auroc": 0.49416666666666664
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 3392,
          "accuracy": 0.002352941176470588
        },
        "0.01": null
      },
      "auroc": 0.4920098039215687
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 4400,
          "accuracy": 0.0
        },
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 2392,
          "accuracy": 0.0033333333333333335
        },
        "0.01": null
      },
      "auroc": 0.49250000000000005
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 6792,
          "accuracy": 0.001176470588235294
        },
        "0.01": null
      },
      "auroc": 0.491421568627451
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1585,
          "fn": 815,
          "accuracy": 0.6604166666666667
        },
        "0.01": null
      },
      "auroc": 0.8210416666666668
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1433,
          "fn": 967,
          "accuracy": 0.5970833333333333
        },
        "0.01": null
      },
      "auroc": 0.789375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3018,
          "fn": 1782,
          "accuracy": 0.62875
        },
        "0.01": null
      },
      "auroc": 0.8052083333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1550,
          "fn": 850,
          "accuracy": 0.6458333333333334
        },
        "0.01": null
      },
      "auroc": 0.8137500000000001
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1327,
          "fn": 1073,
          "accuracy": 0.5529166666666666
        },
        "0.01": null
      },
      "auroc": 0.7672916666666666
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2877,
          "fn": 1923,
          "accuracy": 0.599375
        },
        "0.01": null
      },
      "auroc": 0.7905208333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3135,
          "fn": 1665,
          "accuracy": 0.653125
        },
        "0.01": null
      },
      "auroc": 0.8173958333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2760,
          "fn": 2040,
          "accuracy": 0.575
        },
        "0.01": null
      },
      "auroc": 0.7783333333333333
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 5895,
          "fn": 3705,
          "accuracy": 0.6140625
        },
        "0.01": null
      },
      "auroc": 0.7978645833333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 606,
          "fn": 1794,
          "accuracy": 0.2525
        },
        "0.01": null
      },
      "auroc": 0.6170833333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 2319,
          "accuracy": 0.03375
        },
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 687,
          "fn": 4113,
          "accuracy": 0.143125
        },
        "0.01": null
      },
      "auroc": 0.5623958333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 305,
          "fn": 2095,
          "accuracy": 0.12708333333333333
        },
        "0.01": null
      },
      "auroc": 0.554375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 2232,
          "accuracy": 0.07
        },
        "0.01": null
      },
      "auroc": 0.5258333333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 473,
          "fn": 4327,
          "accuracy": 0.09854166666666667
        },
        "0.01": null
      },
      "auroc": 0.5401041666666667
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 911,
          "fn": 3889,
          "accuracy": 0.18979166666666666
        },
        "0.01": null
      },
      "auroc": 0.5857291666666666
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 249,
          "fn": 4551,
          "accuracy": 0.051875
        },
        "0.01": null
      },
      "auroc": 0.5167708333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1160,
          "fn": 8440,
          "accuracy": 0.12083333333333333
        },
        "0.01": null
      },
      "auroc": 0.55125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1162,
          "fn": 1238,
          "accuracy": 0.4841666666666667
        },
        "0.01": null
      },
      "auroc": 0.7329166666666667
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 677,
          "fn": 1723,
          "accuracy": 0.28208333333333335
        },
        "0.01": null
      },
      "auroc": 0.6318750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1839,
          "fn": 2961,
          "accuracy": 0.383125
        },
        "0.01": null
      },
      "auroc": 0.6823958333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1242,
          "fn": 1158,
          "accuracy": 0.5175
        },
        "0.01": null
      },
      "auroc": 0.7495833333333334
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 338,
          "fn": 2062,
          "accuracy": 0.14083333333333334
        },
        "0.01": null
      },
      "auroc": 0.56125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1580,
          "fn": 3220,
          "accuracy": 0.32916666666666666
        },
        "0.01": null
      },
      "auroc": 0.6554166666666666
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2404,
          "fn": 2396,
          "accuracy": 0.5008333333333334
        },
        "0.01": null
      },
      "auroc": 0.7412500000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1015,
          "fn": 3785,
          "accuracy": 0.21145833333333333
        },
        "0.01": null
      },
      "auroc": 0.5965625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3419,
          "fn": 6181,
          "accuracy": 0.35614583333333333
        },
        "0.01": null
      },
      "auroc": 0.66890625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 313,
          "fn": 2087,
          "accuracy": 0.13041666666666665
        },
        "0.01": null
      },
      "auroc": 0.5560416666666667
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 652,
          "fn": 1748,
          "accuracy": 0.27166666666666667
        },
        "0.01": null
      },
      "auroc": 0.6266666666666667
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 965,
          "fn": 3835,
          "accuracy": 0.20104166666666667
        },
        "0.01": null
      },
      "auroc": 0.5913541666666667
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 504,
          "fn": 1896,
          "accuracy": 0.21
        },
        "0.01": null
      },
      "auroc": 0.5958333333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 195,
          "fn": 2205,
          "accuracy": 0.08125
        },
        "0.01": null
      },
      "auroc": 0.5314583333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 699,
          "fn": 4101,
          "accuracy": 0.145625
        },
        "0.01": null
      },
      "auroc": 0.5636458333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 817,
          "fn": 3983,
          "accuracy": 0.17020833333333332
        },
        "0.01": null
      },
      "auroc": 0.5759375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 847,
          "fn": 3953,
          "accuracy": 0.17645833333333333
        },
        "0.01": null
      },
      "auroc": 0.5790625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1664,
          "fn": 7936,
          "accuracy": 0.17333333333333334
        },
        "0.01": null
      },
      "auroc": 0.5775
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 625,
          "fn": 1775,
          "accuracy": 0.2604166666666667
        },
        "0.01": null
      },
      "auroc": 0.6210416666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 203,
          "fn": 2197,
          "accuracy": 0.08458333333333333
        },
        "0.01": null
      },
      "auroc": 0.533125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 828,
          "fn": 3972,
          "accuracy": 0.1725
        },
        "0.01": null
      },
      "auroc": 0.5770833333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 297,
          "fn": 2103,
          "accuracy": 0.12375
        },
        "0.01": null
      },
      "auroc": 0.5527083333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 2318,
          "accuracy": 0.034166666666666665
        },
        "0.01": null
      },
      "auroc": 0.5079166666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 379,
          "fn": 4421,
          "accuracy": 0.07895833333333334
        },
        "0.01": null
      },
      "auroc": 0.5303125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 922,
          "fn": 3878,
          "accuracy": 0.19208333333333333
        },
        "0.01": null
      },
      "auroc": 0.586875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 285,
          "fn": 4515,
          "accuracy": 0.059375
        },
        "0.01": null
      },
      "auroc": 0.5205208333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1207,
          "fn": 8393,
          "accuracy": 0.12572916666666667
        },
        "0.01": null
      },
      "auroc": 0.5536979166666667
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 935,
          "fn": 1465,
          "accuracy": 0.38958333333333334
        },
        "0.01": null
      },
      "auroc": 0.6856250000000002
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 717,
          "fn": 1683,
          "accuracy": 0.29875
        },
        "0.01": null
      },
      "auroc": 0.6402083333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1652,
          "fn": 3148,
          "accuracy": 0.3441666666666667
        },
        "0.01": null
      },
      "auroc": 0.6629166666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 851,
          "fn": 1549,
          "accuracy": 0.3545833333333333
        },
        "0.01": null
      },
      "auroc": 0.668125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 432,
          "fn": 1968,
          "accuracy": 0.18
        },
        "0.01": null
      },
      "auroc": 0.5808333333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1283,
          "fn": 3517,
          "accuracy": 0.26729166666666665
        },
        "0.01": null
      },
      "auroc": 0.6244791666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1786,
          "fn": 3014,
          "accuracy": 0.3720833333333333
        },
        "0.01": null
      },
      "auroc": 0.676875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1149,
          "fn": 3651,
          "accuracy": 0.239375
        },
        "0.01": null
      },
      "auroc": 0.6105208333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2935,
          "fn": 6665,
          "accuracy": 0.30572916666666666
        },
        "0.01": null
      },
      "auroc": 0.6436979166666666
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1144,
          "fn": 1256,
          "accuracy": 0.4766666666666667
        },
        "0.01": null
      },
      "auroc": 0.7291666666666666
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1144,
          "fn": 1256,
          "accuracy": 0.4766666666666667
        },
        "0.01": null
      },
      "auroc": 0.7291666666666666
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1029,
          "fn": 1371,
          "accuracy": 0.42875
        },
        "0.01": null
      },
      "auroc": 0.7052083333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1029,
          "fn": 1371,
          "accuracy": 0.42875
        },
        "0.01": null
      },
      "auroc": 0.7052083333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2173,
          "fn": 2627,
          "accuracy": 0.4527083333333333
        },
        "0.01": null
      },
      "auroc": 0.7171875000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2173,
          "fn": 2627,
          "accuracy": 0.4527083333333333
        },
        "0.01": null
      },
      "auroc": 0.7171875000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 582,
          "fn": 1818,
          "accuracy": 0.2425
        },
        "0.01": null
      },
      "auroc": 0.6120833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 582,
          "fn": 1818,
          "accuracy": 0.2425
        },
        "0.01": null
      },
      "auroc": 0.6120833333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 537,
          "fn": 1863,
          "accuracy": 0.22375
        },
        "0.01": null
      },
      "auroc": 0.6027083333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 537,
          "fn": 1863,
          "accuracy": 0.22375
        },
        "0.01": null
      },
      "auroc": 0.6027083333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1119,
          "fn": 3681,
          "accuracy": 0.233125
        },
        "0.01": null
      },
      "auroc": 0.6073958333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1119,
          "fn": 3681,
          "accuracy": 0.233125
        },
        "0.01": null
      },
      "auroc": 0.6073958333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 842,
          "fn": 1558,
          "accuracy": 0.35083333333333333
        },
        "0.01": null
      },
      "auroc": 0.66625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 842,
          "fn": 1558,
          "accuracy": 0.35083333333333333
        },
        "0.01": null
      },
      "auroc": 0.66625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 738,
          "fn": 1662,
          "accuracy": 0.3075
        },
        "0.01": null
      },
      "auroc": 0.6445833333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 738,
          "fn": 1662,
          "accuracy": 0.3075
        },
        "0.01": null
      },
      "auroc": 0.6445833333333334
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1580,
          "fn": 3220,
          "accuracy": 0.32916666666666666
        },
        "0.01": null
      },
      "auroc": 0.6554166666666666
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1580,
          "fn": 3220,
          "accuracy": 0.32916666666666666
        },
        "0.01": null
      },
      "auroc": 0.6554166666666666
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 980,
          "fn": 1420,
          "accuracy": 0.4083333333333333
        },
        "0.01": null
      },
      "auroc": 0.695
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 980,
          "fn": 1420,
          "accuracy": 0.4083333333333333
        },
        "0.01": null
      },
      "auroc": 0.695
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 475,
          "fn": 1925,
          "accuracy": 0.19791666666666666
        },
        "0.01": null
      },
      "auroc": 0.5897916666666667
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 475,
          "fn": 1925,
          "accuracy": 0.19791666666666666
        },
        "0.01": null
      },
      "auroc": 0.5897916666666667
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1455,
          "fn": 3345,
          "accuracy": 0.303125
        },
        "0.01": null
      },
      "auroc": 0.6423958333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1455,
          "fn": 3345,
          "accuracy": 0.303125
        },
        "0.01": null
      },
      "auroc": 0.6423958333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 853,
          "fn": 1547,
          "accuracy": 0.35541666666666666
        },
        "0.01": null
      },
      "auroc": 0.6685416666666668
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 853,
          "fn": 1547,
          "accuracy": 0.35541666666666666
        },
        "0.01": null
      },
      "auroc": 0.6685416666666668
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 719,
          "fn": 1681,
          "accuracy": 0.2995833333333333
        },
        "0.01": null
      },
      "auroc": 0.640625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 719,
          "fn": 1681,
          "accuracy": 0.2995833333333333
        },
        "0.01": null
      },
      "auroc": 0.640625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1572,
          "fn": 3228,
          "accuracy": 0.3275
        },
        "0.01": null
      },
      "auroc": 0.6545833333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1572,
          "fn": 3228,
          "accuracy": 0.3275
        },
        "0.01": null
      },
      "auroc": 0.6545833333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 9627,
          "fn": 16773,
          "accuracy": 0.36465909090909093
        },
        "0.01": null
      },
      "auroc": 0.673162878787879
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3763,
          "fn": 10637,
          "accuracy": 0.26131944444444444
        },
        "0.01": null
      },
      "auroc": 0.6214930555555556
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 13390,
          "fn": 27410,
          "accuracy": 0.3281862745098039
        },
        "0.01": null
      },
      "auroc": 0.6549264705882354
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 8247,
          "fn": 18153,
          "accuracy": 0.31238636363636363
        },
        "0.01": null
      },
      "auroc": 0.6470265151515152
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2542,
          "fn": 11858,
          "accuracy": 0.17652777777777778
        },
        "0.01": null
      },
      "auroc": 0.5790972222222223
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 10789,
          "fn": 30011,
          "accuracy": 0.26443627450980395
        },
        "0.01": null
      },
      "auroc": 0.6230514705882353
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 17874,
          "fn": 34926,
          "accuracy": 0.33852272727272725
        },
        "0.01": null
      },
      "auroc": 0.6600946969696969
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 6305,
          "fn": 22495,
          "accuracy": 0.2189236111111111
        },
        "0.01": null
      },
      "auroc": 0.6002951388888889
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 24179,
          "fn": 57421,
          "accuracy": 0.29631127450980393
        },
        "0.01": null
      },
      "auroc": 0.6389889705882353
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9337500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9137500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9225000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9337500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9225000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9281250000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.52625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7275000000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6925
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7562500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5387500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6475
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7712500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5687500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.615
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6625000000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.55375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6687500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66125
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.55625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7225
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8975
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84125
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8600000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8875000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8700000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8912500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8912500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8762500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8762500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88375
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88375
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7637500000000002
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7637500000000002
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73375
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73375
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74875
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74875
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81375
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81375
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9162500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9162500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9050000000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9050000000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77375
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77375
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80625
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8264772727272727
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7054166666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78375
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7846590909090909
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6191666666666668
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7262500000000001
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8055681818181819
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6622916666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.755
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.90625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9087500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9162500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8975
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9137500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8925000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.903125
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6112500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44500000000000006
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5281250000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46625000000000005
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5275000000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5612500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5750000000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4625000000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6662500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6525000000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5425
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.615
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5800000000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5975
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6212500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5525
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.55375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45625000000000004
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.52875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8437500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.845
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7762500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7675000000000002
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8025
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7962500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7962500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7312500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7312500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7637500000000002
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7637500000000002
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58875
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58875
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6025
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6025
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.60375
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.60375
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6025
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6025
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7137500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7137500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68875
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68875
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70125
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70125
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6837500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6837500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6212500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6212500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6525000000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6525000000000001
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.704659090909091
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6345833333333334
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6799264705882353
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.647159090909091
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5829166666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6244852941176471
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6759090909090909
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.60875
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6522058823529412
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9337500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.92625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.92875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9137500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9087500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.92
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.83375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5075000000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6987500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.573125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7312500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5387500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.52375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.615
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.53125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7562500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5212500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325000000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44625000000000004
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.54125
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.586875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8812500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8800000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8325000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8700000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8425
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8712500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8712500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85875
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72375
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72375
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7150000000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7150000000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7662500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7662500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7637500000000002
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7637500000000002
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.765
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.765
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8612500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8612500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87375
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7362500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7362500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7978409090909091
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67625
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7549264705882353
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7517045454545455
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.700514705882353
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7747727272727273
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6414583333333334
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7277205882352942
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9337500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9162500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.925
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9137500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9225000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9325000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9237500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.54625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5643750000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6062500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5800000000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5075000000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.593125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5212500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6312500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.633125
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71125
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51125
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6112500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6212500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.53625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6662500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48125000000000007
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8762500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8775
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8512500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7887500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8200000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.83375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86375
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86375
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8612500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8612500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6837500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6837500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025000000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025000000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7262500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7262500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75375
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75375
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.875
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.875
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72375
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72375
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7425
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7425
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7835227272727274
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6670833333333334
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7424264705882353
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.739659090909091
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6054166666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.692279411764706
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7615909090909091
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63625
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7173529411764706
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.92875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9325000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.92125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9337500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.92
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9268750000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.52625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7250000000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5937500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5337500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7675000000000002
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.665625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7962500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6912500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6937500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6481250000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78125
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.54625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6637500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5525
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7175
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4987500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6081250000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8975
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8762500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8287500000000002
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8525
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8762500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8762500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8825000000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8825000000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7637500000000002
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7637500000000002
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7362500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7362500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91125
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91125
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9025000000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9025000000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79375
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79375
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8223863636363636
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70125
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7796323529411765
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7803409090909091
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6154166666666668
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7221323529411765
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8013636363636365
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6583333333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7508823529411766
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62375
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.595
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6212500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5937500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6075
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6225
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5800000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5425
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5075000000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6212500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325000000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5687500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.54125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5675
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5575000000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5587500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.55375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.53125
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5337500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6587500000000002
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64125
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6062500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.60875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6075
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.615
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.624375
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75125
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75125
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.755
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.755
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5937500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5937500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5975
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5975
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58875
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58875
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5937500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5937500000000001
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6351136363636364
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5833333333333334
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6168382352941177
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6053409090909091
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.55
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5858088235294118
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6202272727272727
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5666666666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6013235294117647
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9337500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9137500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9225000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9337500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9225000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9281250000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5250000000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7262500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.586875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6925
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7562500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5387500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6475
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7712500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5687500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6112500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6587500000000002
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.659375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.55375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6637500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6587500000000002
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.555
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.609375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8975
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84125
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8600000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8875000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8700000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8762500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8762500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8825000000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8825000000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7312500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7312500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7462500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7462500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81375
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81375
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9162500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9162500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9050000000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9050000000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77375
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77375
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80625
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8273863636363636
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7045833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7840441176470588
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7835227272727274
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6191666666666668
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.725514705882353
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8054545454545454
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.661875
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7547794117647061
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9012500000000002
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8712500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.895
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8800000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8875000000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51125
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.675
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6937500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48125000000000007
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7662500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4962500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6312500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.83125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8812500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8800000000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7637500000000002
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8218750000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7387500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7093750000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7712500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5337500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6062500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7250000000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.675
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.90375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9012500000000002
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8362500000000002
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8650000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8675
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8831250000000002
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8687500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8687500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85375
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85375
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8612500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8612500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81125
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91125
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91125
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.845
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.845
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84875
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84875
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8287500000000002
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8287500000000002
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8394318181818182
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7729166666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8159558823529411
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8153409090909092
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6841666666666668
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7690441176470588
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8273863636363636
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7285416666666666
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7925
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44375
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44125000000000003
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44625000000000004
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44125000000000003
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.441875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4987500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.436875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.444375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45500000000000007
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46125000000000005
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4493750000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.436875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.53625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.53625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5212500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5212500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.52875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.52875
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45625000000000004
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45625000000000004
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45375
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45375
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45500000000000007
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45500000000000007
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4571590909090909
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4502205882352941
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4498863636363637
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4391666666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44610294117647065
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45352272727272736
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43833333333333335
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4481617647058824
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9337500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9237500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.92875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.90625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9325000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9237500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.53125
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4912500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6725
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.52875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6025
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6587500000000002
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5225
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5906250000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5687500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6012500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.618125
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.52875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.60375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.60875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44625000000000004
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5275000000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48750000000000004
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.565625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8687500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84125
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7887500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8150000000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.855
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.83375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8443750000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8512500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8512500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68875
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68875
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6912500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6912500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6987500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6987500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8512500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8512500000000001
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8725000000000002
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8725000000000002
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7762500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7762500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7262500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7262500000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75125
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75125
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7703409090909092
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6758333333333334
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7369852941176471
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7230681818181819
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6045833333333335
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68125
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7467045454545455
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6402083333333334
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7091176470588236
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.93125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9337500000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.92875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.92
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9325000000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.92125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9268750000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5937500000000001
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.52375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72125
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.585
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7462500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.53125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7662500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5612500000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6637500000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.51875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6075
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6518750000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78125
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5437500000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6625000000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.55375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49750000000000005
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6081250000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87375
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8387500000000001
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.85625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8675
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8762500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87375
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87375
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8812500000000001
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8812500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7562500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7562500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7262500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7262500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74125
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74125
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8287500000000002
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8287500000000002
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7962500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7962500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8125
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8125
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91875
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.91875
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88375
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9012500000000002
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9012500000000002
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77375
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77375
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8000000000000002
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8000000000000002
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8235227272727274
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70125
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7803676470588236
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7771590909090909
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6175
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7208088235294119
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.800340909090909
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.659375
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7505882352941177
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.436875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.436875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43625
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4370833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43654411764705886
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43647727272727277
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43666666666666665
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43654411764705886
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4363636363636364
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.436875
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43654411764705886
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8208333333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8097916666666667
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8153125000000001
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8189583333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8092708333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8198958333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8046875
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8122916666666666
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7558333333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45395833333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6048958333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5564583333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45625000000000004
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5063541666666667
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6561458333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45510416666666664
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.555625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6858333333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5575000000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6216666666666667
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6629166666666667
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5279166666666667
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5954166666666667
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6743750000000001
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5427083333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6085416666666668
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.573125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7027083333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6379166666666667
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6300000000000001
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5122916666666667
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5711458333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6015625
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6075
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6045312500000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6833333333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5325
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6079166666666667
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5972916666666668
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.52875
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6403125000000001
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49635416666666665
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5683333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7879166666666667
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7920833333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7675000000000002
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7341666666666666
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7508333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7777083333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.763125
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7704166666666667
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.795
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.795
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7772916666666667
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7772916666666667
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7861458333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7861458333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6783333333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6783333333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666667
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666667
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6662500000000001
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6662500000000001
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71125
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71125
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6989583333333335
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6989583333333335
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7051041666666666
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7051041666666666
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7841666666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7841666666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7579166666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7579166666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7710416666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7710416666666667
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7214583333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7214583333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6816666666666666
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6816666666666666
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7015625000000001
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7015625000000001
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7270075757575759
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6414236111111111
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6968014705882353
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6911931818181818
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5817361111111112
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.652561274509804
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7091003787878788
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6115798611111112
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6746813725490196
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9491666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9479166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9429166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7616666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6491666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5066666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5566666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6841666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5216666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6029166666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8366666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7466666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8404166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9404166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8660416666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7716666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8316666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8016666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8091666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6729166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7904166666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6841666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7372916666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8854166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5491666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7129166666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8829166666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7154166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7991666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9491666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9429166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9029166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9210416666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9266666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9266666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9079166666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9079166666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8904166666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8904166666666665
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8975757575757576
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8279166666666665
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729901960784313
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8787121212121213
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8121078431372549
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8881439393939393
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7589583333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8425490196078431
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9154166666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9041666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9241666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9329166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9197916666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6741666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5191666666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5966666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5266666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4941666666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5104166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6004166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5066666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5535416666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7341666666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8254166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6566666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7741666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9041666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6954166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7997916666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8266666666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7766666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5516666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6641666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8304166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6604166666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7454166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8416666666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5566666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6991666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8804166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7204166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8004166666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8091666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8491666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9179166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8935416666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9141666666666667
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9141666666666667
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9254166666666667
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9254166666666667
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8716666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8716666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729166666666667
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729166666666667
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7791666666666667
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7791666666666667
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7854166666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7854166666666665
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7908333333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8496078431372548
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8375757575757575
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6620833333333332
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7756372549019607
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.859621212121212
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7264583333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.812622549019608
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9416666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9429166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9304166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9372916666666665
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7116666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5241666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6179166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5591666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5141666666666665
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6354166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5191666666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5772916666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8679166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9241666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7216666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8229166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7566666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8454166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7941666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8116666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8029166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7891666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5291666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6591666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6704166666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7310416666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729166666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8491666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5516666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7004166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8679166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7054166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7866666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8416666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9329166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9097916666666667
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9079166666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9079166666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8666666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8666666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8629166666666667
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8629166666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8873484848484848
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8099999999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8600490196078432
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8648484848484849
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6795833333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7994607843137255
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8760984848484848
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7447916666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8297549019607844
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9416666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9416666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9241666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9329166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9416666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9354166666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7016666666666665
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5266666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6141666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5491666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5116666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5304166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6254166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5191666666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5722916666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7766666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8579166666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7066666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8066666666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9229166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8322916666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7966666666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7766666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7866666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7766666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5241666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6504166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7866666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6504166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7185416666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8616666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729166666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8441666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5416666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6929166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7016666666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7829166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9116666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8441666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8779166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8829166666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9060416666666665
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666665
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666665
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8829166666666667
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8829166666666667
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666667
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666667
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666665
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666665
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9304166666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9304166666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8516666666666667
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8516666666666667
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8529166666666667
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8529166666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8839393939393939
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7995833333333332
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8532575757575758
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6754166666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7904901960784313
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8685984848484848
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7374999999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8223284313725491
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9491666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9416666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9454166666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9404166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9479166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9429166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7441666666666665
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6404166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6091666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5091666666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5591666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6766666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5229166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5997916666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8241666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8854166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7316666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8316666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7779166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8585416666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8291666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7991666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8066666666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7879166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6829166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7354166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8791666666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8829166666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5491666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7129166666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7141666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7979166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9491666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9404166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9266666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8666666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9185416666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666665
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666665
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9141666666666667
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9141666666666667
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9141666666666667
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9141666666666667
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9154166666666667
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9154166666666667
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8948484848484848
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8237499999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8697549019607843
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8775757575757576
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6879166666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8106372549019607
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8862121212121212
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7558333333333332
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8401960784313727
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6641666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6516666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6579166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6616666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6341666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6479166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6629166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6429166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6529166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5816666666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6891666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6354166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5541666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6191666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5866666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5679166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6110416666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7016666666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6416666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6916666666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6341666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6629166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6966666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6379166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6672916666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5716666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6416666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5591666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5291666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5441666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5654166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5854166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5754166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6366666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5866666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6116666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5641666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5416666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5529166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6004166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5641666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5822916666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6916666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6441666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6679166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6916666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6166666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6916666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6304166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6610416666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5941666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5941666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5929166666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5929166666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6891666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6891666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6741666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6741666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6816666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6816666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6791666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6791666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6291666666666665
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6291666666666665
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6516666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6516666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6216666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6216666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6366666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6366666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6480303030303031
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6425
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6460784313725491
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6282575757575757
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5958333333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.616813725490196
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6381439393939393
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6191666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6314460784313725
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9491666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9404166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9479166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9435416666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7591666666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6479166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5916666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5066666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5491666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6754166666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5216666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5985416666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8316666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8379166666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9404166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7866666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8635416666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8241666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8079166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8041666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5391666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7979166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6816666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7397916666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8791666666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5491666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7091666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7141666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7991666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9491666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9429166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9266666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8666666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9197916666666667
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9266666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9266666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9329166666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9329166666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9179166666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9179166666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666667
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666667
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8998484848484848
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8254166666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8735784313725491
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8757575757575757
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6895833333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8100490196078431
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8878030303030303
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7575
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.841813725490196
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8879166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8566666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8791666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729166666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8835416666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7166666666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5791666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6479166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5341666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6016666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6929166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5566666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6247916666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8041666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8516666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7491666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8204166666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8954166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7766666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8360416666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6641666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8241666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7441666666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7591666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6291666666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6941666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7116666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7266666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7191666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7666666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6866666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7266666666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6991666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5841666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6416666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7329166666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6354166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6841666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8616666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7941666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8379166666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8279166666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8610416666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8166666666666665
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8166666666666665
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8216666666666667
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8216666666666667
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8191666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8191666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7841666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7841666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7566666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7566666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7704166666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7704166666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8141666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8141666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8566666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8566666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8291666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8291666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8416666666666667
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8416666666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8250757575757576
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7741666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8071078431372549
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8123484848484848
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6912499999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7696078431372549
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8187121212121213
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7327083333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7883578431372549
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4841666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48166666666666663
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4829166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48166666666666663
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4766666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4791666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4829166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4791666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48104166666666665
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5516666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4516666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46416666666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4566666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46041666666666664
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5079166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45416666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48104166666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4741666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4616666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4741666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4516666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4629166666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4741666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45041666666666663
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4622916666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6441666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5141666666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5791666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5141666666666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46416666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4891666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5791666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4891666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5341666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7441666666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6191666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6816666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6216666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4666666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5441666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6829166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5429166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6129166666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49666666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4841666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49041666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4941666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4791666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48666666666666664
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49541666666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48166666666666663
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4885416666666667
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7841666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7841666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7641666666666665
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7641666666666665
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7741666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7741666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6141666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6141666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5741666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5741666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5941666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5941666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4516666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4516666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4616666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4616666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4566666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4566666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5066666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5066666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5116666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5116666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5091666666666667
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5091666666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5637121212121211
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49999999999999994
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5412254901960784
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5282575757575757
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4658333333333334
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5062254901960783
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5459848484848484
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4829166666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5237254901960784
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9241666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9354166666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9416666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6941666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6154166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5491666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5066666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5279166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6216666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5216666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5716666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9416666666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8016666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8716666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7191666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8204166666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7604166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8460416666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8041666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7979166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7666666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5216666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6441666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7791666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6629166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7210416666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8716666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8491666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5516666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7004166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8629166666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7116666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7872916666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9379166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9116666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8391666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8754166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9279166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8854166666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9254166666666667
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9254166666666667
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8829166666666667
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8829166666666667
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8716666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8716666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8466666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8466666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666665
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8828030303030303
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8141666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8585784313725491
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6770833333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8684848484848485
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7456249999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8251225490196079
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9491666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9416666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9454166666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9316666666666665
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9479166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9422916666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7616666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5341666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6479166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6016666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5066666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5541666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6816666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5204166666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6010416666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8291666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8879166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7466666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8404166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9404166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7879166666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8291666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7991666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8091666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6729166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7891666666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6829166666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7360416666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666665
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5516666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7104166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8804166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7141666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7972916666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9491666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9291666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9366666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9241666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9241666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9304166666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9304166666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9179166666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9179166666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9341666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9391666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8904166666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8904166666666665
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8975757575757576
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8233333333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8713725490196078
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8775757575757576
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6904166666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8115196078431371
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8875757575757576
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7568749999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8414460784313726
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44916666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8354166666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.830625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8330208333333333
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8381249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8183333333333332
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8282291666666668
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8367708333333335
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8244791666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.830625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6756249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5349999999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6053125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5608333333333333
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333333
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5352083333333333
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6182291666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5222916666666666
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5702604166666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8377083333333333
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7308333333333333
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7842708333333334
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8237499999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6712499999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7474999999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8307291666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7010416666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7658854166666665
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7247916666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7420833333333333
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7334375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7183333333333333
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5289583333333333
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6236458333333333
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7215625000000001
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6355208333333333
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6785416666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8108333333333333
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7779166666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7943749999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7675
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5368749999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6521875
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7891666666666667
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6573958333333334
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7232812500000001
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8435416666666665
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8239583333333332
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8337499999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8218749999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7620833333333333
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7919791666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8327083333333333
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7930208333333334
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8128645833333334
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8393749999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8393749999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8449999999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8449999999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8062499999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8062499999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7906249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7906249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7984375
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7984375
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.811875
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.811875
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80875
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80875
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8103125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8103125
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8337499999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8337499999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.811875
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.811875
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8228125000000001
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8228125000000001
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7802083333333333
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7802083333333333
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7783333333333332
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7783333333333332
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7792708333333334
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7792708333333334
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8009659090909091
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7400694444444444
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7794730392156863
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.778125
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6378472222222222
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7286151960784313
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7895454545454546
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6889583333333332
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7540441176470588
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        }
      },
      "auroc": 0.7618750000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 72,
          "fn": 128,
          "accuracy": 0.36
        },
        "0.01": {
          "tp": 72,
          "fn": 128,
          "accuracy": 0.36
        }
      },
      "auroc": 0.6743750000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 179,
          "fn": 221,
          "accuracy": 0.4475
        },
        "0.01": {
          "tp": 179,
          "fn": 221,
          "accuracy": 0.4475
        }
      },
      "auroc": 0.718125
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 114,
          "fn": 86,
          "accuracy": 0.57
        },
        "0.01": {
          "tp": 114,
          "fn": 86,
          "accuracy": 0.57
        }
      },
      "auroc": 0.7793749999999999
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        },
        "0.01": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        }
      },
      "auroc": 0.669375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 221,
          "fn": 179,
          "accuracy": 0.5525
        },
        "0.01": {
          "tp": 221,
          "fn": 179,
          "accuracy": 0.5525
        }
      },
      "auroc": 0.770625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 142,
          "fn": 258,
          "accuracy": 0.355
        },
        "0.01": {
          "tp": 142,
          "fn": 258,
          "accuracy": 0.355
        }
      },
      "auroc": 0.671875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 363,
          "fn": 437,
          "accuracy": 0.45375
        },
        "0.01": {
          "tp": 363,
          "fn": 437,
          "accuracy": 0.45375
        }
      },
      "auroc": 0.72125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 154,
          "accuracy": 0.23
        },
        "0.01": {
          "tp": 46,
          "fn": 154,
          "accuracy": 0.23
        }
      },
      "auroc": 0.609375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        }
      },
      "auroc": 0.556875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 329,
          "accuracy": 0.1775
        },
        "0.01": {
          "tp": 71,
          "fn": 329,
          "accuracy": 0.1775
        }
      },
      "auroc": 0.583125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        }
      },
      "auroc": 0.711875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        }
      },
      "auroc": 0.551875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 290,
          "accuracy": 0.275
        },
        "0.01": {
          "tp": 110,
          "fn": 290,
          "accuracy": 0.275
        }
      },
      "auroc": 0.631875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 267,
          "accuracy": 0.3325
        },
        "0.01": {
          "tp": 133,
          "fn": 267,
          "accuracy": 0.3325
        }
      },
      "auroc": 0.660625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 352,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 48,
          "fn": 352,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5543750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 181,
          "fn": 619,
          "accuracy": 0.22625
        },
        "0.01": {
          "tp": 181,
          "fn": 619,
          "accuracy": 0.22625
        }
      },
      "auroc": 0.6075
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        },
        "0.01": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        }
      },
      "auroc": 0.8968750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.579375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 195,
          "fn": 205,
          "accuracy": 0.4875
        },
        "0.01": {
          "tp": 195,
          "fn": 205,
          "accuracy": 0.4875
        }
      },
      "auroc": 0.738125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        },
        "0.01": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        }
      },
      "auroc": 0.7893749999999999
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        }
      },
      "auroc": 0.546875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        },
        "0.01": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        }
      },
      "auroc": 0.668125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 279,
          "fn": 121,
          "accuracy": 0.6975
        },
        "0.01": {
          "tp": 279,
          "fn": 121,
          "accuracy": 0.6975
        }
      },
      "auroc": 0.843125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        },
        "0.01": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        }
      },
      "auroc": 0.563125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 334,
          "fn": 466,
          "accuracy": 0.4175
        },
        "0.01": {
          "tp": 334,
          "fn": 466,
          "accuracy": 0.4175
        }
      },
      "auroc": 0.703125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        },
        "0.01": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        }
      },
      "auroc": 0.529375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        },
        "0.01": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        }
      },
      "auroc": 0.8043750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 138,
          "fn": 262,
          "accuracy": 0.345
        },
        "0.01": {
          "tp": 138,
          "fn": 262,
          "accuracy": 0.345
        }
      },
      "auroc": 0.666875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 64,
          "accuracy": 0.68
        },
        "0.01": {
          "tp": 136,
          "fn": 64,
          "accuracy": 0.68
        }
      },
      "auroc": 0.8343750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        },
        "0.01": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        }
      },
      "auroc": 0.614375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        },
        "0.01": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        }
      },
      "auroc": 0.681875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 172,
          "fn": 228,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 172,
          "fn": 228,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 322,
          "fn": 478,
          "accuracy": 0.4025
        },
        "0.01": {
          "tp": 322,
          "fn": 478,
          "accuracy": 0.4025
        }
      },
      "auroc": 0.695625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        },
        "0.01": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        }
      },
      "auroc": 0.591875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5643750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 333,
          "accuracy": 0.1675
        },
        "0.01": {
          "tp": 67,
          "fn": 333,
          "accuracy": 0.1675
        }
      },
      "auroc": 0.578125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        }
      },
      "auroc": 0.699375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        }
      },
      "auroc": 0.506875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        },
        "0.01": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        }
      },
      "auroc": 0.603125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 121,
          "fn": 279,
          "accuracy": 0.3025
        },
        "0.01": {
          "tp": 121,
          "fn": 279,
          "accuracy": 0.3025
        }
      },
      "auroc": 0.645625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        },
        "0.01": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        }
      },
      "auroc": 0.535625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 154,
          "fn": 646,
          "accuracy": 0.1925
        },
        "0.01": {
          "tp": 154,
          "fn": 646,
          "accuracy": 0.1925
        }
      },
      "auroc": 0.590625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        },
        "0.01": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        }
      },
      "auroc": 0.919375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.769375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 280,
          "fn": 120,
          "accuracy": 0.7
        },
        "0.01": {
          "tp": 280,
          "fn": 120,
          "accuracy": 0.7
        }
      },
      "auroc": 0.844375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        },
        "0.01": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        }
      },
      "auroc": 0.854375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        },
        "0.01": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        }
      },
      "auroc": 0.636875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 201,
          "fn": 199,
          "accuracy": 0.5025
        },
        "0.01": {
          "tp": 201,
          "fn": 199,
          "accuracy": 0.5025
        }
      },
      "auroc": 0.745625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        },
        "0.01": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        }
      },
      "auroc": 0.8868750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 167,
          "fn": 233,
          "accuracy": 0.4175
        },
        "0.01": {
          "tp": 167,
          "fn": 233,
          "accuracy": 0.4175
        }
      },
      "auroc": 0.703125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 481,
          "fn": 319,
          "accuracy": 0.60125
        },
        "0.01": {
          "tp": 481,
          "fn": 319,
          "accuracy": 0.60125
        }
      },
      "auroc": 0.7949999999999999
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        },
        "0.01": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        }
      },
      "auroc": 0.829375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        },
        "0.01": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        }
      },
      "auroc": 0.829375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        },
        "0.01": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        }
      },
      "auroc": 0.828125
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        },
        "0.01": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        }
      },
      "auroc": 0.828125
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        },
        "0.01": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        }
      },
      "auroc": 0.716875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        },
        "0.01": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        }
      },
      "auroc": 0.716875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        },
        "0.01": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        }
      },
      "auroc": 0.919375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        },
        "0.01": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        }
      },
      "auroc": 0.919375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        }
      },
      "auroc": 0.821875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        }
      },
      "auroc": 0.821875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        },
        "0.01": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        }
      },
      "auroc": 0.870625
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        },
        "0.01": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        }
      },
      "auroc": 0.870625
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        }
      },
      "auroc": 0.941875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        }
      },
      "auroc": 0.941875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 265,
          "fn": 135,
          "accuracy": 0.6625
        },
        "0.01": {
          "tp": 265,
          "fn": 135,
          "accuracy": 0.6625
        }
      },
      "auroc": 0.825625
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 265,
          "fn": 135,
          "accuracy": 0.6625
        },
        "0.01": {
          "tp": 265,
          "fn": 135,
          "accuracy": 0.6625
        }
      },
      "auroc": 0.825625
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        },
        "0.01": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        }
      },
      "auroc": 0.794375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        },
        "0.01": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        }
      },
      "auroc": 0.794375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        }
      },
      "auroc": 0.726875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        }
      },
      "auroc": 0.726875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 213,
          "fn": 187,
          "accuracy": 0.5325
        },
        "0.01": {
          "tp": 213,
          "fn": 187,
          "accuracy": 0.5325
        }
      },
      "auroc": 0.760625
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 213,
          "fn": 187,
          "accuracy": 0.5325
        },
        "0.01": {
          "tp": 213,
          "fn": 187,
          "accuracy": 0.5325
        }
      },
      "auroc": 0.760625
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1232,
          "fn": 968,
          "accuracy": 0.56
        },
        "0.01": {
          "tp": 1232,
          "fn": 968,
          "accuracy": 0.56
        }
      },
      "auroc": 0.774375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 393,
          "fn": 807,
          "accuracy": 0.3275
        },
        "0.01": {
          "tp": 393,
          "fn": 807,
          "accuracy": 0.3275
        }
      },
      "auroc": 0.6581250000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1625,
          "fn": 1775,
          "accuracy": 0.47794117647058826
        },
        "0.01": {
          "tp": 1625,
          "fn": 1775,
          "accuracy": 0.47794117647058826
        }
      },
      "auroc": 0.7333455882352942
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1210,
          "fn": 990,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 1210,
          "fn": 990,
          "accuracy": 0.55
        }
      },
      "auroc": 0.769375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 224,
          "fn": 976,
          "accuracy": 0.18666666666666668
        },
        "0.01": {
          "tp": 224,
          "fn": 976,
          "accuracy": 0.18666666666666668
        }
      },
      "auroc": 0.5877083333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1434,
          "fn": 1966,
          "accuracy": 0.42176470588235293
        },
        "0.01": {
          "tp": 1434,
          "fn": 1966,
          "accuracy": 0.42176470588235293
        }
      },
      "auroc": 0.7052573529411765
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 2442,
          "fn": 1958,
          "accuracy": 0.555
        },
        "0.01": {
          "tp": 2442,
          "fn": 1958,
          "accuracy": 0.555
        }
      },
      "auroc": 0.7718750000000002
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 617,
          "fn": 1783,
          "accuracy": 0.25708333333333333
        },
        "0.01": {
          "tp": 617,
          "fn": 1783,
          "accuracy": 0.25708333333333333
        }
      },
      "auroc": 0.6229166666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 3059,
          "fn": 3741,
          "accuracy": 0.44985294117647057
        },
        "0.01": {
          "tp": 3059,
          "fn": 3741,
          "accuracy": 0.44985294117647057
        }
      },
      "auroc": 0.7193014705882352
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 135,
          "accuracy": 0.325
        },
        "0.01": {
          "tp": 65,
          "fn": 135,
          "accuracy": 0.325
        }
      },
      "auroc": 0.656875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        }
      },
      "auroc": 0.584375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        },
        "0.01": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        }
      },
      "auroc": 0.620625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        }
      },
      "auroc": 0.644375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        }
      },
      "auroc": 0.576875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 307,
          "accuracy": 0.2325
        },
        "0.01": {
          "tp": 93,
          "fn": 307,
          "accuracy": 0.2325
        }
      },
      "auroc": 0.610625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 125,
          "fn": 275,
          "accuracy": 0.3125
        },
        "0.01": {
          "tp": 125,
          "fn": 275,
          "accuracy": 0.3125
        }
      },
      "auroc": 0.650625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 331,
          "accuracy": 0.1725
        },
        "0.01": {
          "tp": 69,
          "fn": 331,
          "accuracy": 0.1725
        }
      },
      "auroc": 0.580625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 194,
          "fn": 606,
          "accuracy": 0.2425
        },
        "0.01": {
          "tp": 194,
          "fn": 606,
          "accuracy": 0.2425
        }
      },
      "auroc": 0.615625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        }
      },
      "auroc": 0.721875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5493750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 287,
          "accuracy": 0.2825
        },
        "0.01": {
          "tp": 113,
          "fn": 287,
          "accuracy": 0.2825
        }
      },
      "auroc": 0.635625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        }
      },
      "auroc": 0.659375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 19,
          "fn": 181,
          "accuracy": 0.095
        },
        "0.01": {
          "tp": 19,
          "fn": 181,
          "accuracy": 0.095
        }
      },
      "auroc": 0.541875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 315,
          "accuracy": 0.2125
        },
        "0.01": {
          "tp": 85,
          "fn": 315,
          "accuracy": 0.2125
        }
      },
      "auroc": 0.600625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 243,
          "accuracy": 0.3925
        },
        "0.01": {
          "tp": 157,
          "fn": 243,
          "accuracy": 0.3925
        }
      },
      "auroc": 0.690625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 359,
          "accuracy": 0.1025
        },
        "0.01": {
          "tp": 41,
          "fn": 359,
          "accuracy": 0.1025
        }
      },
      "auroc": 0.545625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 198,
          "fn": 602,
          "accuracy": 0.2475
        },
        "0.01": {
          "tp": 198,
          "fn": 602,
          "accuracy": 0.2475
        }
      },
      "auroc": 0.618125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        },
        "0.01": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        }
      },
      "auroc": 0.744375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        },
        "0.01": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        }
      },
      "auroc": 0.544375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 280,
          "accuracy": 0.3
        },
        "0.01": {
          "tp": 120,
          "fn": 280,
          "accuracy": 0.3
        }
      },
      "auroc": 0.644375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 129,
          "accuracy": 0.355
        },
        "0.01": {
          "tp": 71,
          "fn": 129,
          "accuracy": 0.355
        }
      },
      "auroc": 0.671875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 16,
          "fn": 184,
          "accuracy": 0.08
        },
        "0.01": {
          "tp": 16,
          "fn": 184,
          "accuracy": 0.08
        }
      },
      "auroc": 0.534375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        },
        "0.01": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        }
      },
      "auroc": 0.603125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 171,
          "fn": 229,
          "accuracy": 0.4275
        },
        "0.01": {
          "tp": 171,
          "fn": 229,
          "accuracy": 0.4275
        }
      },
      "auroc": 0.708125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 364,
          "accuracy": 0.09
        },
        "0.01": {
          "tp": 36,
          "fn": 364,
          "accuracy": 0.09
        }
      },
      "auroc": 0.539375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 207,
          "fn": 593,
          "accuracy": 0.25875
        },
        "0.01": {
          "tp": 207,
          "fn": 593,
          "accuracy": 0.25875
        }
      },
      "auroc": 0.62375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        },
        "0.01": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        }
      },
      "auroc": 0.6893750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.769375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 188,
          "fn": 212,
          "accuracy": 0.47
        },
        "0.01": {
          "tp": 188,
          "fn": 212,
          "accuracy": 0.47
        }
      },
      "auroc": 0.729375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        },
        "0.01": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        }
      },
      "auroc": 0.794375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        }
      },
      "auroc": 0.581875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 155,
          "fn": 245,
          "accuracy": 0.3875
        },
        "0.01": {
          "tp": 155,
          "fn": 245,
          "accuracy": 0.3875
        }
      },
      "auroc": 0.688125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 198,
          "fn": 202,
          "accuracy": 0.495
        },
        "0.01": {
          "tp": 198,
          "fn": 202,
          "accuracy": 0.495
        }
      },
      "auroc": 0.7418750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 145,
          "fn": 255,
          "accuracy": 0.3625
        },
        "0.01": {
          "tp": 145,
          "fn": 255,
          "accuracy": 0.3625
        }
      },
      "auroc": 0.675625
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 343,
          "fn": 457,
          "accuracy": 0.42875
        },
        "0.01": {
          "tp": 343,
          "fn": 457,
          "accuracy": 0.42875
        }
      },
      "auroc": 0.70875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        },
        "0.01": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        }
      },
      "auroc": 0.719375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        },
        "0.01": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        }
      },
      "auroc": 0.536875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 293,
          "accuracy": 0.2675
        },
        "0.01": {
          "tp": 107,
          "fn": 293,
          "accuracy": 0.2675
        }
      },
      "auroc": 0.628125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 75,
          "fn": 125,
          "accuracy": 0.375
        },
        "0.01": {
          "tp": 75,
          "fn": 125,
          "accuracy": 0.375
        }
      },
      "auroc": 0.681875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.504375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        },
        "0.01": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        }
      },
      "auroc": 0.593125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 235,
          "accuracy": 0.4125
        },
        "0.01": {
          "tp": 165,
          "fn": 235,
          "accuracy": 0.4125
        }
      },
      "auroc": 0.700625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 379,
          "accuracy": 0.0525
        },
        "0.01": {
          "tp": 21,
          "fn": 379,
          "accuracy": 0.0525
        }
      },
      "auroc": 0.520625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 614,
          "accuracy": 0.2325
        },
        "0.01": {
          "tp": 186,
          "fn": 614,
          "accuracy": 0.2325
        }
      },
      "auroc": 0.610625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        },
        "0.01": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        }
      },
      "auroc": 0.829375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 121,
          "accuracy": 0.395
        },
        "0.01": {
          "tp": 79,
          "fn": 121,
          "accuracy": 0.395
        }
      },
      "auroc": 0.691875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 213,
          "fn": 187,
          "accuracy": 0.5325
        },
        "0.01": {
          "tp": 213,
          "fn": 187,
          "accuracy": 0.5325
        }
      },
      "auroc": 0.760625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        }
      },
      "auroc": 0.574375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 283,
          "accuracy": 0.2925
        },
        "0.01": {
          "tp": 117,
          "fn": 283,
          "accuracy": 0.2925
        }
      },
      "auroc": 0.640625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 219,
          "fn": 181,
          "accuracy": 0.5475
        },
        "0.01": {
          "tp": 219,
          "fn": 181,
          "accuracy": 0.5475
        }
      },
      "auroc": 0.768125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 289,
          "accuracy": 0.2775
        },
        "0.01": {
          "tp": 111,
          "fn": 289,
          "accuracy": 0.2775
        }
      },
      "auroc": 0.633125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 330,
          "fn": 470,
          "accuracy": 0.4125
        },
        "0.01": {
          "tp": 330,
          "fn": 470,
          "accuracy": 0.4125
        }
      },
      "auroc": 0.700625
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 129,
          "fn": 71,
          "accuracy": 0.645
        },
        "0.01": {
          "tp": 129,
          "fn": 71,
          "accuracy": 0.645
        }
      },
      "auroc": 0.816875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 129,
          "fn": 71,
          "accuracy": 0.645
        },
        "0.01": {
          "tp": 129,
          "fn": 71,
          "accuracy": 0.645
        }
      },
      "auroc": 0.816875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.801875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.801875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 252,
          "fn": 148,
          "accuracy": 0.63
        },
        "0.01": {
          "tp": 252,
          "fn": 148,
          "accuracy": 0.63
        }
      },
      "auroc": 0.809375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 252,
          "fn": 148,
          "accuracy": 0.63
        },
        "0.01": {
          "tp": 252,
          "fn": 148,
          "accuracy": 0.63
        }
      },
      "auroc": 0.809375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        }
      },
      "auroc": 0.661875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        }
      },
      "auroc": 0.661875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        }
      },
      "auroc": 0.644375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        }
      },
      "auroc": 0.644375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 127,
          "fn": 273,
          "accuracy": 0.3175
        },
        "0.01": {
          "tp": 127,
          "fn": 273,
          "accuracy": 0.3175
        }
      },
      "auroc": 0.653125
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 127,
          "fn": 273,
          "accuracy": 0.3175
        },
        "0.01": {
          "tp": 127,
          "fn": 273,
          "accuracy": 0.3175
        }
      },
      "auroc": 0.653125
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        }
      },
      "auroc": 0.721875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        }
      },
      "auroc": 0.721875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 129,
          "accuracy": 0.355
        },
        "0.01": {
          "tp": 71,
          "fn": 129,
          "accuracy": 0.355
        }
      },
      "auroc": 0.671875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 129,
          "accuracy": 0.355
        },
        "0.01": {
          "tp": 71,
          "fn": 129,
          "accuracy": 0.355
        }
      },
      "auroc": 0.671875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 162,
          "fn": 238,
          "accuracy": 0.405
        },
        "0.01": {
          "tp": 162,
          "fn": 238,
          "accuracy": 0.405
        }
      },
      "auroc": 0.696875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 162,
          "fn": 238,
          "accuracy": 0.405
        },
        "0.01": {
          "tp": 162,
          "fn": 238,
          "accuracy": 0.405
        }
      },
      "auroc": 0.696875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        },
        "0.01": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        }
      },
      "auroc": 0.766875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        },
        "0.01": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        }
      },
      "auroc": 0.766875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.579375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.579375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 143,
          "fn": 257,
          "accuracy": 0.3575
        },
        "0.01": {
          "tp": 143,
          "fn": 257,
          "accuracy": 0.3575
        }
      },
      "auroc": 0.673125
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 143,
          "fn": 257,
          "accuracy": 0.3575
        },
        "0.01": {
          "tp": 143,
          "fn": 257,
          "accuracy": 0.3575
        }
      },
      "auroc": 0.673125
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        },
        "0.01": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        }
      },
      "auroc": 0.714375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        },
        "0.01": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        }
      },
      "auroc": 0.714375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 145,
          "accuracy": 0.275
        },
        "0.01": {
          "tp": 55,
          "fn": 145,
          "accuracy": 0.275
        }
      },
      "auroc": 0.631875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 145,
          "accuracy": 0.275
        },
        "0.01": {
          "tp": 55,
          "fn": 145,
          "accuracy": 0.275
        }
      },
      "auroc": 0.631875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 143,
          "fn": 257,
          "accuracy": 0.3575
        },
        "0.01": {
          "tp": 143,
          "fn": 257,
          "accuracy": 0.3575
        }
      },
      "auroc": 0.673125
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 143,
          "fn": 257,
          "accuracy": 0.3575
        },
        "0.01": {
          "tp": 143,
          "fn": 257,
          "accuracy": 0.3575
        }
      },
      "auroc": 0.673125
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 1042,
          "fn": 1158,
          "accuracy": 0.47363636363636363
        },
        "0.01": {
          "tp": 1042,
          "fn": 1158,
          "accuracy": 0.47363636363636363
        }
      },
      "auroc": 0.7311931818181818
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 284,
          "fn": 916,
          "accuracy": 0.23666666666666666
        },
        "0.01": {
          "tp": 284,
          "fn": 916,
          "accuracy": 0.23666666666666666
        }
      },
      "auroc": 0.6127083333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 1326,
          "fn": 2074,
          "accuracy": 0.39
        },
        "0.01": {
          "tp": 1326,
          "fn": 2074,
          "accuracy": 0.39
        }
      },
      "auroc": 0.6893750000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 820,
          "fn": 1380,
          "accuracy": 0.37272727272727274
        },
        "0.01": {
          "tp": 820,
          "fn": 1380,
          "accuracy": 0.37272727272727274
        }
      },
      "auroc": 0.6807386363636364
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 139,
          "fn": 1061,
          "accuracy": 0.11583333333333333
        },
        "0.01": {
          "tp": 139,
          "fn": 1061,
          "accuracy": 0.11583333333333333
        }
      },
      "auroc": 0.5522916666666666
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 959,
          "fn": 2441,
          "accuracy": 0.28205882352941175
        },
        "0.01": {
          "tp": 959,
          "fn": 2441,
          "accuracy": 0.28205882352941175
        }
      },
      "auroc": 0.6354044117647059
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 1862,
          "fn": 2538,
          "accuracy": 0.42318181818181816
        },
        "0.01": {
          "tp": 1862,
          "fn": 2538,
          "accuracy": 0.42318181818181816
        }
      },
      "auroc": 0.7059659090909091
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 423,
          "fn": 1977,
          "accuracy": 0.17625
        },
        "0.01": {
          "tp": 423,
          "fn": 1977,
          "accuracy": 0.17625
        }
      },
      "auroc": 0.5825
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 2285,
          "fn": 4515,
          "accuracy": 0.3360294117647059
        },
        "0.01": {
          "tp": 2285,
          "fn": 4515,
          "accuracy": 0.3360294117647059
        }
      },
      "auroc": 0.6623897058823529
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 96,
          "fn": 104,
          "accuracy": 0.48
        },
        "0.01": {
          "tp": 96,
          "fn": 104,
          "accuracy": 0.48
        }
      },
      "auroc": 0.734375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 58,
          "fn": 142,
          "accuracy": 0.29
        },
        "0.01": {
          "tp": 58,
          "fn": 142,
          "accuracy": 0.29
        }
      },
      "auroc": 0.639375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 154,
          "fn": 246,
          "accuracy": 0.385
        },
        "0.01": {
          "tp": 154,
          "fn": 246,
          "accuracy": 0.385
        }
      },
      "auroc": 0.686875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 99,
          "accuracy": 0.505
        },
        "0.01": {
          "tp": 101,
          "fn": 99,
          "accuracy": 0.505
        }
      },
      "auroc": 0.746875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        },
        "0.01": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        }
      },
      "auroc": 0.654375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 235,
          "accuracy": 0.4125
        },
        "0.01": {
          "tp": 165,
          "fn": 235,
          "accuracy": 0.4125
        }
      },
      "auroc": 0.700625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 197,
          "fn": 203,
          "accuracy": 0.4925
        },
        "0.01": {
          "tp": 197,
          "fn": 203,
          "accuracy": 0.4925
        }
      },
      "auroc": 0.740625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 278,
          "accuracy": 0.305
        },
        "0.01": {
          "tp": 122,
          "fn": 278,
          "accuracy": 0.305
        }
      },
      "auroc": 0.646875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 319,
          "fn": 481,
          "accuracy": 0.39875
        },
        "0.01": {
          "tp": 319,
          "fn": 481,
          "accuracy": 0.39875
        }
      },
      "auroc": 0.69375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 144,
          "accuracy": 0.28
        },
        "0.01": {
          "tp": 56,
          "fn": 144,
          "accuracy": 0.28
        }
      },
      "auroc": 0.634375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        }
      },
      "auroc": 0.556875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 319,
          "accuracy": 0.2025
        },
        "0.01": {
          "tp": 81,
          "fn": 319,
          "accuracy": 0.2025
        }
      },
      "auroc": 0.5956250000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        },
        "0.01": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        }
      },
      "auroc": 0.704375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5543750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        }
      },
      "auroc": 0.629375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 140,
          "fn": 260,
          "accuracy": 0.35
        },
        "0.01": {
          "tp": 140,
          "fn": 260,
          "accuracy": 0.35
        }
      },
      "auroc": 0.669375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 351,
          "accuracy": 0.1225
        },
        "0.01": {
          "tp": 49,
          "fn": 351,
          "accuracy": 0.1225
        }
      },
      "auroc": 0.555625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 189,
          "fn": 611,
          "accuracy": 0.23625
        },
        "0.01": {
          "tp": 189,
          "fn": 611,
          "accuracy": 0.23625
        }
      },
      "auroc": 0.6125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 151,
          "fn": 49,
          "accuracy": 0.755
        },
        "0.01": {
          "tp": 151,
          "fn": 49,
          "accuracy": 0.755
        }
      },
      "auroc": 0.871875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        }
      },
      "auroc": 0.566875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 180,
          "fn": 220,
          "accuracy": 0.45
        },
        "0.01": {
          "tp": 180,
          "fn": 220,
          "accuracy": 0.45
        }
      },
      "auroc": 0.719375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 115,
          "fn": 85,
          "accuracy": 0.575
        },
        "0.01": {
          "tp": 115,
          "fn": 85,
          "accuracy": 0.575
        }
      },
      "auroc": 0.781875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5493750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 137,
          "fn": 263,
          "accuracy": 0.3425
        },
        "0.01": {
          "tp": 137,
          "fn": 263,
          "accuracy": 0.3425
        }
      },
      "auroc": 0.665625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        },
        "0.01": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        }
      },
      "auroc": 0.558125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 317,
          "fn": 483,
          "accuracy": 0.39625
        },
        "0.01": {
          "tp": 317,
          "fn": 483,
          "accuracy": 0.39625
        }
      },
      "auroc": 0.6925
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5543750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        },
        "0.01": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        }
      },
      "auroc": 0.794375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 144,
          "fn": 256,
          "accuracy": 0.36
        },
        "0.01": {
          "tp": 144,
          "fn": 256,
          "accuracy": 0.36
        }
      },
      "auroc": 0.6743750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        },
        "0.01": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        }
      },
      "auroc": 0.591875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 172,
          "fn": 228,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 172,
          "fn": 228,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 243,
          "accuracy": 0.3925
        },
        "0.01": {
          "tp": 157,
          "fn": 243,
          "accuracy": 0.3925
        }
      },
      "auroc": 0.690625
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 159,
          "fn": 241,
          "accuracy": 0.3975
        },
        "0.01": {
          "tp": 159,
          "fn": 241,
          "accuracy": 0.3975
        }
      },
      "auroc": 0.693125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 316,
          "fn": 484,
          "accuracy": 0.395
        },
        "0.01": {
          "tp": 316,
          "fn": 484,
          "accuracy": 0.395
        }
      },
      "auroc": 0.691875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        },
        "0.01": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        }
      },
      "auroc": 0.641875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.561875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 314,
          "accuracy": 0.215
        },
        "0.01": {
          "tp": 86,
          "fn": 314,
          "accuracy": 0.215
        }
      },
      "auroc": 0.601875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        }
      },
      "auroc": 0.694375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.504375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 316,
          "accuracy": 0.21
        },
        "0.01": {
          "tp": 84,
          "fn": 316,
          "accuracy": 0.21
        }
      },
      "auroc": 0.599375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        },
        "0.01": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        }
      },
      "auroc": 0.668125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        },
        "0.01": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        }
      },
      "auroc": 0.533125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 630,
          "accuracy": 0.2125
        },
        "0.01": {
          "tp": 170,
          "fn": 630,
          "accuracy": 0.2125
        }
      },
      "auroc": 0.600625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        },
        "0.01": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        }
      },
      "auroc": 0.906875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.769375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 275,
          "fn": 125,
          "accuracy": 0.6875
        },
        "0.01": {
          "tp": 275,
          "fn": 125,
          "accuracy": 0.6875
        }
      },
      "auroc": 0.838125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        },
        "0.01": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        }
      },
      "auroc": 0.636875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 190,
          "fn": 210,
          "accuracy": 0.475
        },
        "0.01": {
          "tp": 190,
          "fn": 210,
          "accuracy": 0.475
        }
      },
      "auroc": 0.731875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 298,
          "fn": 102,
          "accuracy": 0.745
        },
        "0.01": {
          "tp": 298,
          "fn": 102,
          "accuracy": 0.745
        }
      },
      "auroc": 0.8668750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 167,
          "fn": 233,
          "accuracy": 0.4175
        },
        "0.01": {
          "tp": 167,
          "fn": 233,
          "accuracy": 0.4175
        }
      },
      "auroc": 0.703125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 465,
          "fn": 335,
          "accuracy": 0.58125
        },
        "0.01": {
          "tp": 465,
          "fn": 335,
          "accuracy": 0.58125
        }
      },
      "auroc": 0.785
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 132,
          "fn": 68,
          "accuracy": 0.66
        },
        "0.01": {
          "tp": 132,
          "fn": 68,
          "accuracy": 0.66
        }
      },
      "auroc": 0.8243750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 132,
          "fn": 68,
          "accuracy": 0.66
        },
        "0.01": {
          "tp": 132,
          "fn": 68,
          "accuracy": 0.66
        }
      },
      "auroc": 0.8243750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        },
        "0.01": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        }
      },
      "auroc": 0.8143750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        },
        "0.01": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        }
      },
      "auroc": 0.8143750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 260,
          "fn": 140,
          "accuracy": 0.65
        },
        "0.01": {
          "tp": 260,
          "fn": 140,
          "accuracy": 0.65
        }
      },
      "auroc": 0.819375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 260,
          "fn": 140,
          "accuracy": 0.65
        },
        "0.01": {
          "tp": 260,
          "fn": 140,
          "accuracy": 0.65
        }
      },
      "auroc": 0.819375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        }
      },
      "auroc": 0.694375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        }
      },
      "auroc": 0.694375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        }
      },
      "auroc": 0.694375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        }
      },
      "auroc": 0.694375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 160,
          "fn": 240,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 160,
          "fn": 240,
          "accuracy": 0.4
        }
      },
      "auroc": 0.694375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 160,
          "fn": 240,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 160,
          "fn": 240,
          "accuracy": 0.4
        }
      },
      "auroc": 0.694375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 50,
          "accuracy": 0.75
        },
        "0.01": {
          "tp": 150,
          "fn": 50,
          "accuracy": 0.75
        }
      },
      "auroc": 0.8693750000000001
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 50,
          "accuracy": 0.75
        },
        "0.01": {
          "tp": 150,
          "fn": 50,
          "accuracy": 0.75
        }
      },
      "auroc": 0.8693750000000001
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        },
        "0.01": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        }
      },
      "auroc": 0.786875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        },
        "0.01": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        }
      },
      "auroc": 0.786875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        },
        "0.01": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        }
      },
      "auroc": 0.828125
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        },
        "0.01": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        }
      },
      "auroc": 0.828125
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        },
        "0.01": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        }
      },
      "auroc": 0.921875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        },
        "0.01": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        }
      },
      "auroc": 0.921875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        }
      },
      "auroc": 0.666875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        }
      },
      "auroc": 0.666875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 240,
          "fn": 160,
          "accuracy": 0.6
        },
        "0.01": {
          "tp": 240,
          "fn": 160,
          "accuracy": 0.6
        }
      },
      "auroc": 0.794375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 240,
          "fn": 160,
          "accuracy": 0.6
        },
        "0.01": {
          "tp": 240,
          "fn": 160,
          "accuracy": 0.6
        }
      },
      "auroc": 0.794375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        },
        "0.01": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        }
      },
      "auroc": 0.7718750000000002
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        },
        "0.01": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        }
      },
      "auroc": 0.7718750000000002
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 196,
          "fn": 204,
          "accuracy": 0.49
        },
        "0.01": {
          "tp": 196,
          "fn": 204,
          "accuracy": 0.49
        }
      },
      "auroc": 0.739375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 196,
          "fn": 204,
          "accuracy": 0.49
        },
        "0.01": {
          "tp": 196,
          "fn": 204,
          "accuracy": 0.49
        }
      },
      "auroc": 0.739375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 1195,
          "fn": 1005,
          "accuracy": 0.5431818181818182
        },
        "0.01": {
          "tp": 1195,
          "fn": 1005,
          "accuracy": 0.5431818181818182
        }
      },
      "auroc": 0.7659659090909091
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 369,
          "fn": 831,
          "accuracy": 0.3075
        },
        "0.01": {
          "tp": 369,
          "fn": 831,
          "accuracy": 0.3075
        }
      },
      "auroc": 0.6481250000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 1564,
          "fn": 1836,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 1564,
          "fn": 1836,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 1125,
          "fn": 1075,
          "accuracy": 0.5113636363636364
        },
        "0.01": {
          "tp": 1125,
          "fn": 1075,
          "accuracy": 0.5113636363636364
        }
      },
      "auroc": 0.7500568181818181
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 210,
          "fn": 990,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 210,
          "fn": 990,
          "accuracy": 0.175
        }
      },
      "auroc": 0.581875
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 1335,
          "fn": 2065,
          "accuracy": 0.3926470588235294
        },
        "0.01": {
          "tp": 1335,
          "fn": 2065,
          "accuracy": 0.3926470588235294
        }
      },
      "auroc": 0.6906985294117647
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 2320,
          "fn": 2080,
          "accuracy": 0.5272727272727272
        },
        "0.01": {
          "tp": 2320,
          "fn": 2080,
          "accuracy": 0.5272727272727272
        }
      },
      "auroc": 0.7580113636363637
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 579,
          "fn": 1821,
          "accuracy": 0.24125
        },
        "0.01": {
          "tp": 579,
          "fn": 1821,
          "accuracy": 0.24125
        }
      },
      "auroc": 0.615
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 2899,
          "fn": 3901,
          "accuracy": 0.4263235294117647
        },
        "0.01": {
          "tp": 2899,
          "fn": 3901,
          "accuracy": 0.4263235294117647
        }
      },
      "auroc": 0.7075367647058823
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 95,
          "fn": 105,
          "accuracy": 0.475
        },
        "0.01": {
          "tp": 95,
          "fn": 105,
          "accuracy": 0.475
        }
      },
      "auroc": 0.731875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 53,
          "fn": 147,
          "accuracy": 0.265
        },
        "0.01": {
          "tp": 53,
          "fn": 147,
          "accuracy": 0.265
        }
      },
      "auroc": 0.6268750000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 148,
          "fn": 252,
          "accuracy": 0.37
        },
        "0.01": {
          "tp": 148,
          "fn": 252,
          "accuracy": 0.37
        }
      },
      "auroc": 0.6793750000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        },
        "0.01": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        }
      },
      "auroc": 0.739375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        },
        "0.01": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        }
      },
      "auroc": 0.654375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 162,
          "fn": 238,
          "accuracy": 0.405
        },
        "0.01": {
          "tp": 162,
          "fn": 238,
          "accuracy": 0.405
        }
      },
      "auroc": 0.696875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 193,
          "fn": 207,
          "accuracy": 0.4825
        },
        "0.01": {
          "tp": 193,
          "fn": 207,
          "accuracy": 0.4825
        }
      },
      "auroc": 0.735625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 283,
          "accuracy": 0.2925
        },
        "0.01": {
          "tp": 117,
          "fn": 283,
          "accuracy": 0.2925
        }
      },
      "auroc": 0.640625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 310,
          "fn": 490,
          "accuracy": 0.3875
        },
        "0.01": {
          "tp": 310,
          "fn": 490,
          "accuracy": 0.3875
        }
      },
      "auroc": 0.688125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 149,
          "accuracy": 0.255
        },
        "0.01": {
          "tp": 51,
          "fn": 149,
          "accuracy": 0.255
        }
      },
      "auroc": 0.621875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5643750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        },
        "0.01": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        }
      },
      "auroc": 0.593125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        },
        "0.01": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        }
      },
      "auroc": 0.704375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        }
      },
      "auroc": 0.551875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 293,
          "accuracy": 0.2675
        },
        "0.01": {
          "tp": 107,
          "fn": 293,
          "accuracy": 0.2675
        }
      },
      "auroc": 0.628125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 135,
          "fn": 265,
          "accuracy": 0.3375
        },
        "0.01": {
          "tp": 135,
          "fn": 265,
          "accuracy": 0.3375
        }
      },
      "auroc": 0.663125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        },
        "0.01": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        }
      },
      "auroc": 0.558125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 614,
          "accuracy": 0.2325
        },
        "0.01": {
          "tp": 186,
          "fn": 614,
          "accuracy": 0.2325
        }
      },
      "auroc": 0.610625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 151,
          "fn": 49,
          "accuracy": 0.755
        },
        "0.01": {
          "tp": 151,
          "fn": 49,
          "accuracy": 0.755
        }
      },
      "auroc": 0.871875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        }
      },
      "auroc": 0.576875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 115,
          "fn": 85,
          "accuracy": 0.575
        },
        "0.01": {
          "tp": 115,
          "fn": 85,
          "accuracy": 0.575
        }
      },
      "auroc": 0.781875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        },
        "0.01": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        }
      },
      "auroc": 0.539375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 267,
          "accuracy": 0.3325
        },
        "0.01": {
          "tp": 133,
          "fn": 267,
          "accuracy": 0.3325
        }
      },
      "auroc": 0.660625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        },
        "0.01": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        }
      },
      "auroc": 0.558125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 317,
          "fn": 483,
          "accuracy": 0.39625
        },
        "0.01": {
          "tp": 317,
          "fn": 483,
          "accuracy": 0.39625
        }
      },
      "auroc": 0.6925
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 16,
          "fn": 184,
          "accuracy": 0.08
        },
        "0.01": {
          "tp": 16,
          "fn": 184,
          "accuracy": 0.08
        }
      },
      "auroc": 0.534375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        },
        "0.01": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        }
      },
      "auroc": 0.794375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 264,
          "accuracy": 0.34
        },
        "0.01": {
          "tp": 136,
          "fn": 264,
          "accuracy": 0.34
        }
      },
      "auroc": 0.664375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        }
      },
      "auroc": 0.821875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        },
        "0.01": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        }
      },
      "auroc": 0.594375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 171,
          "fn": 229,
          "accuracy": 0.4275
        },
        "0.01": {
          "tp": 171,
          "fn": 229,
          "accuracy": 0.4275
        }
      },
      "auroc": 0.708125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 147,
          "fn": 253,
          "accuracy": 0.3675
        },
        "0.01": {
          "tp": 147,
          "fn": 253,
          "accuracy": 0.3675
        }
      },
      "auroc": 0.678125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 160,
          "fn": 240,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 160,
          "fn": 240,
          "accuracy": 0.4
        }
      },
      "auroc": 0.694375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 307,
          "fn": 493,
          "accuracy": 0.38375
        },
        "0.01": {
          "tp": 307,
          "fn": 493,
          "accuracy": 0.38375
        }
      },
      "auroc": 0.68625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        },
        "0.01": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        }
      },
      "auroc": 0.596875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        }
      },
      "auroc": 0.556875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 334,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 66,
          "fn": 334,
          "accuracy": 0.165
        }
      },
      "auroc": 0.576875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        }
      },
      "auroc": 0.711875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.504375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        },
        "0.01": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        }
      },
      "auroc": 0.608125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 272,
          "accuracy": 0.32
        },
        "0.01": {
          "tp": 128,
          "fn": 272,
          "accuracy": 0.32
        }
      },
      "auroc": 0.654375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 371,
          "accuracy": 0.0725
        },
        "0.01": {
          "tp": 29,
          "fn": 371,
          "accuracy": 0.0725
        }
      },
      "auroc": 0.530625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 643,
          "accuracy": 0.19625
        },
        "0.01": {
          "tp": 157,
          "fn": 643,
          "accuracy": 0.19625
        }
      },
      "auroc": 0.5925
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 162,
          "fn": 38,
          "accuracy": 0.81
        },
        "0.01": {
          "tp": 162,
          "fn": 38,
          "accuracy": 0.81
        }
      },
      "auroc": 0.899375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7518750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 265,
          "fn": 135,
          "accuracy": 0.6625
        },
        "0.01": {
          "tp": 265,
          "fn": 135,
          "accuracy": 0.6625
        }
      },
      "auroc": 0.825625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 132,
          "fn": 68,
          "accuracy": 0.66
        },
        "0.01": {
          "tp": 132,
          "fn": 68,
          "accuracy": 0.66
        }
      },
      "auroc": 0.8243750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 50,
          "fn": 150,
          "accuracy": 0.25
        },
        "0.01": {
          "tp": 50,
          "fn": 150,
          "accuracy": 0.25
        }
      },
      "auroc": 0.619375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 182,
          "fn": 218,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 182,
          "fn": 218,
          "accuracy": 0.455
        }
      },
      "auroc": 0.721875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 294,
          "fn": 106,
          "accuracy": 0.735
        },
        "0.01": {
          "tp": 294,
          "fn": 106,
          "accuracy": 0.735
        }
      },
      "auroc": 0.861875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 153,
          "fn": 247,
          "accuracy": 0.3825
        },
        "0.01": {
          "tp": 153,
          "fn": 247,
          "accuracy": 0.3825
        }
      },
      "auroc": 0.685625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 447,
          "fn": 353,
          "accuracy": 0.55875
        },
        "0.01": {
          "tp": 447,
          "fn": 353,
          "accuracy": 0.55875
        }
      },
      "auroc": 0.7737499999999999
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        },
        "0.01": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        }
      },
      "auroc": 0.819375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        },
        "0.01": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        }
      },
      "auroc": 0.819375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 263,
          "fn": 137,
          "accuracy": 0.6575
        },
        "0.01": {
          "tp": 263,
          "fn": 137,
          "accuracy": 0.6575
        }
      },
      "auroc": 0.823125
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 263,
          "fn": 137,
          "accuracy": 0.6575
        },
        "0.01": {
          "tp": 263,
          "fn": 137,
          "accuracy": 0.6575
        }
      },
      "auroc": 0.823125
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 121,
          "accuracy": 0.395
        },
        "0.01": {
          "tp": 79,
          "fn": 121,
          "accuracy": 0.395
        }
      },
      "auroc": 0.691875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 121,
          "accuracy": 0.395
        },
        "0.01": {
          "tp": 79,
          "fn": 121,
          "accuracy": 0.395
        }
      },
      "auroc": 0.691875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 164,
          "fn": 236,
          "accuracy": 0.41
        },
        "0.01": {
          "tp": 164,
          "fn": 236,
          "accuracy": 0.41
        }
      },
      "auroc": 0.699375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 164,
          "fn": 236,
          "accuracy": 0.41
        },
        "0.01": {
          "tp": 164,
          "fn": 236,
          "accuracy": 0.41
        }
      },
      "auroc": 0.699375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        },
        "0.01": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        }
      },
      "auroc": 0.856875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        },
        "0.01": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        }
      },
      "auroc": 0.856875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.801875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.801875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 268,
          "fn": 132,
          "accuracy": 0.67
        },
        "0.01": {
          "tp": 268,
          "fn": 132,
          "accuracy": 0.67
        }
      },
      "auroc": 0.829375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 268,
          "fn": 132,
          "accuracy": 0.67
        },
        "0.01": {
          "tp": 268,
          "fn": 132,
          "accuracy": 0.67
        }
      },
      "auroc": 0.829375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        }
      },
      "auroc": 0.926875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        }
      },
      "auroc": 0.926875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        },
        "0.01": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        }
      },
      "auroc": 0.704375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        },
        "0.01": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        }
      },
      "auroc": 0.704375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 257,
          "fn": 143,
          "accuracy": 0.6425
        },
        "0.01": {
          "tp": 257,
          "fn": 143,
          "accuracy": 0.6425
        }
      },
      "auroc": 0.815625
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 257,
          "fn": 143,
          "accuracy": 0.6425
        },
        "0.01": {
          "tp": 257,
          "fn": 143,
          "accuracy": 0.6425
        }
      },
      "auroc": 0.815625
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        }
      },
      "auroc": 0.776875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        }
      },
      "auroc": 0.776875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        },
        "0.01": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        }
      },
      "auroc": 0.704375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        },
        "0.01": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        }
      },
      "auroc": 0.704375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 197,
          "fn": 203,
          "accuracy": 0.4925
        },
        "0.01": {
          "tp": 197,
          "fn": 203,
          "accuracy": 0.4925
        }
      },
      "auroc": 0.740625
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 197,
          "fn": 203,
          "accuracy": 0.4925
        },
        "0.01": {
          "tp": 197,
          "fn": 203,
          "accuracy": 0.4925
        }
      },
      "auroc": 0.740625
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 1165,
          "fn": 1035,
          "accuracy": 0.5295454545454545
        },
        "0.01": {
          "tp": 1165,
          "fn": 1035,
          "accuracy": 0.5295454545454545
        }
      },
      "auroc": 0.7591477272727273
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 362,
          "fn": 838,
          "accuracy": 0.3016666666666667
        },
        "0.01": {
          "tp": 362,
          "fn": 838,
          "accuracy": 0.3016666666666667
        }
      },
      "auroc": 0.6452083333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 1527,
          "fn": 1873,
          "accuracy": 0.4491176470588235
        },
        "0.01": {
          "tp": 1527,
          "fn": 1873,
          "accuracy": 0.4491176470588235
        }
      },
      "auroc": 0.7189338235294118
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 1147,
          "fn": 1053,
          "accuracy": 0.5213636363636364
        },
        "0.01": {
          "tp": 1147,
          "fn": 1053,
          "accuracy": 0.5213636363636364
        }
      },
      "auroc": 0.7550568181818182
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 199,
          "fn": 1001,
          "accuracy": 0.16583333333333333
        },
        "0.01": {
          "tp": 199,
          "fn": 1001,
          "accuracy": 0.16583333333333333
        }
      },
      "auroc": 0.5772916666666666
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 1346,
          "fn": 2054,
          "accuracy": 0.39588235294117646
        },
        "0.01": {
          "tp": 1346,
          "fn": 2054,
          "accuracy": 0.39588235294117646
        }
      },
      "auroc": 0.6923161764705883
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 2312,
          "fn": 2088,
          "accuracy": 0.5254545454545455
        },
        "0.01": {
          "tp": 2312,
          "fn": 2088,
          "accuracy": 0.5254545454545455
        }
      },
      "auroc": 0.7571022727272727
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 561,
          "fn": 1839,
          "accuracy": 0.23375
        },
        "0.01": {
          "tp": 561,
          "fn": 1839,
          "accuracy": 0.23375
        }
      },
      "auroc": 0.6112500000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 2873,
          "fn": 3927,
          "accuracy": 0.4225
        },
        "0.01": {
          "tp": 2873,
          "fn": 3927,
          "accuracy": 0.4225
        }
      },
      "auroc": 0.705625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        },
        "0.01": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        }
      },
      "auroc": 0.756875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 68,
          "fn": 132,
          "accuracy": 0.34
        },
        "0.01": {
          "tp": 68,
          "fn": 132,
          "accuracy": 0.34
        }
      },
      "auroc": 0.664375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 227,
          "accuracy": 0.4325
        },
        "0.01": {
          "tp": 173,
          "fn": 227,
          "accuracy": 0.4325
        }
      },
      "auroc": 0.7106250000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        },
        "0.01": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        }
      },
      "auroc": 0.7718750000000002
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        },
        "0.01": {
          "tp": 69,
          "fn": 131,
          "accuracy": 0.345
        }
      },
      "auroc": 0.666875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 180,
          "fn": 220,
          "accuracy": 0.45
        },
        "0.01": {
          "tp": 180,
          "fn": 220,
          "accuracy": 0.45
        }
      },
      "auroc": 0.719375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 216,
          "fn": 184,
          "accuracy": 0.54
        },
        "0.01": {
          "tp": 216,
          "fn": 184,
          "accuracy": 0.54
        }
      },
      "auroc": 0.764375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 137,
          "fn": 263,
          "accuracy": 0.3425
        },
        "0.01": {
          "tp": 137,
          "fn": 263,
          "accuracy": 0.3425
        }
      },
      "auroc": 0.665625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 353,
          "fn": 447,
          "accuracy": 0.44125
        },
        "0.01": {
          "tp": 353,
          "fn": 447,
          "accuracy": 0.44125
        }
      },
      "auroc": 0.715
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        },
        "0.01": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        }
      },
      "auroc": 0.606875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        }
      },
      "auroc": 0.556875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        }
      },
      "auroc": 0.581875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        }
      },
      "auroc": 0.551875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        }
      },
      "auroc": 0.629375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 270,
          "accuracy": 0.325
        },
        "0.01": {
          "tp": 130,
          "fn": 270,
          "accuracy": 0.325
        }
      },
      "auroc": 0.656875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 352,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 48,
          "fn": 352,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5543750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 622,
          "accuracy": 0.2225
        },
        "0.01": {
          "tp": 178,
          "fn": 622,
          "accuracy": 0.2225
        }
      },
      "auroc": 0.605625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 43,
          "accuracy": 0.785
        },
        "0.01": {
          "tp": 157,
          "fn": 43,
          "accuracy": 0.785
        }
      },
      "auroc": 0.8868750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.579375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 191,
          "fn": 209,
          "accuracy": 0.4775
        },
        "0.01": {
          "tp": 191,
          "fn": 209,
          "accuracy": 0.4775
        }
      },
      "auroc": 0.733125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        },
        "0.01": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        }
      },
      "auroc": 0.786875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        }
      },
      "auroc": 0.546875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 138,
          "fn": 262,
          "accuracy": 0.345
        },
        "0.01": {
          "tp": 138,
          "fn": 262,
          "accuracy": 0.345
        }
      },
      "auroc": 0.666875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 274,
          "fn": 126,
          "accuracy": 0.685
        },
        "0.01": {
          "tp": 274,
          "fn": 126,
          "accuracy": 0.685
        }
      },
      "auroc": 0.836875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        },
        "0.01": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        }
      },
      "auroc": 0.563125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 329,
          "fn": 471,
          "accuracy": 0.41125
        },
        "0.01": {
          "tp": 329,
          "fn": 471,
          "accuracy": 0.41125
        }
      },
      "auroc": 0.7
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        },
        "0.01": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        }
      },
      "auroc": 0.529375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        },
        "0.01": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        }
      },
      "auroc": 0.799375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 264,
          "accuracy": 0.34
        },
        "0.01": {
          "tp": 136,
          "fn": 264,
          "accuracy": 0.34
        }
      },
      "auroc": 0.664375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 64,
          "accuracy": 0.68
        },
        "0.01": {
          "tp": 136,
          "fn": 64,
          "accuracy": 0.68
        }
      },
      "auroc": 0.8343750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 154,
          "accuracy": 0.23
        },
        "0.01": {
          "tp": 46,
          "fn": 154,
          "accuracy": 0.23
        }
      },
      "auroc": 0.609375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 182,
          "fn": 218,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 182,
          "fn": 218,
          "accuracy": 0.455
        }
      },
      "auroc": 0.721875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        },
        "0.01": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        }
      },
      "auroc": 0.681875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 232,
          "accuracy": 0.42
        },
        "0.01": {
          "tp": 168,
          "fn": 232,
          "accuracy": 0.42
        }
      },
      "auroc": 0.704375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 318,
          "fn": 482,
          "accuracy": 0.3975
        },
        "0.01": {
          "tp": 318,
          "fn": 482,
          "accuracy": 0.3975
        }
      },
      "auroc": 0.693125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        },
        "0.01": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        }
      },
      "auroc": 0.594375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        }
      },
      "auroc": 0.566875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 331,
          "accuracy": 0.1725
        },
        "0.01": {
          "tp": 69,
          "fn": 331,
          "accuracy": 0.1725
        }
      },
      "auroc": 0.580625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        }
      },
      "auroc": 0.699375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        }
      },
      "auroc": 0.506875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        },
        "0.01": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        }
      },
      "auroc": 0.603125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 278,
          "accuracy": 0.305
        },
        "0.01": {
          "tp": 122,
          "fn": 278,
          "accuracy": 0.305
        }
      },
      "auroc": 0.646875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 366,
          "accuracy": 0.085
        },
        "0.01": {
          "tp": 34,
          "fn": 366,
          "accuracy": 0.085
        }
      },
      "auroc": 0.536875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 644,
          "accuracy": 0.195
        },
        "0.01": {
          "tp": 156,
          "fn": 644,
          "accuracy": 0.195
        }
      },
      "auroc": 0.591875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        },
        "0.01": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        }
      },
      "auroc": 0.916875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        }
      },
      "auroc": 0.7618750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 276,
          "fn": 124,
          "accuracy": 0.69
        },
        "0.01": {
          "tp": 276,
          "fn": 124,
          "accuracy": 0.69
        }
      },
      "auroc": 0.839375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 140,
          "fn": 60,
          "accuracy": 0.7
        },
        "0.01": {
          "tp": 140,
          "fn": 60,
          "accuracy": 0.7
        }
      },
      "auroc": 0.844375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 58,
          "fn": 142,
          "accuracy": 0.29
        },
        "0.01": {
          "tp": 58,
          "fn": 142,
          "accuracy": 0.29
        }
      },
      "auroc": 0.639375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 198,
          "fn": 202,
          "accuracy": 0.495
        },
        "0.01": {
          "tp": 198,
          "fn": 202,
          "accuracy": 0.495
        }
      },
      "auroc": 0.7418750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 309,
          "fn": 91,
          "accuracy": 0.7725
        },
        "0.01": {
          "tp": 309,
          "fn": 91,
          "accuracy": 0.7725
        }
      },
      "auroc": 0.880625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 235,
          "accuracy": 0.4125
        },
        "0.01": {
          "tp": 165,
          "fn": 235,
          "accuracy": 0.4125
        }
      },
      "auroc": 0.700625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 474,
          "fn": 326,
          "accuracy": 0.5925
        },
        "0.01": {
          "tp": 474,
          "fn": 326,
          "accuracy": 0.5925
        }
      },
      "auroc": 0.790625
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 132,
          "fn": 68,
          "accuracy": 0.66
        },
        "0.01": {
          "tp": 132,
          "fn": 68,
          "accuracy": 0.66
        }
      },
      "auroc": 0.8243750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 132,
          "fn": 68,
          "accuracy": 0.66
        },
        "0.01": {
          "tp": 132,
          "fn": 68,
          "accuracy": 0.66
        }
      },
      "auroc": 0.8243750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        },
        "0.01": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        }
      },
      "auroc": 0.819375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        },
        "0.01": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        }
      },
      "auroc": 0.819375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 262,
          "fn": 138,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 262,
          "fn": 138,
          "accuracy": 0.655
        }
      },
      "auroc": 0.821875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 262,
          "fn": 138,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 262,
          "fn": 138,
          "accuracy": 0.655
        }
      },
      "auroc": 0.821875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 177,
          "fn": 223,
          "accuracy": 0.4425
        },
        "0.01": {
          "tp": 177,
          "fn": 223,
          "accuracy": 0.4425
        }
      },
      "auroc": 0.715625
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 177,
          "fn": 223,
          "accuracy": 0.4425
        },
        "0.01": {
          "tp": 177,
          "fn": 223,
          "accuracy": 0.4425
        }
      },
      "auroc": 0.715625
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        },
        "0.01": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        }
      },
      "auroc": 0.909375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        },
        "0.01": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        }
      },
      "auroc": 0.909375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        }
      },
      "auroc": 0.821875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        }
      },
      "auroc": 0.821875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 297,
          "fn": 103,
          "accuracy": 0.7425
        },
        "0.01": {
          "tp": 297,
          "fn": 103,
          "accuracy": 0.7425
        }
      },
      "auroc": 0.8656250000000001
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 297,
          "fn": 103,
          "accuracy": 0.7425
        },
        "0.01": {
          "tp": 297,
          "fn": 103,
          "accuracy": 0.7425
        }
      },
      "auroc": 0.8656250000000001
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        },
        "0.01": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        }
      },
      "auroc": 0.9393750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        },
        "0.01": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        }
      },
      "auroc": 0.9393750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        },
        "0.01": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        }
      },
      "auroc": 0.701875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        },
        "0.01": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        }
      },
      "auroc": 0.701875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 261,
          "fn": 139,
          "accuracy": 0.6525
        },
        "0.01": {
          "tp": 261,
          "fn": 139,
          "accuracy": 0.6525
        }
      },
      "auroc": 0.820625
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 261,
          "fn": 139,
          "accuracy": 0.6525
        },
        "0.01": {
          "tp": 261,
          "fn": 139,
          "accuracy": 0.6525
        }
      },
      "auroc": 0.820625
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        },
        "0.01": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        }
      },
      "auroc": 0.786875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        },
        "0.01": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        }
      },
      "auroc": 0.786875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 89,
          "fn": 111,
          "accuracy": 0.445
        },
        "0.01": {
          "tp": 89,
          "fn": 111,
          "accuracy": 0.445
        }
      },
      "auroc": 0.716875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 89,
          "fn": 111,
          "accuracy": 0.445
        },
        "0.01": {
          "tp": 89,
          "fn": 111,
          "accuracy": 0.445
        }
      },
      "auroc": 0.716875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 206,
          "fn": 194,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 206,
          "fn": 194,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7518750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 206,
          "fn": 194,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 206,
          "fn": 194,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7518750000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1215,
          "fn": 985,
          "accuracy": 0.5522727272727272
        },
        "0.01": {
          "tp": 1215,
          "fn": 985,
          "accuracy": 0.5522727272727272
        }
      },
      "auroc": 0.7705113636363636
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 385,
          "fn": 815,
          "accuracy": 0.32083333333333336
        },
        "0.01": {
          "tp": 385,
          "fn": 815,
          "accuracy": 0.32083333333333336
        }
      },
      "auroc": 0.6547916666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1600,
          "fn": 1800,
          "accuracy": 0.47058823529411764
        },
        "0.01": {
          "tp": 1600,
          "fn": 1800,
          "accuracy": 0.47058823529411764
        }
      },
      "auroc": 0.7296691176470589
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1189,
          "fn": 1011,
          "accuracy": 0.5404545454545454
        },
        "0.01": {
          "tp": 1189,
          "fn": 1011,
          "accuracy": 0.5404545454545454
        }
      },
      "auroc": 0.7646022727272728
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 222,
          "fn": 978,
          "accuracy": 0.185
        },
        "0.01": {
          "tp": 222,
          "fn": 978,
          "accuracy": 0.185
        }
      },
      "auroc": 0.586875
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1411,
          "fn": 1989,
          "accuracy": 0.415
        },
        "0.01": {
          "tp": 1411,
          "fn": 1989,
          "accuracy": 0.415
        }
      },
      "auroc": 0.701875
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 2404,
          "fn": 1996,
          "accuracy": 0.5463636363636364
        },
        "0.01": {
          "tp": 2404,
          "fn": 1996,
          "accuracy": 0.5463636363636364
        }
      },
      "auroc": 0.7675568181818182
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 607,
          "fn": 1793,
          "accuracy": 0.2529166666666667
        },
        "0.01": {
          "tp": 607,
          "fn": 1793,
          "accuracy": 0.2529166666666667
        }
      },
      "auroc": 0.6208333333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 3011,
          "fn": 3789,
          "accuracy": 0.44279411764705884
        },
        "0.01": {
          "tp": 3011,
          "fn": 3789,
          "accuracy": 0.44279411764705884
        }
      },
      "auroc": 0.7157720588235295
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        }
      },
      "auroc": 0.584375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        },
        "0.01": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        }
      },
      "auroc": 0.569375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 334,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 66,
          "fn": 334,
          "accuracy": 0.165
        }
      },
      "auroc": 0.576875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        },
        "0.01": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        }
      },
      "auroc": 0.594375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        }
      },
      "auroc": 0.581875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 75,
          "fn": 325,
          "accuracy": 0.1875
        },
        "0.01": {
          "tp": 75,
          "fn": 325,
          "accuracy": 0.1875
        }
      },
      "auroc": 0.588125
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 76,
          "fn": 324,
          "accuracy": 0.19
        },
        "0.01": {
          "tp": 76,
          "fn": 324,
          "accuracy": 0.19
        }
      },
      "auroc": 0.589375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        },
        "0.01": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        }
      },
      "auroc": 0.575625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 141,
          "fn": 659,
          "accuracy": 0.17625
        },
        "0.01": {
          "tp": 141,
          "fn": 659,
          "accuracy": 0.17625
        }
      },
      "auroc": 0.5825
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 145,
          "accuracy": 0.275
        },
        "0.01": {
          "tp": 55,
          "fn": 145,
          "accuracy": 0.275
        }
      },
      "auroc": 0.631875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 44,
          "fn": 156,
          "accuracy": 0.22
        },
        "0.01": {
          "tp": 44,
          "fn": 156,
          "accuracy": 0.22
        }
      },
      "auroc": 0.604375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 99,
          "fn": 301,
          "accuracy": 0.2475
        },
        "0.01": {
          "tp": 99,
          "fn": 301,
          "accuracy": 0.2475
        }
      },
      "auroc": 0.618125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5543750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        },
        "0.01": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        }
      },
      "auroc": 0.596875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        },
        "0.01": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        }
      },
      "auroc": 0.575625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        },
        "0.01": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        }
      },
      "auroc": 0.593125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 315,
          "accuracy": 0.2125
        },
        "0.01": {
          "tp": 85,
          "fn": 315,
          "accuracy": 0.2125
        }
      },
      "auroc": 0.600625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 164,
          "fn": 636,
          "accuracy": 0.205
        },
        "0.01": {
          "tp": 164,
          "fn": 636,
          "accuracy": 0.205
        }
      },
      "auroc": 0.596875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 42,
          "fn": 158,
          "accuracy": 0.21
        },
        "0.01": {
          "tp": 42,
          "fn": 158,
          "accuracy": 0.21
        }
      },
      "auroc": 0.599375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        }
      },
      "auroc": 0.574375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 326,
          "accuracy": 0.185
        },
        "0.01": {
          "tp": 74,
          "fn": 326,
          "accuracy": 0.185
        }
      },
      "auroc": 0.586875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        },
        "0.01": {
          "tp": 40,
          "fn": 160,
          "accuracy": 0.2
        }
      },
      "auroc": 0.594375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 42,
          "fn": 158,
          "accuracy": 0.21
        },
        "0.01": {
          "tp": 42,
          "fn": 158,
          "accuracy": 0.21
        }
      },
      "auroc": 0.599375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 318,
          "accuracy": 0.205
        },
        "0.01": {
          "tp": 82,
          "fn": 318,
          "accuracy": 0.205
        }
      },
      "auroc": 0.596875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 318,
          "accuracy": 0.205
        },
        "0.01": {
          "tp": 82,
          "fn": 318,
          "accuracy": 0.205
        }
      },
      "auroc": 0.596875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 326,
          "accuracy": 0.185
        },
        "0.01": {
          "tp": 74,
          "fn": 326,
          "accuracy": 0.185
        }
      },
      "auroc": 0.586875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 644,
          "accuracy": 0.195
        },
        "0.01": {
          "tp": 156,
          "fn": 644,
          "accuracy": 0.195
        }
      },
      "auroc": 0.591875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 72,
          "fn": 128,
          "accuracy": 0.36
        },
        "0.01": {
          "tp": 72,
          "fn": 128,
          "accuracy": 0.36
        }
      },
      "auroc": 0.6743750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5643750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 300,
          "accuracy": 0.25
        },
        "0.01": {
          "tp": 100,
          "fn": 300,
          "accuracy": 0.25
        }
      },
      "auroc": 0.619375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        }
      },
      "auroc": 0.581875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        },
        "0.01": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        }
      },
      "auroc": 0.524375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        },
        "0.01": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        }
      },
      "auroc": 0.553125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 293,
          "accuracy": 0.2675
        },
        "0.01": {
          "tp": 107,
          "fn": 293,
          "accuracy": 0.2675
        }
      },
      "auroc": 0.628125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        },
        "0.01": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        }
      },
      "auroc": 0.544375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 147,
          "fn": 653,
          "accuracy": 0.18375
        },
        "0.01": {
          "tp": 147,
          "fn": 653,
          "accuracy": 0.18375
        }
      },
      "auroc": 0.58625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 129,
          "accuracy": 0.355
        },
        "0.01": {
          "tp": 71,
          "fn": 129,
          "accuracy": 0.355
        }
      },
      "auroc": 0.671875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        },
        "0.01": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        }
      },
      "auroc": 0.586875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        }
      },
      "auroc": 0.629375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        }
      },
      "auroc": 0.546875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        }
      },
      "auroc": 0.516875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        }
      },
      "auroc": 0.531875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 308,
          "accuracy": 0.23
        },
        "0.01": {
          "tp": 92,
          "fn": 308,
          "accuracy": 0.23
        }
      },
      "auroc": 0.609375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 354,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 46,
          "fn": 354,
          "accuracy": 0.115
        }
      },
      "auroc": 0.551875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 138,
          "fn": 662,
          "accuracy": 0.1725
        },
        "0.01": {
          "tp": 138,
          "fn": 662,
          "accuracy": 0.1725
        }
      },
      "auroc": 0.580625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 75,
          "fn": 125,
          "accuracy": 0.375
        },
        "0.01": {
          "tp": 75,
          "fn": 125,
          "accuracy": 0.375
        }
      },
      "auroc": 0.681875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 144,
          "accuracy": 0.28
        },
        "0.01": {
          "tp": 56,
          "fn": 144,
          "accuracy": 0.28
        }
      },
      "auroc": 0.634375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 131,
          "fn": 269,
          "accuracy": 0.3275
        },
        "0.01": {
          "tp": 131,
          "fn": 269,
          "accuracy": 0.3275
        }
      },
      "auroc": 0.6581250000000001
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 145,
          "accuracy": 0.275
        },
        "0.01": {
          "tp": 55,
          "fn": 145,
          "accuracy": 0.275
        }
      },
      "auroc": 0.631875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        },
        "0.01": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        }
      },
      "auroc": 0.606875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 300,
          "accuracy": 0.25
        },
        "0.01": {
          "tp": 100,
          "fn": 300,
          "accuracy": 0.25
        }
      },
      "auroc": 0.619375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 270,
          "accuracy": 0.325
        },
        "0.01": {
          "tp": 130,
          "fn": 270,
          "accuracy": 0.325
        }
      },
      "auroc": 0.656875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        },
        "0.01": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        }
      },
      "auroc": 0.620625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 231,
          "fn": 569,
          "accuracy": 0.28875
        },
        "0.01": {
          "tp": 231,
          "fn": 569,
          "accuracy": 0.28875
        }
      },
      "auroc": 0.63875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        },
        "0.01": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        }
      },
      "auroc": 0.856875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        },
        "0.01": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        }
      },
      "auroc": 0.856875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        },
        "0.01": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        }
      },
      "auroc": 0.854375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        },
        "0.01": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        }
      },
      "auroc": 0.854375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 289,
          "fn": 111,
          "accuracy": 0.7225
        },
        "0.01": {
          "tp": 289,
          "fn": 111,
          "accuracy": 0.7225
        }
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 289,
          "fn": 111,
          "accuracy": 0.7225
        },
        "0.01": {
          "tp": 289,
          "fn": 111,
          "accuracy": 0.7225
        }
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        },
        "0.01": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        }
      },
      "auroc": 0.606875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        },
        "0.01": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        }
      },
      "auroc": 0.606875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.579375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.579375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        },
        "0.01": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        }
      },
      "auroc": 0.593125
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        },
        "0.01": {
          "tp": 79,
          "fn": 321,
          "accuracy": 0.1975
        }
      },
      "auroc": 0.593125
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        }
      },
      "auroc": 0.574375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        }
      },
      "auroc": 0.574375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        }
      },
      "auroc": 0.566875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        }
      },
      "auroc": 0.566875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 61,
          "fn": 339,
          "accuracy": 0.1525
        },
        "0.01": {
          "tp": 61,
          "fn": 339,
          "accuracy": 0.1525
        }
      },
      "auroc": 0.5706250000000002
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 61,
          "fn": 339,
          "accuracy": 0.1525
        },
        "0.01": {
          "tp": 61,
          "fn": 339,
          "accuracy": 0.1525
        }
      },
      "auroc": 0.5706250000000002
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        },
        "0.01": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        }
      },
      "auroc": 0.586875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        },
        "0.01": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        }
      },
      "auroc": 0.586875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 277,
          "accuracy": 0.3075
        },
        "0.01": {
          "tp": 123,
          "fn": 277,
          "accuracy": 0.3075
        }
      },
      "auroc": 0.6481250000000001
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 277,
          "accuracy": 0.3075
        },
        "0.01": {
          "tp": 123,
          "fn": 277,
          "accuracy": 0.3075
        }
      },
      "auroc": 0.6481250000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        },
        "0.01": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        }
      },
      "auroc": 0.636875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        },
        "0.01": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        }
      },
      "auroc": 0.636875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        }
      },
      "auroc": 0.661875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        },
        "0.01": {
          "tp": 67,
          "fn": 133,
          "accuracy": 0.335
        }
      },
      "auroc": 0.661875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 124,
          "fn": 276,
          "accuracy": 0.31
        },
        "0.01": {
          "tp": 124,
          "fn": 276,
          "accuracy": 0.31
        }
      },
      "auroc": 0.649375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 124,
          "fn": 276,
          "accuracy": 0.31
        },
        "0.01": {
          "tp": 124,
          "fn": 276,
          "accuracy": 0.31
        }
      },
      "auroc": 0.649375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 716,
          "fn": 1484,
          "accuracy": 0.32545454545454544
        },
        "0.01": {
          "tp": 716,
          "fn": 1484,
          "accuracy": 0.32545454545454544
        }
      },
      "auroc": 0.6571022727272727
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 227,
          "fn": 973,
          "accuracy": 0.18916666666666668
        },
        "0.01": {
          "tp": 227,
          "fn": 973,
          "accuracy": 0.18916666666666668
        }
      },
      "auroc": 0.5889583333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 943,
          "fn": 2457,
          "accuracy": 0.2773529411764706
        },
        "0.01": {
          "tp": 943,
          "fn": 2457,
          "accuracy": 0.2773529411764706
        }
      },
      "auroc": 0.6330514705882353
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 526,
          "fn": 1674,
          "accuracy": 0.2390909090909091
        },
        "0.01": {
          "tp": 526,
          "fn": 1674,
          "accuracy": 0.2390909090909091
        }
      },
      "auroc": 0.6139204545454545
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 1016,
          "accuracy": 0.15333333333333332
        },
        "0.01": {
          "tp": 184,
          "fn": 1016,
          "accuracy": 0.15333333333333332
        }
      },
      "auroc": 0.5710416666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 710,
          "fn": 2690,
          "accuracy": 0.2088235294117647
        },
        "0.01": {
          "tp": 710,
          "fn": 2690,
          "accuracy": 0.2088235294117647
        }
      },
      "auroc": 0.5987867647058823
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 1242,
          "fn": 3158,
          "accuracy": 0.2822727272727273
        },
        "0.01": {
          "tp": 1242,
          "fn": 3158,
          "accuracy": 0.2822727272727273
        }
      },
      "auroc": 0.6355113636363636
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 411,
          "fn": 1989,
          "accuracy": 0.17125
        },
        "0.01": {
          "tp": 411,
          "fn": 1989,
          "accuracy": 0.17125
        }
      },
      "auroc": 0.5800000000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 1653,
          "fn": 5147,
          "accuracy": 0.24308823529411766
        },
        "0.01": {
          "tp": 1653,
          "fn": 5147,
          "accuracy": 0.24308823529411766
        }
      },
      "auroc": 0.6159191176470589
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        }
      },
      "auroc": 0.7618750000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 72,
          "fn": 128,
          "accuracy": 0.36
        },
        "0.01": {
          "tp": 72,
          "fn": 128,
          "accuracy": 0.36
        }
      },
      "auroc": 0.6743750000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 179,
          "fn": 221,
          "accuracy": 0.4475
        },
        "0.01": {
          "tp": 179,
          "fn": 221,
          "accuracy": 0.4475
        }
      },
      "auroc": 0.718125
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 114,
          "fn": 86,
          "accuracy": 0.57
        },
        "0.01": {
          "tp": 114,
          "fn": 86,
          "accuracy": 0.57
        }
      },
      "auroc": 0.7793749999999999
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        },
        "0.01": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        }
      },
      "auroc": 0.669375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 221,
          "fn": 179,
          "accuracy": 0.5525
        },
        "0.01": {
          "tp": 221,
          "fn": 179,
          "accuracy": 0.5525
        }
      },
      "auroc": 0.770625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 142,
          "fn": 258,
          "accuracy": 0.355
        },
        "0.01": {
          "tp": 142,
          "fn": 258,
          "accuracy": 0.355
        }
      },
      "auroc": 0.671875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 363,
          "fn": 437,
          "accuracy": 0.45375
        },
        "0.01": {
          "tp": 363,
          "fn": 437,
          "accuracy": 0.45375
        }
      },
      "auroc": 0.72125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        },
        "0.01": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        }
      },
      "auroc": 0.606875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        }
      },
      "auroc": 0.556875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        }
      },
      "auroc": 0.581875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        }
      },
      "auroc": 0.711875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        }
      },
      "auroc": 0.551875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 290,
          "accuracy": 0.275
        },
        "0.01": {
          "tp": 110,
          "fn": 290,
          "accuracy": 0.275
        }
      },
      "auroc": 0.631875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 132,
          "fn": 268,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 132,
          "fn": 268,
          "accuracy": 0.33
        }
      },
      "auroc": 0.659375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 352,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 48,
          "fn": 352,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5543750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 180,
          "fn": 620,
          "accuracy": 0.225
        },
        "0.01": {
          "tp": 180,
          "fn": 620,
          "accuracy": 0.225
        }
      },
      "auroc": 0.606875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        },
        "0.01": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        }
      },
      "auroc": 0.8968750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.579375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 195,
          "fn": 205,
          "accuracy": 0.4875
        },
        "0.01": {
          "tp": 195,
          "fn": 205,
          "accuracy": 0.4875
        }
      },
      "auroc": 0.738125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        },
        "0.01": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        }
      },
      "auroc": 0.7893749999999999
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        }
      },
      "auroc": 0.546875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        },
        "0.01": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        }
      },
      "auroc": 0.668125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 279,
          "fn": 121,
          "accuracy": 0.6975
        },
        "0.01": {
          "tp": 279,
          "fn": 121,
          "accuracy": 0.6975
        }
      },
      "auroc": 0.843125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        },
        "0.01": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        }
      },
      "auroc": 0.563125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 334,
          "fn": 466,
          "accuracy": 0.4175
        },
        "0.01": {
          "tp": 334,
          "fn": 466,
          "accuracy": 0.4175
        }
      },
      "auroc": 0.703125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        },
        "0.01": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        }
      },
      "auroc": 0.529375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        },
        "0.01": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        }
      },
      "auroc": 0.8043750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 138,
          "fn": 262,
          "accuracy": 0.345
        },
        "0.01": {
          "tp": 138,
          "fn": 262,
          "accuracy": 0.345
        }
      },
      "auroc": 0.666875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 64,
          "accuracy": 0.68
        },
        "0.01": {
          "tp": 136,
          "fn": 64,
          "accuracy": 0.68
        }
      },
      "auroc": 0.8343750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        },
        "0.01": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        }
      },
      "auroc": 0.614375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        },
        "0.01": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        }
      },
      "auroc": 0.681875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 172,
          "fn": 228,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 172,
          "fn": 228,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 322,
          "fn": 478,
          "accuracy": 0.4025
        },
        "0.01": {
          "tp": 322,
          "fn": 478,
          "accuracy": 0.4025
        }
      },
      "auroc": 0.695625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        },
        "0.01": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        }
      },
      "auroc": 0.591875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5643750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 333,
          "accuracy": 0.1675
        },
        "0.01": {
          "tp": 67,
          "fn": 333,
          "accuracy": 0.1675
        }
      },
      "auroc": 0.578125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        }
      },
      "auroc": 0.699375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        }
      },
      "auroc": 0.506875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        },
        "0.01": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        }
      },
      "auroc": 0.603125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 121,
          "fn": 279,
          "accuracy": 0.3025
        },
        "0.01": {
          "tp": 121,
          "fn": 279,
          "accuracy": 0.3025
        }
      },
      "auroc": 0.645625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        },
        "0.01": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        }
      },
      "auroc": 0.535625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 154,
          "fn": 646,
          "accuracy": 0.1925
        },
        "0.01": {
          "tp": 154,
          "fn": 646,
          "accuracy": 0.1925
        }
      },
      "auroc": 0.590625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        },
        "0.01": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        }
      },
      "auroc": 0.919375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.769375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 280,
          "fn": 120,
          "accuracy": 0.7
        },
        "0.01": {
          "tp": 280,
          "fn": 120,
          "accuracy": 0.7
        }
      },
      "auroc": 0.844375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        },
        "0.01": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        }
      },
      "auroc": 0.854375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        },
        "0.01": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        }
      },
      "auroc": 0.636875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 201,
          "fn": 199,
          "accuracy": 0.5025
        },
        "0.01": {
          "tp": 201,
          "fn": 199,
          "accuracy": 0.5025
        }
      },
      "auroc": 0.745625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        },
        "0.01": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        }
      },
      "auroc": 0.8868750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 167,
          "fn": 233,
          "accuracy": 0.4175
        },
        "0.01": {
          "tp": 167,
          "fn": 233,
          "accuracy": 0.4175
        }
      },
      "auroc": 0.703125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 481,
          "fn": 319,
          "accuracy": 0.60125
        },
        "0.01": {
          "tp": 481,
          "fn": 319,
          "accuracy": 0.60125
        }
      },
      "auroc": 0.7949999999999999
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        },
        "0.01": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        }
      },
      "auroc": 0.829375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        },
        "0.01": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        }
      },
      "auroc": 0.829375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        },
        "0.01": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        }
      },
      "auroc": 0.828125
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        },
        "0.01": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        }
      },
      "auroc": 0.828125
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        }
      },
      "auroc": 0.721875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        }
      },
      "auroc": 0.721875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 177,
          "fn": 223,
          "accuracy": 0.4425
        },
        "0.01": {
          "tp": 177,
          "fn": 223,
          "accuracy": 0.4425
        }
      },
      "auroc": 0.715625
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 177,
          "fn": 223,
          "accuracy": 0.4425
        },
        "0.01": {
          "tp": 177,
          "fn": 223,
          "accuracy": 0.4425
        }
      },
      "auroc": 0.715625
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        },
        "0.01": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        }
      },
      "auroc": 0.919375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        },
        "0.01": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        }
      },
      "auroc": 0.919375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        }
      },
      "auroc": 0.821875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        }
      },
      "auroc": 0.821875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        },
        "0.01": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        }
      },
      "auroc": 0.870625
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        },
        "0.01": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        }
      },
      "auroc": 0.870625
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        }
      },
      "auroc": 0.941875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        }
      },
      "auroc": 0.941875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 265,
          "fn": 135,
          "accuracy": 0.6625
        },
        "0.01": {
          "tp": 265,
          "fn": 135,
          "accuracy": 0.6625
        }
      },
      "auroc": 0.825625
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 265,
          "fn": 135,
          "accuracy": 0.6625
        },
        "0.01": {
          "tp": 265,
          "fn": 135,
          "accuracy": 0.6625
        }
      },
      "auroc": 0.825625
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        },
        "0.01": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        }
      },
      "auroc": 0.794375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        },
        "0.01": {
          "tp": 120,
          "fn": 80,
          "accuracy": 0.6
        }
      },
      "auroc": 0.794375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        }
      },
      "auroc": 0.726875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        }
      },
      "auroc": 0.726875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 213,
          "fn": 187,
          "accuracy": 0.5325
        },
        "0.01": {
          "tp": 213,
          "fn": 187,
          "accuracy": 0.5325
        }
      },
      "auroc": 0.760625
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 213,
          "fn": 187,
          "accuracy": 0.5325
        },
        "0.01": {
          "tp": 213,
          "fn": 187,
          "accuracy": 0.5325
        }
      },
      "auroc": 0.760625
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1230,
          "fn": 970,
          "accuracy": 0.5590909090909091
        },
        "0.01": {
          "tp": 1230,
          "fn": 970,
          "accuracy": 0.5590909090909091
        }
      },
      "auroc": 0.7739204545454546
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 393,
          "fn": 807,
          "accuracy": 0.3275
        },
        "0.01": {
          "tp": 393,
          "fn": 807,
          "accuracy": 0.3275
        }
      },
      "auroc": 0.6581250000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1623,
          "fn": 1777,
          "accuracy": 0.4773529411764706
        },
        "0.01": {
          "tp": 1623,
          "fn": 1777,
          "accuracy": 0.4773529411764706
        }
      },
      "auroc": 0.7330514705882353
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1210,
          "fn": 990,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 1210,
          "fn": 990,
          "accuracy": 0.55
        }
      },
      "auroc": 0.769375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 224,
          "fn": 976,
          "accuracy": 0.18666666666666668
        },
        "0.01": {
          "tp": 224,
          "fn": 976,
          "accuracy": 0.18666666666666668
        }
      },
      "auroc": 0.5877083333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1434,
          "fn": 1966,
          "accuracy": 0.42176470588235293
        },
        "0.01": {
          "tp": 1434,
          "fn": 1966,
          "accuracy": 0.42176470588235293
        }
      },
      "auroc": 0.7052573529411765
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 2440,
          "fn": 1960,
          "accuracy": 0.5545454545454546
        },
        "0.01": {
          "tp": 2440,
          "fn": 1960,
          "accuracy": 0.5545454545454546
        }
      },
      "auroc": 0.7716477272727273
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 617,
          "fn": 1783,
          "accuracy": 0.25708333333333333
        },
        "0.01": {
          "tp": 617,
          "fn": 1783,
          "accuracy": 0.25708333333333333
        }
      },
      "auroc": 0.6229166666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 3057,
          "fn": 3743,
          "accuracy": 0.4495588235294118
        },
        "0.01": {
          "tp": 3057,
          "fn": 3743,
          "accuracy": 0.4495588235294118
        }
      },
      "auroc": 0.719154411764706
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        }
      },
      "auroc": 0.531875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        }
      },
      "auroc": 0.516875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 376,
          "accuracy": 0.06
        },
        "0.01": {
          "tp": 24,
          "fn": 376,
          "accuracy": 0.06
        }
      },
      "auroc": 0.524375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 26,
          "fn": 174,
          "accuracy": 0.13
        },
        "0.01": {
          "tp": 26,
          "fn": 174,
          "accuracy": 0.13
        }
      },
      "auroc": 0.559375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 193,
          "accuracy": 0.035
        },
        "0.01": {
          "tp": 7,
          "fn": 193,
          "accuracy": 0.035
        }
      },
      "auroc": 0.511875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        },
        "0.01": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        }
      },
      "auroc": 0.535625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 359,
          "accuracy": 0.1025
        },
        "0.01": {
          "tp": 41,
          "fn": 359,
          "accuracy": 0.1025
        }
      },
      "auroc": 0.545625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 16,
          "fn": 384,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 16,
          "fn": 384,
          "accuracy": 0.04
        }
      },
      "auroc": 0.514375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 743,
          "accuracy": 0.07125
        },
        "0.01": {
          "tp": 57,
          "fn": 743,
          "accuracy": 0.07125
        }
      },
      "auroc": 0.53
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5493750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        }
      },
      "auroc": 0.581875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 343,
          "accuracy": 0.1425
        },
        "0.01": {
          "tp": 57,
          "fn": 343,
          "accuracy": 0.1425
        }
      },
      "auroc": 0.565625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        }
      },
      "auroc": 0.659375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        },
        "0.01": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        }
      },
      "auroc": 0.569375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 96,
          "fn": 304,
          "accuracy": 0.24
        },
        "0.01": {
          "tp": 96,
          "fn": 304,
          "accuracy": 0.24
        }
      },
      "auroc": 0.614375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 312,
          "accuracy": 0.22
        },
        "0.01": {
          "tp": 88,
          "fn": 312,
          "accuracy": 0.22
        }
      },
      "auroc": 0.604375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        },
        "0.01": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        }
      },
      "auroc": 0.575625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 153,
          "fn": 647,
          "accuracy": 0.19125
        },
        "0.01": {
          "tp": 153,
          "fn": 647,
          "accuracy": 0.19125
        }
      },
      "auroc": 0.59
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        }
      },
      "auroc": 0.571875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.504375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 365,
          "accuracy": 0.0875
        },
        "0.01": {
          "tp": 35,
          "fn": 365,
          "accuracy": 0.0875
        }
      },
      "auroc": 0.538125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        },
        "0.01": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        }
      },
      "auroc": 0.524375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.514375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 20,
          "fn": 380,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 20,
          "fn": 380,
          "accuracy": 0.05
        }
      },
      "auroc": 0.519375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 357,
          "accuracy": 0.1075
        },
        "0.01": {
          "tp": 43,
          "fn": 357,
          "accuracy": 0.1075
        }
      },
      "auroc": 0.548125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 388,
          "accuracy": 0.03
        },
        "0.01": {
          "tp": 12,
          "fn": 388,
          "accuracy": 0.03
        }
      },
      "auroc": 0.509375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 745,
          "accuracy": 0.06875
        },
        "0.01": {
          "tp": 55,
          "fn": 745,
          "accuracy": 0.06875
        }
      },
      "auroc": 0.52875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        }
      },
      "auroc": 0.516875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        },
        "0.01": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        }
      },
      "auroc": 0.719375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 99,
          "fn": 301,
          "accuracy": 0.2475
        },
        "0.01": {
          "tp": 99,
          "fn": 301,
          "accuracy": 0.2475
        }
      },
      "auroc": 0.618125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        }
      },
      "auroc": 0.726875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        }
      },
      "auroc": 0.601875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 136,
          "fn": 264,
          "accuracy": 0.34
        },
        "0.01": {
          "tp": 136,
          "fn": 264,
          "accuracy": 0.34
        }
      },
      "auroc": 0.664375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 102,
          "fn": 298,
          "accuracy": 0.255
        },
        "0.01": {
          "tp": 102,
          "fn": 298,
          "accuracy": 0.255
        }
      },
      "auroc": 0.621875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 267,
          "accuracy": 0.3325
        },
        "0.01": {
          "tp": 133,
          "fn": 267,
          "accuracy": 0.3325
        }
      },
      "auroc": 0.660625
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 235,
          "fn": 565,
          "accuracy": 0.29375
        },
        "0.01": {
          "tp": 235,
          "fn": 565,
          "accuracy": 0.29375
        }
      },
      "auroc": 0.64125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5493750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.521875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        },
        "0.01": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        }
      },
      "auroc": 0.535625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        }
      },
      "auroc": 0.601875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        }
      },
      "auroc": 0.519375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 53,
          "fn": 347,
          "accuracy": 0.1325
        },
        "0.01": {
          "tp": 53,
          "fn": 347,
          "accuracy": 0.1325
        }
      },
      "auroc": 0.560625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        },
        "0.01": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        }
      },
      "auroc": 0.575625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 379,
          "accuracy": 0.0525
        },
        "0.01": {
          "tp": 21,
          "fn": 379,
          "accuracy": 0.0525
        }
      },
      "auroc": 0.520625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 714,
          "accuracy": 0.1075
        },
        "0.01": {
          "tp": 86,
          "fn": 714,
          "accuracy": 0.1075
        }
      },
      "auroc": 0.548125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        },
        "0.01": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        }
      },
      "auroc": 0.596875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.514375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 351,
          "accuracy": 0.1225
        },
        "0.01": {
          "tp": 49,
          "fn": 351,
          "accuracy": 0.1225
        }
      },
      "auroc": 0.555625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5543750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        }
      },
      "auroc": 0.516875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        },
        "0.01": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        }
      },
      "auroc": 0.535625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        },
        "0.01": {
          "tp": 65,
          "fn": 335,
          "accuracy": 0.1625
        }
      },
      "auroc": 0.575625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 383,
          "accuracy": 0.0425
        },
        "0.01": {
          "tp": 17,
          "fn": 383,
          "accuracy": 0.0425
        }
      },
      "auroc": 0.515625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 718,
          "accuracy": 0.1025
        },
        "0.01": {
          "tp": 82,
          "fn": 718,
          "accuracy": 0.1025
        }
      },
      "auroc": 0.545625
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        }
      },
      "auroc": 0.776875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        }
      },
      "auroc": 0.776875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        }
      },
      "auroc": 0.774375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        }
      },
      "auroc": 0.774375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 225,
          "fn": 175,
          "accuracy": 0.5625
        },
        "0.01": {
          "tp": 225,
          "fn": 175,
          "accuracy": 0.5625
        }
      },
      "auroc": 0.775625
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 225,
          "fn": 175,
          "accuracy": 0.5625
        },
        "0.01": {
          "tp": 225,
          "fn": 175,
          "accuracy": 0.5625
        }
      },
      "auroc": 0.775625
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        }
      },
      "auroc": 0.551875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        }
      },
      "auroc": 0.551875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        }
      },
      "auroc": 0.546875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        }
      },
      "auroc": 0.546875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5493750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5493750000000001
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.579375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.579375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.521875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.521875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 355,
          "accuracy": 0.1125
        },
        "0.01": {
          "tp": 45,
          "fn": 355,
          "accuracy": 0.1125
        }
      },
      "auroc": 0.550625
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 355,
          "accuracy": 0.1125
        },
        "0.01": {
          "tp": 45,
          "fn": 355,
          "accuracy": 0.1125
        }
      },
      "auroc": 0.550625
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        },
        "0.01": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        }
      },
      "auroc": 0.669375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        },
        "0.01": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        }
      },
      "auroc": 0.669375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        },
        "0.01": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        }
      },
      "auroc": 0.501875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        },
        "0.01": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        }
      },
      "auroc": 0.501875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        },
        "0.01": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        }
      },
      "auroc": 0.5856250000000001
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        },
        "0.01": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        }
      },
      "auroc": 0.5856250000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        }
      },
      "auroc": 0.584375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        }
      },
      "auroc": 0.584375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5643750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5643750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        }
      },
      "auroc": 0.574375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        }
      },
      "auroc": 0.574375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 416,
          "fn": 1784,
          "accuracy": 0.1890909090909091
        },
        "0.01": {
          "tp": 416,
          "fn": 1784,
          "accuracy": 0.1890909090909091
        }
      },
      "auroc": 0.5889204545454545
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 157,
          "fn": 1043,
          "accuracy": 0.13083333333333333
        },
        "0.01": {
          "tp": 157,
          "fn": 1043,
          "accuracy": 0.13083333333333333
        }
      },
      "auroc": 0.5597916666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 573,
          "fn": 2827,
          "accuracy": 0.16852941176470587
        },
        "0.01": {
          "tp": 573,
          "fn": 2827,
          "accuracy": 0.16852941176470587
        }
      },
      "auroc": 0.5786397058823529
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 439,
          "fn": 1761,
          "accuracy": 0.19954545454545455
        },
        "0.01": {
          "tp": 439,
          "fn": 1761,
          "accuracy": 0.19954545454545455
        }
      },
      "auroc": 0.5941477272727272
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 1093,
          "accuracy": 0.08916666666666667
        },
        "0.01": {
          "tp": 107,
          "fn": 1093,
          "accuracy": 0.08916666666666667
        }
      },
      "auroc": 0.5389583333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 546,
          "fn": 2854,
          "accuracy": 0.16058823529411764
        },
        "0.01": {
          "tp": 546,
          "fn": 2854,
          "accuracy": 0.16058823529411764
        }
      },
      "auroc": 0.5746691176470589
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 855,
          "fn": 3545,
          "accuracy": 0.1943181818181818
        },
        "0.01": {
          "tp": 855,
          "fn": 3545,
          "accuracy": 0.1943181818181818
        }
      },
      "auroc": 0.5915340909090909
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 264,
          "fn": 2136,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 264,
          "fn": 2136,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5493750000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 1119,
          "fn": 5681,
          "accuracy": 0.16455882352941176
        },
        "0.01": {
          "tp": 1119,
          "fn": 5681,
          "accuracy": 0.16455882352941176
        }
      },
      "auroc": 0.5766544117647059
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.495625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.495625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 799,
          "accuracy": 0.00125
        },
        "0.01": {
          "tp": 1,
          "fn": 799,
          "accuracy": 0.00125
        }
      },
      "auroc": 0.495
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        },
        "0.01": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        }
      },
      "auroc": 0.539375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 19,
          "fn": 381,
          "accuracy": 0.0475
        },
        "0.01": {
          "tp": 19,
          "fn": 381,
          "accuracy": 0.0475
        }
      },
      "auroc": 0.5181250000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5493750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.514375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        }
      },
      "auroc": 0.531875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        },
        "0.01": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        }
      },
      "auroc": 0.544375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 391,
          "accuracy": 0.0225
        },
        "0.01": {
          "tp": 9,
          "fn": 391,
          "accuracy": 0.0225
        }
      },
      "auroc": 0.505625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 751,
          "accuracy": 0.06125
        },
        "0.01": {
          "tp": 49,
          "fn": 751,
          "accuracy": 0.06125
        }
      },
      "auroc": 0.525
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        },
        "0.01": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        }
      },
      "auroc": 0.501875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.504375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        },
        "0.01": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        }
      },
      "auroc": 0.503125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.504375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 394,
          "accuracy": 0.015
        },
        "0.01": {
          "tp": 6,
          "fn": 394,
          "accuracy": 0.015
        }
      },
      "auroc": 0.501875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 395,
          "accuracy": 0.0125
        },
        "0.01": {
          "tp": 5,
          "fn": 395,
          "accuracy": 0.0125
        }
      },
      "auroc": 0.500625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 392,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 8,
          "fn": 392,
          "accuracy": 0.02
        }
      },
      "auroc": 0.504375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 787,
          "accuracy": 0.01625
        },
        "0.01": {
          "tp": 13,
          "fn": 787,
          "accuracy": 0.01625
        }
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        }
      },
      "auroc": 0.519375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 72,
          "fn": 128,
          "accuracy": 0.36
        },
        "0.01": {
          "tp": 72,
          "fn": 128,
          "accuracy": 0.36
        }
      },
      "auroc": 0.6743750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 318,
          "accuracy": 0.205
        },
        "0.01": {
          "tp": 82,
          "fn": 318,
          "accuracy": 0.205
        }
      },
      "auroc": 0.596875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 154,
          "accuracy": 0.23
        },
        "0.01": {
          "tp": 46,
          "fn": 154,
          "accuracy": 0.23
        }
      },
      "auroc": 0.609375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        },
        "0.01": {
          "tp": 13,
          "fn": 187,
          "accuracy": 0.065
        }
      },
      "auroc": 0.526875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 341,
          "accuracy": 0.1475
        },
        "0.01": {
          "tp": 59,
          "fn": 341,
          "accuracy": 0.1475
        }
      },
      "auroc": 0.568125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5643750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 315,
          "accuracy": 0.2125
        },
        "0.01": {
          "tp": 85,
          "fn": 315,
          "accuracy": 0.2125
        }
      },
      "auroc": 0.600625
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 141,
          "fn": 659,
          "accuracy": 0.17625
        },
        "0.01": {
          "tp": 141,
          "fn": 659,
          "accuracy": 0.17625
        }
      },
      "auroc": 0.5825
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        },
        "0.01": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        }
      },
      "auroc": 0.529375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        }
      },
      "auroc": 0.506875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 19,
          "fn": 381,
          "accuracy": 0.0475
        },
        "0.01": {
          "tp": 19,
          "fn": 381,
          "accuracy": 0.0475
        }
      },
      "auroc": 0.5181250000000001
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        },
        "0.01": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        }
      },
      "auroc": 0.569375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 368,
          "accuracy": 0.08
        },
        "0.01": {
          "tp": 32,
          "fn": 368,
          "accuracy": 0.08
        }
      },
      "auroc": 0.534375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5493750000000001
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        },
        "0.01": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        }
      },
      "auroc": 0.503125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 749,
          "accuracy": 0.06375
        },
        "0.01": {
          "tp": 51,
          "fn": 749,
          "accuracy": 0.06375
        }
      },
      "auroc": 0.52625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        },
        "0.01": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        }
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        },
        "0.01": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        }
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 795,
          "accuracy": 0.00625
        },
        "0.01": {
          "tp": 5,
          "fn": 795,
          "accuracy": 0.00625
        }
      },
      "auroc": 0.49750000000000005
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        }
      },
      "auroc": 0.571875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        }
      },
      "auroc": 0.571875
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        }
      },
      "auroc": 0.574375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        }
      },
      "auroc": 0.574375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        },
        "0.01": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        }
      },
      "auroc": 0.573125
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        },
        "0.01": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        }
      },
      "auroc": 0.573125
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.514375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.514375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.504375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.504375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 388,
          "accuracy": 0.03
        },
        "0.01": {
          "tp": 12,
          "fn": 388,
          "accuracy": 0.03
        }
      },
      "auroc": 0.509375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 388,
          "accuracy": 0.03
        },
        "0.01": {
          "tp": 12,
          "fn": 388,
          "accuracy": 0.03
        }
      },
      "auroc": 0.509375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.495625
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.495625
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 396,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 4,
          "fn": 396,
          "accuracy": 0.01
        }
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 396,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 4,
          "fn": 396,
          "accuracy": 0.01
        }
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 2112,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 88,
          "fn": 2112,
          "accuracy": 0.04
        }
      },
      "auroc": 0.514375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 1116,
          "accuracy": 0.07
        },
        "0.01": {
          "tp": 84,
          "fn": 1116,
          "accuracy": 0.07
        }
      },
      "auroc": 0.529375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 172,
          "fn": 3228,
          "accuracy": 0.05058823529411765
        },
        "0.01": {
          "tp": 172,
          "fn": 3228,
          "accuracy": 0.05058823529411765
        }
      },
      "auroc": 0.5196691176470588
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 140,
          "fn": 2060,
          "accuracy": 0.06363636363636363
        },
        "0.01": {
          "tp": 140,
          "fn": 2060,
          "accuracy": 0.06363636363636363
        }
      },
      "auroc": 0.5261931818181819
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 1172,
          "accuracy": 0.023333333333333334
        },
        "0.01": {
          "tp": 28,
          "fn": 1172,
          "accuracy": 0.023333333333333334
        }
      },
      "auroc": 0.5060416666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 3232,
          "accuracy": 0.04941176470588235
        },
        "0.01": {
          "tp": 168,
          "fn": 3232,
          "accuracy": 0.04941176470588235
        }
      },
      "auroc": 0.5190808823529411
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 228,
          "fn": 4172,
          "accuracy": 0.05181818181818182
        },
        "0.01": {
          "tp": 228,
          "fn": 4172,
          "accuracy": 0.05181818181818182
        }
      },
      "auroc": 0.5202840909090909
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 2288,
          "accuracy": 0.04666666666666667
        },
        "0.01": {
          "tp": 112,
          "fn": 2288,
          "accuracy": 0.04666666666666667
        }
      },
      "auroc": 0.5177083333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 340,
          "fn": 6460,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 340,
          "fn": 6460,
          "accuracy": 0.05
        }
      },
      "auroc": 0.519375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        }
      },
      "auroc": 0.726875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        }
      },
      "auroc": 0.659375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 159,
          "fn": 241,
          "accuracy": 0.3975
        },
        "0.01": {
          "tp": 159,
          "fn": 241,
          "accuracy": 0.3975
        }
      },
      "auroc": 0.693125
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        },
        "0.01": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        }
      },
      "auroc": 0.756875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 68,
          "fn": 132,
          "accuracy": 0.34
        },
        "0.01": {
          "tp": 68,
          "fn": 132,
          "accuracy": 0.34
        }
      },
      "auroc": 0.664375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 227,
          "accuracy": 0.4325
        },
        "0.01": {
          "tp": 173,
          "fn": 227,
          "accuracy": 0.4325
        }
      },
      "auroc": 0.7106250000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 198,
          "fn": 202,
          "accuracy": 0.495
        },
        "0.01": {
          "tp": 198,
          "fn": 202,
          "accuracy": 0.495
        }
      },
      "auroc": 0.7418750000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 266,
          "accuracy": 0.335
        },
        "0.01": {
          "tp": 134,
          "fn": 266,
          "accuracy": 0.335
        }
      },
      "auroc": 0.661875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 332,
          "fn": 468,
          "accuracy": 0.415
        },
        "0.01": {
          "tp": 332,
          "fn": 468,
          "accuracy": 0.415
        }
      },
      "auroc": 0.701875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        },
        "0.01": {
          "tp": 41,
          "fn": 159,
          "accuracy": 0.205
        }
      },
      "auroc": 0.596875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        }
      },
      "auroc": 0.556875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 334,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 66,
          "fn": 334,
          "accuracy": 0.165
        }
      },
      "auroc": 0.576875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        },
        "0.01": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        }
      },
      "auroc": 0.6893750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        }
      },
      "auroc": 0.551875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        },
        "0.01": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        }
      },
      "auroc": 0.620625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 281,
          "accuracy": 0.2975
        },
        "0.01": {
          "tp": 119,
          "fn": 281,
          "accuracy": 0.2975
        }
      },
      "auroc": 0.643125
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 352,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 48,
          "fn": 352,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5543750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 167,
          "fn": 633,
          "accuracy": 0.20875
        },
        "0.01": {
          "tp": 167,
          "fn": 633,
          "accuracy": 0.20875
        }
      },
      "auroc": 0.59875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 143,
          "fn": 57,
          "accuracy": 0.715
        },
        "0.01": {
          "tp": 143,
          "fn": 57,
          "accuracy": 0.715
        }
      },
      "auroc": 0.8518749999999999
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        }
      },
      "auroc": 0.576875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 224,
          "accuracy": 0.44
        },
        "0.01": {
          "tp": 176,
          "fn": 224,
          "accuracy": 0.44
        }
      },
      "auroc": 0.714375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 106,
          "fn": 94,
          "accuracy": 0.53
        },
        "0.01": {
          "tp": 106,
          "fn": 94,
          "accuracy": 0.53
        }
      },
      "auroc": 0.759375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        }
      },
      "auroc": 0.546875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 127,
          "fn": 273,
          "accuracy": 0.3175
        },
        "0.01": {
          "tp": 127,
          "fn": 273,
          "accuracy": 0.3175
        }
      },
      "auroc": 0.653125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 249,
          "fn": 151,
          "accuracy": 0.6225
        },
        "0.01": {
          "tp": 249,
          "fn": 151,
          "accuracy": 0.6225
        }
      },
      "auroc": 0.805625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 54,
          "fn": 346,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 54,
          "fn": 346,
          "accuracy": 0.135
        }
      },
      "auroc": 0.561875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 303,
          "fn": 497,
          "accuracy": 0.37875
        },
        "0.01": {
          "tp": 303,
          "fn": 497,
          "accuracy": 0.37875
        }
      },
      "auroc": 0.68375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        },
        "0.01": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        }
      },
      "auroc": 0.536875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 125,
          "fn": 75,
          "accuracy": 0.625
        },
        "0.01": {
          "tp": 125,
          "fn": 75,
          "accuracy": 0.625
        }
      },
      "auroc": 0.806875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 142,
          "fn": 258,
          "accuracy": 0.355
        },
        "0.01": {
          "tp": 142,
          "fn": 258,
          "accuracy": 0.355
        }
      },
      "auroc": 0.671875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        },
        "0.01": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        }
      },
      "auroc": 0.8143750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        },
        "0.01": {
          "tp": 45,
          "fn": 155,
          "accuracy": 0.225
        }
      },
      "auroc": 0.606875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 227,
          "accuracy": 0.4325
        },
        "0.01": {
          "tp": 173,
          "fn": 227,
          "accuracy": 0.4325
        }
      },
      "auroc": 0.7106250000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 145,
          "fn": 255,
          "accuracy": 0.3625
        },
        "0.01": {
          "tp": 145,
          "fn": 255,
          "accuracy": 0.3625
        }
      },
      "auroc": 0.675625
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 230,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 170,
          "fn": 230,
          "accuracy": 0.425
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 315,
          "fn": 485,
          "accuracy": 0.39375
        },
        "0.01": {
          "tp": 315,
          "fn": 485,
          "accuracy": 0.39375
        }
      },
      "auroc": 0.69125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        }
      },
      "auroc": 0.584375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.561875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        },
        "0.01": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        }
      },
      "auroc": 0.573125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        }
      },
      "auroc": 0.696875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        },
        "0.01": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        }
      },
      "auroc": 0.509375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        },
        "0.01": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        }
      },
      "auroc": 0.603125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 283,
          "accuracy": 0.2925
        },
        "0.01": {
          "tp": 117,
          "fn": 283,
          "accuracy": 0.2925
        }
      },
      "auroc": 0.640625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        },
        "0.01": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        }
      },
      "auroc": 0.535625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 650,
          "accuracy": 0.1875
        },
        "0.01": {
          "tp": 150,
          "fn": 650,
          "accuracy": 0.1875
        }
      },
      "auroc": 0.588125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 154,
          "fn": 46,
          "accuracy": 0.77
        },
        "0.01": {
          "tp": 154,
          "fn": 46,
          "accuracy": 0.77
        }
      },
      "auroc": 0.879375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        },
        "0.01": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        }
      },
      "auroc": 0.756875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        },
        "0.01": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        }
      },
      "auroc": 0.818125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 131,
          "fn": 69,
          "accuracy": 0.655
        }
      },
      "auroc": 0.821875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 58,
          "fn": 142,
          "accuracy": 0.29
        },
        "0.01": {
          "tp": 58,
          "fn": 142,
          "accuracy": 0.29
        }
      },
      "auroc": 0.639375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 189,
          "fn": 211,
          "accuracy": 0.4725
        },
        "0.01": {
          "tp": 189,
          "fn": 211,
          "accuracy": 0.4725
        }
      },
      "auroc": 0.730625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 285,
          "fn": 115,
          "accuracy": 0.7125
        },
        "0.01": {
          "tp": 285,
          "fn": 115,
          "accuracy": 0.7125
        }
      },
      "auroc": 0.850625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 163,
          "fn": 237,
          "accuracy": 0.4075
        },
        "0.01": {
          "tp": 163,
          "fn": 237,
          "accuracy": 0.4075
        }
      },
      "auroc": 0.698125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 448,
          "fn": 352,
          "accuracy": 0.56
        },
        "0.01": {
          "tp": 448,
          "fn": 352,
          "accuracy": 0.56
        }
      },
      "auroc": 0.774375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 266,
          "fn": 134,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        }
      },
      "auroc": 0.696875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        }
      },
      "auroc": 0.696875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 126,
          "accuracy": 0.37
        },
        "0.01": {
          "tp": 74,
          "fn": 126,
          "accuracy": 0.37
        }
      },
      "auroc": 0.6793750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 126,
          "accuracy": 0.37
        },
        "0.01": {
          "tp": 74,
          "fn": 126,
          "accuracy": 0.37
        }
      },
      "auroc": 0.6793750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 155,
          "fn": 245,
          "accuracy": 0.3875
        },
        "0.01": {
          "tp": 155,
          "fn": 245,
          "accuracy": 0.3875
        }
      },
      "auroc": 0.688125
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 155,
          "fn": 245,
          "accuracy": 0.3875
        },
        "0.01": {
          "tp": 155,
          "fn": 245,
          "accuracy": 0.3875
        }
      },
      "auroc": 0.688125
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 146,
          "fn": 54,
          "accuracy": 0.73
        },
        "0.01": {
          "tp": 146,
          "fn": 54,
          "accuracy": 0.73
        }
      },
      "auroc": 0.859375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 146,
          "fn": 54,
          "accuracy": 0.73
        },
        "0.01": {
          "tp": 146,
          "fn": 54,
          "accuracy": 0.73
        }
      },
      "auroc": 0.859375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.769375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.769375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 256,
          "fn": 144,
          "accuracy": 0.64
        },
        "0.01": {
          "tp": 256,
          "fn": 144,
          "accuracy": 0.64
        }
      },
      "auroc": 0.8143750000000001
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 256,
          "fn": 144,
          "accuracy": 0.64
        },
        "0.01": {
          "tp": 256,
          "fn": 144,
          "accuracy": 0.64
        }
      },
      "auroc": 0.8143750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 154,
          "fn": 46,
          "accuracy": 0.77
        },
        "0.01": {
          "tp": 154,
          "fn": 46,
          "accuracy": 0.77
        }
      },
      "auroc": 0.879375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 154,
          "fn": 46,
          "accuracy": 0.77
        },
        "0.01": {
          "tp": 154,
          "fn": 46,
          "accuracy": 0.77
        }
      },
      "auroc": 0.879375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        }
      },
      "auroc": 0.644375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        }
      },
      "auroc": 0.644375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 214,
          "fn": 186,
          "accuracy": 0.535
        },
        "0.01": {
          "tp": 214,
          "fn": 186,
          "accuracy": 0.535
        }
      },
      "auroc": 0.7618750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 214,
          "fn": 186,
          "accuracy": 0.535
        },
        "0.01": {
          "tp": 214,
          "fn": 186,
          "accuracy": 0.535
        }
      },
      "auroc": 0.7618750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7518750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7518750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        }
      },
      "auroc": 0.711875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        }
      },
      "auroc": 0.711875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 190,
          "fn": 210,
          "accuracy": 0.475
        },
        "0.01": {
          "tp": 190,
          "fn": 210,
          "accuracy": 0.475
        }
      },
      "auroc": 0.731875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 190,
          "fn": 210,
          "accuracy": 0.475
        },
        "0.01": {
          "tp": 190,
          "fn": 210,
          "accuracy": 0.475
        }
      },
      "auroc": 0.731875
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1101,
          "fn": 1099,
          "accuracy": 0.5004545454545455
        },
        "0.01": {
          "tp": 1101,
          "fn": 1099,
          "accuracy": 0.5004545454545455
        }
      },
      "auroc": 0.7446022727272728
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 381,
          "fn": 819,
          "accuracy": 0.3175
        },
        "0.01": {
          "tp": 381,
          "fn": 819,
          "accuracy": 0.3175
        }
      },
      "auroc": 0.653125
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1482,
          "fn": 1918,
          "accuracy": 0.43588235294117644
        },
        "0.01": {
          "tp": 1482,
          "fn": 1918,
          "accuracy": 0.43588235294117644
        }
      },
      "auroc": 0.7123161764705882
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1093,
          "fn": 1107,
          "accuracy": 0.4968181818181818
        },
        "0.01": {
          "tp": 1093,
          "fn": 1107,
          "accuracy": 0.4968181818181818
        }
      },
      "auroc": 0.7427840909090909
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 221,
          "fn": 979,
          "accuracy": 0.18416666666666667
        },
        "0.01": {
          "tp": 221,
          "fn": 979,
          "accuracy": 0.18416666666666667
        }
      },
      "auroc": 0.5864583333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1314,
          "fn": 2086,
          "accuracy": 0.3864705882352941
        },
        "0.01": {
          "tp": 1314,
          "fn": 2086,
          "accuracy": 0.3864705882352941
        }
      },
      "auroc": 0.6876102941176471
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 2194,
          "fn": 2206,
          "accuracy": 0.49863636363636366
        },
        "0.01": {
          "tp": 2194,
          "fn": 2206,
          "accuracy": 0.49863636363636366
        }
      },
      "auroc": 0.7436931818181818
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 602,
          "fn": 1798,
          "accuracy": 0.25083333333333335
        },
        "0.01": {
          "tp": 602,
          "fn": 1798,
          "accuracy": 0.25083333333333335
        }
      },
      "auroc": 0.6197916666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 2796,
          "fn": 4004,
          "accuracy": 0.4111764705882353
        },
        "0.01": {
          "tp": 2796,
          "fn": 4004,
          "accuracy": 0.4111764705882353
        }
      },
      "auroc": 0.6999632352941176
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 104,
          "fn": 96,
          "accuracy": 0.52
        },
        "0.01": {
          "tp": 104,
          "fn": 96,
          "accuracy": 0.52
        }
      },
      "auroc": 0.754375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        }
      },
      "auroc": 0.659375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 230,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 170,
          "fn": 230,
          "accuracy": 0.425
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        },
        "0.01": {
          "tp": 113,
          "fn": 87,
          "accuracy": 0.565
        }
      },
      "auroc": 0.776875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 68,
          "fn": 132,
          "accuracy": 0.34
        },
        "0.01": {
          "tp": 68,
          "fn": 132,
          "accuracy": 0.34
        }
      },
      "auroc": 0.664375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 181,
          "fn": 219,
          "accuracy": 0.4525
        },
        "0.01": {
          "tp": 181,
          "fn": 219,
          "accuracy": 0.4525
        }
      },
      "auroc": 0.7206250000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 217,
          "fn": 183,
          "accuracy": 0.5425
        },
        "0.01": {
          "tp": 217,
          "fn": 183,
          "accuracy": 0.5425
        }
      },
      "auroc": 0.765625
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 266,
          "accuracy": 0.335
        },
        "0.01": {
          "tp": 134,
          "fn": 266,
          "accuracy": 0.335
        }
      },
      "auroc": 0.661875
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 351,
          "fn": 449,
          "accuracy": 0.43875
        },
        "0.01": {
          "tp": 351,
          "fn": 449,
          "accuracy": 0.43875
        }
      },
      "auroc": 0.71375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 154,
          "accuracy": 0.23
        },
        "0.01": {
          "tp": 46,
          "fn": 154,
          "accuracy": 0.23
        }
      },
      "auroc": 0.609375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5543750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        }
      },
      "auroc": 0.581875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5493750000000001
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        }
      },
      "auroc": 0.629375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 132,
          "fn": 268,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 132,
          "fn": 268,
          "accuracy": 0.33
        }
      },
      "auroc": 0.659375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 354,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 46,
          "fn": 354,
          "accuracy": 0.115
        }
      },
      "auroc": 0.551875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 622,
          "accuracy": 0.2225
        },
        "0.01": {
          "tp": 178,
          "fn": 622,
          "accuracy": 0.2225
        }
      },
      "auroc": 0.605625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 154,
          "fn": 46,
          "accuracy": 0.77
        },
        "0.01": {
          "tp": 154,
          "fn": 46,
          "accuracy": 0.77
        }
      },
      "auroc": 0.879375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.579375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 188,
          "fn": 212,
          "accuracy": 0.47
        },
        "0.01": {
          "tp": 188,
          "fn": 212,
          "accuracy": 0.47
        }
      },
      "auroc": 0.729375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 116,
          "fn": 84,
          "accuracy": 0.58
        },
        "0.01": {
          "tp": 116,
          "fn": 84,
          "accuracy": 0.58
        }
      },
      "auroc": 0.784375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        }
      },
      "auroc": 0.546875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 137,
          "fn": 263,
          "accuracy": 0.3425
        },
        "0.01": {
          "tp": 137,
          "fn": 263,
          "accuracy": 0.3425
        }
      },
      "auroc": 0.665625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 270,
          "fn": 130,
          "accuracy": 0.675
        },
        "0.01": {
          "tp": 270,
          "fn": 130,
          "accuracy": 0.675
        }
      },
      "auroc": 0.831875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        },
        "0.01": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        }
      },
      "auroc": 0.563125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 325,
          "fn": 475,
          "accuracy": 0.40625
        },
        "0.01": {
          "tp": 325,
          "fn": 475,
          "accuracy": 0.40625
        }
      },
      "auroc": 0.6975
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        }
      },
      "auroc": 0.531875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        },
        "0.01": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        }
      },
      "auroc": 0.8043750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        },
        "0.01": {
          "tp": 139,
          "fn": 261,
          "accuracy": 0.3475
        }
      },
      "auroc": 0.668125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 135,
          "fn": 65,
          "accuracy": 0.675
        },
        "0.01": {
          "tp": 135,
          "fn": 65,
          "accuracy": 0.675
        }
      },
      "auroc": 0.831875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 153,
          "accuracy": 0.235
        },
        "0.01": {
          "tp": 47,
          "fn": 153,
          "accuracy": 0.235
        }
      },
      "auroc": 0.611875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 182,
          "fn": 218,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 182,
          "fn": 218,
          "accuracy": 0.455
        }
      },
      "auroc": 0.721875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        },
        "0.01": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        }
      },
      "auroc": 0.681875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 171,
          "fn": 229,
          "accuracy": 0.4275
        },
        "0.01": {
          "tp": 171,
          "fn": 229,
          "accuracy": 0.4275
        }
      },
      "auroc": 0.708125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 321,
          "fn": 479,
          "accuracy": 0.40125
        },
        "0.01": {
          "tp": 321,
          "fn": 479,
          "accuracy": 0.40125
        }
      },
      "auroc": 0.6950000000000001
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        },
        "0.01": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        }
      },
      "auroc": 0.591875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        },
        "0.01": {
          "tp": 25,
          "fn": 175,
          "accuracy": 0.125
        }
      },
      "auroc": 0.556875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        }
      },
      "auroc": 0.574375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        }
      },
      "auroc": 0.699375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        }
      },
      "auroc": 0.506875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        },
        "0.01": {
          "tp": 87,
          "fn": 313,
          "accuracy": 0.2175
        }
      },
      "auroc": 0.603125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 121,
          "fn": 279,
          "accuracy": 0.3025
        },
        "0.01": {
          "tp": 121,
          "fn": 279,
          "accuracy": 0.3025
        }
      },
      "auroc": 0.645625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        }
      },
      "auroc": 0.531875
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 151,
          "fn": 649,
          "accuracy": 0.18875
        },
        "0.01": {
          "tp": 151,
          "fn": 649,
          "accuracy": 0.18875
        }
      },
      "auroc": 0.58875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        },
        "0.01": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        }
      },
      "auroc": 0.9143749999999999
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.769375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 278,
          "fn": 122,
          "accuracy": 0.695
        },
        "0.01": {
          "tp": 278,
          "fn": 122,
          "accuracy": 0.695
        }
      },
      "auroc": 0.8418749999999999
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        },
        "0.01": {
          "tp": 144,
          "fn": 56,
          "accuracy": 0.72
        }
      },
      "auroc": 0.854375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        },
        "0.01": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        }
      },
      "auroc": 0.636875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 201,
          "fn": 199,
          "accuracy": 0.5025
        },
        "0.01": {
          "tp": 201,
          "fn": 199,
          "accuracy": 0.5025
        }
      },
      "auroc": 0.745625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 312,
          "fn": 88,
          "accuracy": 0.78
        },
        "0.01": {
          "tp": 312,
          "fn": 88,
          "accuracy": 0.78
        }
      },
      "auroc": 0.884375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 167,
          "fn": 233,
          "accuracy": 0.4175
        },
        "0.01": {
          "tp": 167,
          "fn": 233,
          "accuracy": 0.4175
        }
      },
      "auroc": 0.703125
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 479,
          "fn": 321,
          "accuracy": 0.59875
        },
        "0.01": {
          "tp": 479,
          "fn": 321,
          "accuracy": 0.59875
        }
      },
      "auroc": 0.79375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8268750000000001
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        },
        "0.01": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        }
      },
      "auroc": 0.829375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        },
        "0.01": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        }
      },
      "auroc": 0.829375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        },
        "0.01": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        }
      },
      "auroc": 0.828125
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        },
        "0.01": {
          "tp": 267,
          "fn": 133,
          "accuracy": 0.6675
        }
      },
      "auroc": 0.828125
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        }
      },
      "auroc": 0.724375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.709375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        },
        "0.01": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        }
      },
      "auroc": 0.716875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        },
        "0.01": {
          "tp": 178,
          "fn": 222,
          "accuracy": 0.445
        }
      },
      "auroc": 0.716875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 167,
          "fn": 33,
          "accuracy": 0.835
        },
        "0.01": {
          "tp": 167,
          "fn": 33,
          "accuracy": 0.835
        }
      },
      "auroc": 0.911875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 167,
          "fn": 33,
          "accuracy": 0.835
        },
        "0.01": {
          "tp": 167,
          "fn": 33,
          "accuracy": 0.835
        }
      },
      "auroc": 0.911875
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        },
        "0.01": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        }
      },
      "auroc": 0.8143750000000001
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        },
        "0.01": {
          "tp": 128,
          "fn": 72,
          "accuracy": 0.64
        }
      },
      "auroc": 0.8143750000000001
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 295,
          "fn": 105,
          "accuracy": 0.7375
        },
        "0.01": {
          "tp": 295,
          "fn": 105,
          "accuracy": 0.7375
        }
      },
      "auroc": 0.863125
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 295,
          "fn": 105,
          "accuracy": 0.7375
        },
        "0.01": {
          "tp": 295,
          "fn": 105,
          "accuracy": 0.7375
        }
      },
      "auroc": 0.863125
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        },
        "0.01": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        }
      },
      "auroc": 0.934375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        },
        "0.01": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        }
      },
      "auroc": 0.934375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        },
        "0.01": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        }
      },
      "auroc": 0.701875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        },
        "0.01": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        }
      },
      "auroc": 0.701875
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        },
        "0.01": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        }
      },
      "auroc": 0.818125
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        },
        "0.01": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        }
      },
      "auroc": 0.818125
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        },
        "0.01": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        }
      },
      "auroc": 0.791875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        },
        "0.01": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        }
      },
      "auroc": 0.791875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        }
      },
      "auroc": 0.726875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        },
        "0.01": {
          "tp": 93,
          "fn": 107,
          "accuracy": 0.465
        }
      },
      "auroc": 0.726875
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 212,
          "fn": 188,
          "accuracy": 0.53
        },
        "0.01": {
          "tp": 212,
          "fn": 188,
          "accuracy": 0.53
        }
      },
      "auroc": 0.759375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 212,
          "fn": 188,
          "accuracy": 0.53
        },
        "0.01": {
          "tp": 212,
          "fn": 188,
          "accuracy": 0.53
        }
      },
      "auroc": 0.759375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1213,
          "fn": 987,
          "accuracy": 0.5513636363636364
        },
        "0.01": {
          "tp": 1213,
          "fn": 987,
          "accuracy": 0.5513636363636364
        }
      },
      "auroc": 0.7700568181818181
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 383,
          "fn": 817,
          "accuracy": 0.31916666666666665
        },
        "0.01": {
          "tp": 383,
          "fn": 817,
          "accuracy": 0.31916666666666665
        }
      },
      "auroc": 0.6539583333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1596,
          "fn": 1804,
          "accuracy": 0.46941176470588236
        },
        "0.01": {
          "tp": 1596,
          "fn": 1804,
          "accuracy": 0.46941176470588236
        }
      },
      "auroc": 0.7290808823529412
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1200,
          "fn": 1000,
          "accuracy": 0.5454545454545454
        },
        "0.01": {
          "tp": 1200,
          "fn": 1000,
          "accuracy": 0.5454545454545454
        }
      },
      "auroc": 0.7671022727272727
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 220,
          "fn": 980,
          "accuracy": 0.18333333333333332
        },
        "0.01": {
          "tp": 220,
          "fn": 980,
          "accuracy": 0.18333333333333332
        }
      },
      "auroc": 0.5860416666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1420,
          "fn": 1980,
          "accuracy": 0.4176470588235294
        },
        "0.01": {
          "tp": 1420,
          "fn": 1980,
          "accuracy": 0.4176470588235294
        }
      },
      "auroc": 0.7031985294117648
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 2413,
          "fn": 1987,
          "accuracy": 0.548409090909091
        },
        "0.01": {
          "tp": 2413,
          "fn": 1987,
          "accuracy": 0.548409090909091
        }
      },
      "auroc": 0.7685795454545454
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 603,
          "fn": 1797,
          "accuracy": 0.25125
        },
        "0.01": {
          "tp": 603,
          "fn": 1797,
          "accuracy": 0.25125
        }
      },
      "auroc": 0.62
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 3016,
          "fn": 3784,
          "accuracy": 0.4435294117647059
        },
        "0.01": {
          "tp": 3016,
          "fn": 3784,
          "accuracy": 0.4435294117647059
        }
      },
      "auroc": 0.716139705882353
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.495625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.495625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 798,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 2,
          "fn": 798,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.495625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.495625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        },
        "0.01": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        }
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 797,
          "accuracy": 0.00375
        },
        "0.01": {
          "tp": 3,
          "fn": 797,
          "accuracy": 0.00375
        }
      },
      "auroc": 0.49624999999999997
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 2200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 2200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 1197,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 3,
          "fn": 1197,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.495625
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 3397,
          "accuracy": 0.0008823529411764706
        },
        "0.01": {
          "tp": 3,
          "fn": 3397,
          "accuracy": 0.0008823529411764706
        }
      },
      "auroc": 0.4948161764705883
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 2200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 2200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 1198,
          "accuracy": 0.0016666666666666668
        },
        "0.01": {
          "tp": 2,
          "fn": 1198,
          "accuracy": 0.0016666666666666668
        }
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 3398,
          "accuracy": 0.000588235294117647
        },
        "0.01": {
          "tp": 2,
          "fn": 3398,
          "accuracy": 0.000588235294117647
        }
      },
      "auroc": 0.4946691176470588
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 4400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 4400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.494375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 2395,
          "accuracy": 0.0020833333333333333
        },
        "0.01": {
          "tp": 5,
          "fn": 2395,
          "accuracy": 0.0020833333333333333
        }
      },
      "auroc": 0.4954166666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 6795,
          "accuracy": 0.0007352941176470588
        },
        "0.01": {
          "tp": 5,
          "fn": 6795,
          "accuracy": 0.0007352941176470588
        }
      },
      "auroc": 0.49474264705882354
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 824,
          "fn": 1576,
          "accuracy": 0.3433333333333333
        },
        "0.01": {
          "tp": 824,
          "fn": 1576,
          "accuracy": 0.3433333333333333
        }
      },
      "auroc": 0.6660416666666666
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 530,
          "fn": 1870,
          "accuracy": 0.22083333333333333
        },
        "0.01": {
          "tp": 530,
          "fn": 1870,
          "accuracy": 0.22083333333333333
        }
      },
      "auroc": 0.6047916666666666
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1354,
          "fn": 3446,
          "accuracy": 0.28208333333333335
        },
        "0.01": {
          "tp": 1354,
          "fn": 3446,
          "accuracy": 0.28208333333333335
        }
      },
      "auroc": 0.6354166666666667
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 882,
          "fn": 1518,
          "accuracy": 0.3675
        },
        "0.01": {
          "tp": 882,
          "fn": 1518,
          "accuracy": 0.3675
        }
      },
      "auroc": 0.678125
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 548,
          "fn": 1852,
          "accuracy": 0.22833333333333333
        },
        "0.01": {
          "tp": 548,
          "fn": 1852,
          "accuracy": 0.22833333333333333
        }
      },
      "auroc": 0.6085416666666666
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1430,
          "fn": 3370,
          "accuracy": 0.29791666666666666
        },
        "0.01": {
          "tp": 1430,
          "fn": 3370,
          "accuracy": 0.29791666666666666
        }
      },
      "auroc": 0.6433333333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1706,
          "fn": 3094,
          "accuracy": 0.35541666666666666
        },
        "0.01": {
          "tp": 1706,
          "fn": 3094,
          "accuracy": 0.35541666666666666
        }
      },
      "auroc": 0.6720833333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1078,
          "fn": 3722,
          "accuracy": 0.22458333333333333
        },
        "0.01": {
          "tp": 1078,
          "fn": 3722,
          "accuracy": 0.22458333333333333
        }
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2784,
          "fn": 6816,
          "accuracy": 0.29
        },
        "0.01": {
          "tp": 2784,
          "fn": 6816,
          "accuracy": 0.29
        }
      },
      "auroc": 0.639375
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 516,
          "fn": 1884,
          "accuracy": 0.215
        },
        "0.01": {
          "tp": 516,
          "fn": 1884,
          "accuracy": 0.215
        }
      },
      "auroc": 0.601875
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 280,
          "fn": 2120,
          "accuracy": 0.11666666666666667
        },
        "0.01": {
          "tp": 280,
          "fn": 2120,
          "accuracy": 0.11666666666666667
        }
      },
      "auroc": 0.5527083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 796,
          "fn": 4004,
          "accuracy": 0.16583333333333333
        },
        "0.01": {
          "tp": 796,
          "fn": 4004,
          "accuracy": 0.16583333333333333
        }
      },
      "auroc": 0.5772916666666666
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 769,
          "fn": 1631,
          "accuracy": 0.3204166666666667
        },
        "0.01": {
          "tp": 769,
          "fn": 1631,
          "accuracy": 0.3204166666666667
        }
      },
      "auroc": 0.6545833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 260,
          "fn": 2140,
          "accuracy": 0.10833333333333334
        },
        "0.01": {
          "tp": 260,
          "fn": 2140,
          "accuracy": 0.10833333333333334
        }
      },
      "auroc": 0.5485416666666667
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1029,
          "fn": 3771,
          "accuracy": 0.214375
        },
        "0.01": {
          "tp": 1029,
          "fn": 3771,
          "accuracy": 0.214375
        }
      },
      "auroc": 0.6015625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1285,
          "fn": 3515,
          "accuracy": 0.2677083333333333
        },
        "0.01": {
          "tp": 1285,
          "fn": 3515,
          "accuracy": 0.2677083333333333
        }
      },
      "auroc": 0.6282291666666666
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 540,
          "fn": 4260,
          "accuracy": 0.1125
        },
        "0.01": {
          "tp": 540,
          "fn": 4260,
          "accuracy": 0.1125
        }
      },
      "auroc": 0.550625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1825,
          "fn": 7775,
          "accuracy": 0.19010416666666666
        },
        "0.01": {
          "tp": 1825,
          "fn": 7775,
          "accuracy": 0.19010416666666666
        }
      },
      "auroc": 0.5894270833333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1254,
          "fn": 1146,
          "accuracy": 0.5225
        },
        "0.01": {
          "tp": 1254,
          "fn": 1146,
          "accuracy": 0.5225
        }
      },
      "auroc": 0.755625
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 293,
          "fn": 2107,
          "accuracy": 0.12208333333333334
        },
        "0.01": {
          "tp": 293,
          "fn": 2107,
          "accuracy": 0.12208333333333334
        }
      },
      "auroc": 0.5554166666666667
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1547,
          "fn": 3253,
          "accuracy": 0.32229166666666664
        },
        "0.01": {
          "tp": 1547,
          "fn": 3253,
          "accuracy": 0.32229166666666664
        }
      },
      "auroc": 0.6555208333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 930,
          "fn": 1470,
          "accuracy": 0.3875
        },
        "0.01": {
          "tp": 930,
          "fn": 1470,
          "accuracy": 0.3875
        }
      },
      "auroc": 0.688125
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 216,
          "fn": 2184,
          "accuracy": 0.09
        },
        "0.01": {
          "tp": 216,
          "fn": 2184,
          "accuracy": 0.09
        }
      },
      "auroc": 0.539375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1146,
          "fn": 3654,
          "accuracy": 0.23875
        },
        "0.01": {
          "tp": 1146,
          "fn": 3654,
          "accuracy": 0.23875
        }
      },
      "auroc": 0.61375
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2184,
          "fn": 2616,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 2184,
          "fn": 2616,
          "accuracy": 0.455
        }
      },
      "auroc": 0.721875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 509,
          "fn": 4291,
          "accuracy": 0.10604166666666667
        },
        "0.01": {
          "tp": 509,
          "fn": 4291,
          "accuracy": 0.10604166666666667
        }
      },
      "auroc": 0.5473958333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2693,
          "fn": 6907,
          "accuracy": 0.28052083333333333
        },
        "0.01": {
          "tp": 2693,
          "fn": 6907,
          "accuracy": 0.28052083333333333
        }
      },
      "auroc": 0.6346354166666667
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 283,
          "fn": 2117,
          "accuracy": 0.11791666666666667
        },
        "0.01": {
          "tp": 283,
          "fn": 2117,
          "accuracy": 0.11791666666666667
        }
      },
      "auroc": 0.5533333333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1159,
          "fn": 1241,
          "accuracy": 0.48291666666666666
        },
        "0.01": {
          "tp": 1159,
          "fn": 1241,
          "accuracy": 0.48291666666666666
        }
      },
      "auroc": 0.7358333333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1442,
          "fn": 3358,
          "accuracy": 0.30041666666666667
        },
        "0.01": {
          "tp": 1442,
          "fn": 3358,
          "accuracy": 0.30041666666666667
        }
      },
      "auroc": 0.6445833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1229,
          "fn": 1171,
          "accuracy": 0.5120833333333333
        },
        "0.01": {
          "tp": 1229,
          "fn": 1171,
          "accuracy": 0.5120833333333333
        }
      },
      "auroc": 0.7504166666666667
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 416,
          "fn": 1984,
          "accuracy": 0.17333333333333334
        },
        "0.01": {
          "tp": 416,
          "fn": 1984,
          "accuracy": 0.17333333333333334
        }
      },
      "auroc": 0.5810416666666667
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1645,
          "fn": 3155,
          "accuracy": 0.34270833333333334
        },
        "0.01": {
          "tp": 1645,
          "fn": 3155,
          "accuracy": 0.34270833333333334
        }
      },
      "auroc": 0.6657291666666667
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1512,
          "fn": 3288,
          "accuracy": 0.315
        },
        "0.01": {
          "tp": 1512,
          "fn": 3288,
          "accuracy": 0.315
        }
      },
      "auroc": 0.651875
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1575,
          "fn": 3225,
          "accuracy": 0.328125
        },
        "0.01": {
          "tp": 1575,
          "fn": 3225,
          "accuracy": 0.328125
        }
      },
      "auroc": 0.6584375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3087,
          "fn": 6513,
          "accuracy": 0.3215625
        },
        "0.01": {
          "tp": 3087,
          "fn": 6513,
          "accuracy": 0.3215625
        }
      },
      "auroc": 0.65515625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 490,
          "fn": 1910,
          "accuracy": 0.20416666666666666
        },
        "0.01": {
          "tp": 490,
          "fn": 1910,
          "accuracy": 0.20416666666666666
        }
      },
      "auroc": 0.5964583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 259,
          "fn": 2141,
          "accuracy": 0.10791666666666666
        },
        "0.01": {
          "tp": 259,
          "fn": 2141,
          "accuracy": 0.10791666666666666
        }
      },
      "auroc": 0.5483333333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 749,
          "fn": 4051,
          "accuracy": 0.15604166666666666
        },
        "0.01": {
          "tp": 749,
          "fn": 4051,
          "accuracy": 0.15604166666666666
        }
      },
      "auroc": 0.5723958333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 745,
          "fn": 1655,
          "accuracy": 0.3104166666666667
        },
        "0.01": {
          "tp": 745,
          "fn": 1655,
          "accuracy": 0.3104166666666667
        }
      },
      "auroc": 0.6495833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 2341,
          "accuracy": 0.024583333333333332
        },
        "0.01": {
          "tp": 59,
          "fn": 2341,
          "accuracy": 0.024583333333333332
        }
      },
      "auroc": 0.5066666666666667
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 804,
          "fn": 3996,
          "accuracy": 0.1675
        },
        "0.01": {
          "tp": 804,
          "fn": 3996,
          "accuracy": 0.1675
        }
      },
      "auroc": 0.578125
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1235,
          "fn": 3565,
          "accuracy": 0.25729166666666664
        },
        "0.01": {
          "tp": 1235,
          "fn": 3565,
          "accuracy": 0.25729166666666664
        }
      },
      "auroc": 0.6230208333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 318,
          "fn": 4482,
          "accuracy": 0.06625
        },
        "0.01": {
          "tp": 318,
          "fn": 4482,
          "accuracy": 0.06625
        }
      },
      "auroc": 0.5275
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1553,
          "fn": 8047,
          "accuracy": 0.16177083333333334
        },
        "0.01": {
          "tp": 1553,
          "fn": 8047,
          "accuracy": 0.16177083333333334
        }
      },
      "auroc": 0.5752604166666667
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1409,
          "fn": 991,
          "accuracy": 0.5870833333333333
        },
        "0.01": {
          "tp": 1409,
          "fn": 991,
          "accuracy": 0.5870833333333333
        }
      },
      "auroc": 0.7879166666666666
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 900,
          "fn": 1500,
          "accuracy": 0.375
        },
        "0.01": {
          "tp": 900,
          "fn": 1500,
          "accuracy": 0.375
        }
      },
      "auroc": 0.681875
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2309,
          "fn": 2491,
          "accuracy": 0.48104166666666665
        },
        "0.01": {
          "tp": 2309,
          "fn": 2491,
          "accuracy": 0.48104166666666665
        }
      },
      "auroc": 0.7348958333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1133,
          "fn": 1267,
          "accuracy": 0.47208333333333335
        },
        "0.01": {
          "tp": 1133,
          "fn": 1267,
          "accuracy": 0.47208333333333335
        }
      },
      "auroc": 0.7304166666666667
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 481,
          "fn": 1919,
          "accuracy": 0.20041666666666666
        },
        "0.01": {
          "tp": 481,
          "fn": 1919,
          "accuracy": 0.20041666666666666
        }
      },
      "auroc": 0.5945833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1614,
          "fn": 3186,
          "accuracy": 0.33625
        },
        "0.01": {
          "tp": 1614,
          "fn": 3186,
          "accuracy": 0.33625
        }
      },
      "auroc": 0.6625
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2542,
          "fn": 2258,
          "accuracy": 0.5295833333333333
        },
        "0.01": {
          "tp": 2542,
          "fn": 2258,
          "accuracy": 0.5295833333333333
        }
      },
      "auroc": 0.7591666666666667
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1381,
          "fn": 3419,
          "accuracy": 0.28770833333333334
        },
        "0.01": {
          "tp": 1381,
          "fn": 3419,
          "accuracy": 0.28770833333333334
        }
      },
      "auroc": 0.6382291666666666
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3923,
          "fn": 5677,
          "accuracy": 0.4086458333333333
        },
        "0.01": {
          "tp": 3923,
          "fn": 5677,
          "accuracy": 0.4086458333333333
        }
      },
      "auroc": 0.6986979166666667
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1349,
          "fn": 1051,
          "accuracy": 0.5620833333333334
        },
        "0.01": {
          "tp": 1349,
          "fn": 1051,
          "accuracy": 0.5620833333333334
        }
      },
      "auroc": 0.7754166666666666
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1349,
          "fn": 1051,
          "accuracy": 0.5620833333333334
        },
        "0.01": {
          "tp": 1349,
          "fn": 1051,
          "accuracy": 0.5620833333333334
        }
      },
      "auroc": 0.7754166666666666
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1332,
          "fn": 1068,
          "accuracy": 0.555
        },
        "0.01": {
          "tp": 1332,
          "fn": 1068,
          "accuracy": 0.555
        }
      },
      "auroc": 0.7718750000000002
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1332,
          "fn": 1068,
          "accuracy": 0.555
        },
        "0.01": {
          "tp": 1332,
          "fn": 1068,
          "accuracy": 0.555
        }
      },
      "auroc": 0.7718750000000002
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2681,
          "fn": 2119,
          "accuracy": 0.5585416666666667
        },
        "0.01": {
          "tp": 2681,
          "fn": 2119,
          "accuracy": 0.5585416666666667
        }
      },
      "auroc": 0.7736458333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2681,
          "fn": 2119,
          "accuracy": 0.5585416666666667
        },
        "0.01": {
          "tp": 2681,
          "fn": 2119,
          "accuracy": 0.5585416666666667
        }
      },
      "auroc": 0.7736458333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 756,
          "fn": 1644,
          "accuracy": 0.315
        },
        "0.01": {
          "tp": 756,
          "fn": 1644,
          "accuracy": 0.315
        }
      },
      "auroc": 0.651875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 756,
          "fn": 1644,
          "accuracy": 0.315
        },
        "0.01": {
          "tp": 756,
          "fn": 1644,
          "accuracy": 0.315
        }
      },
      "auroc": 0.651875
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 695,
          "fn": 1705,
          "accuracy": 0.28958333333333336
        },
        "0.01": {
          "tp": 695,
          "fn": 1705,
          "accuracy": 0.28958333333333336
        }
      },
      "auroc": 0.6391666666666667
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 695,
          "fn": 1705,
          "accuracy": 0.28958333333333336
        },
        "0.01": {
          "tp": 695,
          "fn": 1705,
          "accuracy": 0.28958333333333336
        }
      },
      "auroc": 0.6391666666666667
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1451,
          "fn": 3349,
          "accuracy": 0.3022916666666667
        },
        "0.01": {
          "tp": 1451,
          "fn": 3349,
          "accuracy": 0.3022916666666667
        }
      },
      "auroc": 0.6455208333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1451,
          "fn": 3349,
          "accuracy": 0.3022916666666667
        },
        "0.01": {
          "tp": 1451,
          "fn": 3349,
          "accuracy": 0.3022916666666667
        }
      },
      "auroc": 0.6455208333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1271,
          "fn": 1129,
          "accuracy": 0.5295833333333333
        },
        "0.01": {
          "tp": 1271,
          "fn": 1129,
          "accuracy": 0.5295833333333333
        }
      },
      "auroc": 0.7591666666666667
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1271,
          "fn": 1129,
          "accuracy": 0.5295833333333333
        },
        "0.01": {
          "tp": 1271,
          "fn": 1129,
          "accuracy": 0.5295833333333333
        }
      },
      "auroc": 0.7591666666666667
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 982,
          "fn": 1418,
          "accuracy": 0.4091666666666667
        },
        "0.01": {
          "tp": 982,
          "fn": 1418,
          "accuracy": 0.4091666666666667
        }
      },
      "auroc": 0.6989583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 982,
          "fn": 1418,
          "accuracy": 0.4091666666666667
        },
        "0.01": {
          "tp": 982,
          "fn": 1418,
          "accuracy": 0.4091666666666667
        }
      },
      "auroc": 0.6989583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2253,
          "fn": 2547,
          "accuracy": 0.469375
        },
        "0.01": {
          "tp": 2253,
          "fn": 2547,
          "accuracy": 0.469375
        }
      },
      "auroc": 0.7290625
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2253,
          "fn": 2547,
          "accuracy": 0.469375
        },
        "0.01": {
          "tp": 2253,
          "fn": 2547,
          "accuracy": 0.469375
        }
      },
      "auroc": 0.7290625
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1475,
          "fn": 925,
          "accuracy": 0.6145833333333334
        },
        "0.01": {
          "tp": 1475,
          "fn": 925,
          "accuracy": 0.6145833333333334
        }
      },
      "auroc": 0.8016666666666667
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1475,
          "fn": 925,
          "accuracy": 0.6145833333333334
        },
        "0.01": {
          "tp": 1475,
          "fn": 925,
          "accuracy": 0.6145833333333334
        }
      },
      "auroc": 0.8016666666666667
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 626,
          "fn": 1774,
          "accuracy": 0.2608333333333333
        },
        "0.01": {
          "tp": 626,
          "fn": 1774,
          "accuracy": 0.2608333333333333
        }
      },
      "auroc": 0.6247916666666666
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 626,
          "fn": 1774,
          "accuracy": 0.2608333333333333
        },
        "0.01": {
          "tp": 626,
          "fn": 1774,
          "accuracy": 0.2608333333333333
        }
      },
      "auroc": 0.6247916666666666
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2101,
          "fn": 2699,
          "accuracy": 0.4377083333333333
        },
        "0.01": {
          "tp": 2101,
          "fn": 2699,
          "accuracy": 0.4377083333333333
        }
      },
      "auroc": 0.7132291666666667
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2101,
          "fn": 2699,
          "accuracy": 0.4377083333333333
        },
        "0.01": {
          "tp": 2101,
          "fn": 2699,
          "accuracy": 0.4377083333333333
        }
      },
      "auroc": 0.7132291666666667
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 986,
          "fn": 1414,
          "accuracy": 0.41083333333333333
        },
        "0.01": {
          "tp": 986,
          "fn": 1414,
          "accuracy": 0.41083333333333333
        }
      },
      "auroc": 0.6997916666666667
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 986,
          "fn": 1414,
          "accuracy": 0.41083333333333333
        },
        "0.01": {
          "tp": 986,
          "fn": 1414,
          "accuracy": 0.41083333333333333
        }
      },
      "auroc": 0.6997916666666667
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 776,
          "fn": 1624,
          "accuracy": 0.3233333333333333
        },
        "0.01": {
          "tp": 776,
          "fn": 1624,
          "accuracy": 0.3233333333333333
        }
      },
      "auroc": 0.6560416666666666
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 776,
          "fn": 1624,
          "accuracy": 0.3233333333333333
        },
        "0.01": {
          "tp": 776,
          "fn": 1624,
          "accuracy": 0.3233333333333333
        }
      },
      "auroc": 0.6560416666666666
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1762,
          "fn": 3038,
          "accuracy": 0.3670833333333333
        },
        "0.01": {
          "tp": 1762,
          "fn": 3038,
          "accuracy": 0.3670833333333333
        }
      },
      "auroc": 0.6779166666666667
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1762,
          "fn": 3038,
          "accuracy": 0.3670833333333333
        },
        "0.01": {
          "tp": 1762,
          "fn": 3038,
          "accuracy": 0.3670833333333333
        }
      },
      "auroc": 0.6779166666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 10613,
          "fn": 15787,
          "accuracy": 0.40200757575757573
        },
        "0.01": {
          "tp": 10613,
          "fn": 15787,
          "accuracy": 0.40200757575757573
        }
      },
      "auroc": 0.6953787878787878
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3421,
          "fn": 10979,
          "accuracy": 0.23756944444444444
        },
        "0.01": {
          "tp": 3421,
          "fn": 10979,
          "accuracy": 0.23756944444444444
        }
      },
      "auroc": 0.6131597222222223
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 14034,
          "fn": 26766,
          "accuracy": 0.34397058823529414
        },
        "0.01": {
          "tp": 14034,
          "fn": 26766,
          "accuracy": 0.34397058823529414
        }
      },
      "auroc": 0.6663602941176471
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 10099,
          "fn": 16301,
          "accuracy": 0.3825378787878788
        },
        "0.01": {
          "tp": 10099,
          "fn": 16301,
          "accuracy": 0.3825378787878788
        }
      },
      "auroc": 0.6856439393939394
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1980,
          "fn": 12420,
          "accuracy": 0.1375
        },
        "0.01": {
          "tp": 1980,
          "fn": 12420,
          "accuracy": 0.1375
        }
      },
      "auroc": 0.563125
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 12079,
          "fn": 28721,
          "accuracy": 0.2960539215686275
        },
        "0.01": {
          "tp": 12079,
          "fn": 28721,
          "accuracy": 0.2960539215686275
        }
      },
      "auroc": 0.6424019607843138
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 20712,
          "fn": 32088,
          "accuracy": 0.3922727272727273
        },
        "0.01": {
          "tp": 20712,
          "fn": 32088,
          "accuracy": 0.3922727272727273
        }
      },
      "auroc": 0.6905113636363637
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 5401,
          "fn": 23399,
          "accuracy": 0.18753472222222223
        },
        "0.01": {
          "tp": 5401,
          "fn": 23399,
          "accuracy": 0.18753472222222223
        }
      },
      "auroc": 0.5881423611111112
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 26113,
          "fn": 55487,
          "accuracy": 0.3200122549019608
        },
        "0.01": {
          "tp": 26113,
          "fn": 55487,
          "accuracy": 0.3200122549019608
        }
      },
      "auroc": 0.6543811274509804
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7474999999999999
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8475
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7975
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7675
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7975
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7825000000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7575
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8225
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7899999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6825
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.755
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47250000000000003
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61375
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71875
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46499999999999997
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.591875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7899999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45999999999999996
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.624375
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5575
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8675
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8475
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7512500000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.731875
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5725
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6575
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.615
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5825
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5599999999999999
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6825
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7312500000000001
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6849999999999999
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6825
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68375
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.706875
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8575
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8575
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86125
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86125
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7374999999999999
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7374999999999999
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71375
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71375
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.795
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.795
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7725000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7725000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7837500000000001
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7837500000000001
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6625
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6625
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6475
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6475
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6950000000000001
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6897058823529412
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.745
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58625
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6889705882352941
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7200000000000001
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.633125
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6893382352941176
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.615
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.665
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6225
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4525
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5825
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7000000000000001
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47250000000000003
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7062499999999999
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5843750000000001
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7474999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45499999999999996
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.60125
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7274999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58625
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7374999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59375
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.89
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7637499999999999
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8099999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5750000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6925000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72375
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7325
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.728125
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.55
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4525
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.54625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6200000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47624999999999995
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.548125
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6200000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6575
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6175
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5675
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5925
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.615625
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8350000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8350000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8150000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8150000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8250000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8250000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5650000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5650000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5599999999999999
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5599999999999999
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5625
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5625
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.595
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.595
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6200000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6200000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6075
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6075
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.755
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.755
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7212500000000001
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7212500000000001
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5825
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5825
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6225
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6225
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6025
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6025
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6604545454545455
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6033333333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6402941176470588
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6754545454545454
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5245833333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6222058823529412
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6679545454545455
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5639583333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63125
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.745
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8300000000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7875
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7625
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8025
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7825000000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75375
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81625
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.785
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6925000000000001
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5750000000000001
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47250000000000003
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6075
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7175
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46499999999999997
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5912499999999999
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46499999999999997
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62625
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.785
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61625
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78625
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45625000000000004
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6212500000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5825
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8825
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7325
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8375
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73875
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7100000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7356250000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5875
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6175
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6025
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.705
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4525
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57875
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.535
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5906250000000001
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7775
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73375
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.675
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7043750000000001
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8575
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8575
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86375
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86375
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6212500000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6212500000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7000000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7000000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.725
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.725
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8225
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8225
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79125
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79125
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6575
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6575
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64125
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64125
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6916176470588236
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5791666666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.683235294117647
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7212500000000001
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6254166666666666
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6874264705882352
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7675
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8250000000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79625
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7725000000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77125
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7975
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7837500000000001
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.675
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.475
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59375
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6937500000000001
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46625000000000005
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8025
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7975
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6212500000000001
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7999999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45125000000000004
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625625
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5650000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8724999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71875
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6075
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71375
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6925000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7162499999999999
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5375
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56375
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4525
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63875
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.566875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.645
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7225
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68375
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6200000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6475
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67125
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.659375
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8575
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8575
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8524999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8524999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.855
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.855
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.615
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.615
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5925
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5925
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.60375
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.60375
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.675
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.675
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.705
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.705
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8350000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8350000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7575
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7575
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79625
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79625
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5975
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5975
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6200000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6200000000000001
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6931818181818182
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6454166666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6763235294117648
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7263636363636364
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5616666666666666
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.668235294117647
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7097727272727273
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6035416666666666
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6722794117647058
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7474999999999999
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8450000000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79625
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7675
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7925
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7575
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.81875
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7881250000000001
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56875
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7474999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47250000000000003
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71375
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46499999999999997
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.589375
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.785
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4525
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78625
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46125000000000005
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62375
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.555
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7100000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8425
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74625
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69875
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7575
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.728125
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46499999999999997
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58375
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5575
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.596875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6849999999999999
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.775
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6825
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6775
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68375
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72625
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.705
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8624999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8624999999999999
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6425
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6425
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6275000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6275000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6825
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6825
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7274999999999999
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7274999999999999
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.705
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.705
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7925
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7925
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7675
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7675
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.645
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.645
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6943181818181818
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6770833333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6882352941176471
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7413636363636363
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.585
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6861764705882353
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.717840909090909
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6310416666666666
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6872058823529412
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5599999999999999
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5475
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.55375
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5875
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57875
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57375
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.55875
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6675
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66125
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5925
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5975
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.595
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.628125
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6849999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6675
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6849999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6575
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6575
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6675
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6625
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8150000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7474999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5825
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5525
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5675
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69875
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6743750000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7100000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.675
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6925000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5825
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5525
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5675
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61375
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63125
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63375
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6075
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.620625
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7075
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7075
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7625
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7625
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.735
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.735
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.715
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.715
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6825
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6825
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69875
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69875
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.645
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.645
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6675
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6675
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6537499999999999
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6537499999999999
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6763636363636364
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6670588235294118
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5912499999999999
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6163235294117647
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6531818181818182
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.620625
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6416911764705883
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8150000000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7875
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7975
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7899999999999999
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7937500000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7787499999999999
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8025
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.790625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.795
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.755
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47250000000000003
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61375
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.775
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46499999999999997
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6200000000000001
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8675
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4675
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6675
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.855
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6525
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86125
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.745
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9175
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.83125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8450000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.795
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77625
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.785625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6775
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5975
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7274999999999999
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.595
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.53
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61625
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.755
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7975
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77625
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.765
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6925000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.745
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7525000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8675
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8675
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.65
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6200000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6200000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7525000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7525000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8075
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8075
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.88
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.805
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.805
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6475
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6475
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7636363636363636
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6754166666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7325
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7777272727272727
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58375
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.709264705882353
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7706818181818181
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6295833333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7208823529411764
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7274999999999999
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7837500000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.755
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.805
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7412500000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8225
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.781875
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6675
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45999999999999996
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56375
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.715
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.475
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.595
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.475
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5775
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4525
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68375
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46375
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57375
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5525
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8724999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8275
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.725
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77625
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79875
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.744375
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6275000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.60375
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5962500000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5650000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6775
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.72875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6925000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6575
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.675
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6849999999999999
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.701875
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8675
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8675
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8375
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8375
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8524999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8524999999999999
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6275000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6275000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64375
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64375
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6950000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6950000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7075
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7075
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70125
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70125
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.775
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.775
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7625
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7625
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76875
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76875
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6525
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6525
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64625
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64625
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6838636363636363
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6758333333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6810294117647059
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7274999999999999
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6054166666666666
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6844117647058824
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7056818181818182
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.640625
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6827205882352941
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44625000000000004
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44625000000000004
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44625000000000004
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46499999999999997
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45375
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.475
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44625000000000004
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.458125
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4625
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4525
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.485
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45999999999999996
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47250000000000003
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46375
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46125000000000005
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45499999999999996
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44875
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44875
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44562500000000005
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4525
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4525
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44875
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44875
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44545454545454544
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44666666666666666
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4458823529411765
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4540909090909091
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44791666666666663
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45191176470588235
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4497727272727273
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44729166666666664
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4488970588235294
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.735
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7875
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7675
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7999999999999999
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7837500000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7512500000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.785625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6849999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57125
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47250000000000003
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6062500000000001
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46499999999999997
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7899999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46499999999999997
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6275000000000001
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.785
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6175
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6225
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5575
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8675
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.84
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.645
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7425
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69875
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.75625
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7274999999999999
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5750000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6175
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6975
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.56125
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.785
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73625
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6849999999999999
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6775
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68625
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7274999999999999
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.706875
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8575
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8575
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8624999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8624999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6275000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6275000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61625
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61625
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7325
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7325
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7100000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7100000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7899999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7899999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7575
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7575
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77375
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77375
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.665
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.665
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6537499999999999
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6537499999999999
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6940909090909091
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6791666666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6888235294117647
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7397727272727274
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5833333333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6845588235294118
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7169318181818182
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63125
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6866911764705882
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8450000000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7925
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7625
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7975
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7512500000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8212499999999999
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78625
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6825
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4575
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.755
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47250000000000003
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61375
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.71875
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46499999999999997
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.591875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7925
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4675
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44999999999999996
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.61875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7899999999999999
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.624375
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5575
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8675
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8475
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7512500000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.76125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.731875
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5725
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6525
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7000000000000001
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58125
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63625
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5575
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.596875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.775
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7274999999999999
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7274999999999999
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70375
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8524999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8524999999999999
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.86
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8562500000000001
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8562500000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6375000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7325
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7325
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7100000000000001
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7100000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7925
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7925
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.77
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78125
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78125
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.66
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64625
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64625
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.693409090909091
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6775
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6877941176470589
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7425
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.58625
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6873529411764706
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7179545454545454
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.631875
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875735294117648
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4475
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44499999999999995
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44375
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44333333333333336
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4427941176470588
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4425
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4429166666666666
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4426470588235294
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666667
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7325
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7008333333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6885416666666667
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7039583333333334
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69625
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6788541666666666
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7182291666666667
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6985416666666667
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6539583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47125000000000006
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5626041666666667
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6816666666666666
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48020833333333335
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5809375
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6678125
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47572916666666665
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5717708333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7179166666666668
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47729166666666667
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5976041666666666
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.709375
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4677083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5885416666666666
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7136458333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47250000000000003
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5930729166666667
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5841666666666666
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.79625
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6902083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7522916666666667
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6039583333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.678125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6682291666666667
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7001041666666666
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6841666666666667
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5766666666666667
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5883333333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5825
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.644375
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4677083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5560416666666667
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6105208333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5280208333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5692708333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6370833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6966666666666667
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.666875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6389583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6154166666666666
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6271875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6380208333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6560416666666666
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6470312500000001
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7760416666666666
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7760416666666666
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7791666666666667
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7791666666666667
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7776041666666667
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7776041666666667
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6062500000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6062500000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5854166666666667
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5854166666666667
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5958333333333334
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5958333333333334
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64125
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64125
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6654166666666667
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6654166666666667
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6533333333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6533333333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.729375
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.729375
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6966666666666667
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6966666666666667
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7130208333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7130208333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6218750000000001
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6218750000000001
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6105208333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6105208333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6537310606060606
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6270486111111111
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.644313725490196
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6785227272727273
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5564930555555555
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6354534313725491
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6661268939393941
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5917708333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6398835784313726
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 192,
          "fn": 8,
          "accuracy": 0.96
        },
        "0.01": {
          "tp": 192,
          "fn": 8,
          "accuracy": 0.96
        }
      },
      "auroc": 0.9635416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 190,
          "fn": 10,
          "accuracy": 0.95
        },
        "0.01": {
          "tp": 190,
          "fn": 10,
          "accuracy": 0.95
        }
      },
      "auroc": 0.9585416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 382,
          "fn": 18,
          "accuracy": 0.955
        },
        "0.01": {
          "tp": 382,
          "fn": 18,
          "accuracy": 0.955
        }
      },
      "auroc": 0.9610416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 172,
          "fn": 28,
          "accuracy": 0.86
        },
        "0.01": {
          "tp": 172,
          "fn": 28,
          "accuracy": 0.86
        }
      },
      "auroc": 0.9135416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 358,
          "fn": 42,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 358,
          "fn": 42,
          "accuracy": 0.895
        }
      },
      "auroc": 0.9310416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 378,
          "fn": 22,
          "accuracy": 0.945
        },
        "0.01": {
          "tp": 378,
          "fn": 22,
          "accuracy": 0.945
        }
      },
      "auroc": 0.9560416666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 362,
          "fn": 38,
          "accuracy": 0.905
        },
        "0.01": {
          "tp": 362,
          "fn": 38,
          "accuracy": 0.905
        }
      },
      "auroc": 0.9360416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 740,
          "fn": 60,
          "accuracy": 0.925
        },
        "0.01": {
          "tp": 740,
          "fn": 60,
          "accuracy": 0.925
        }
      },
      "auroc": 0.9460416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 38,
          "fn": 362,
          "accuracy": 0.095
        },
        "0.01": {
          "tp": 38,
          "fn": 362,
          "accuracy": 0.095
        }
      },
      "auroc": 0.5310416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        }
      },
      "auroc": 0.5635416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        },
        "0.01": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        }
      },
      "auroc": 0.5335416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 52,
          "fn": 348,
          "accuracy": 0.13
        },
        "0.01": {
          "tp": 52,
          "fn": 348,
          "accuracy": 0.13
        }
      },
      "auroc": 0.5485416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 341,
          "accuracy": 0.1475
        },
        "0.01": {
          "tp": 59,
          "fn": 341,
          "accuracy": 0.1475
        }
      },
      "auroc": 0.5572916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        },
        "0.01": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        }
      },
      "auroc": 0.5222916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 710,
          "accuracy": 0.1125
        },
        "0.01": {
          "tp": 90,
          "fn": 710,
          "accuracy": 0.1125
        }
      },
      "auroc": 0.5397916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 44,
          "accuracy": 0.78
        },
        "0.01": {
          "tp": 156,
          "fn": 44,
          "accuracy": 0.78
        }
      },
      "auroc": 0.8735416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.7910416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 279,
          "fn": 121,
          "accuracy": 0.6975
        },
        "0.01": {
          "tp": 279,
          "fn": 121,
          "accuracy": 0.6975
        }
      },
      "auroc": 0.8322916666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 152,
          "fn": 48,
          "accuracy": 0.76
        },
        "0.01": {
          "tp": 152,
          "fn": 48,
          "accuracy": 0.76
        }
      },
      "auroc": 0.8635416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 96,
          "fn": 104,
          "accuracy": 0.48
        },
        "0.01": {
          "tp": 96,
          "fn": 104,
          "accuracy": 0.48
        }
      },
      "auroc": 0.7235416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 248,
          "fn": 152,
          "accuracy": 0.62
        },
        "0.01": {
          "tp": 248,
          "fn": 152,
          "accuracy": 0.62
        }
      },
      "auroc": 0.7935416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 308,
          "fn": 92,
          "accuracy": 0.77
        },
        "0.01": {
          "tp": 308,
          "fn": 92,
          "accuracy": 0.77
        }
      },
      "auroc": 0.8685416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 219,
          "fn": 181,
          "accuracy": 0.5475
        },
        "0.01": {
          "tp": 219,
          "fn": 181,
          "accuracy": 0.5475
        }
      },
      "auroc": 0.7572916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 527,
          "fn": 273,
          "accuracy": 0.65875
        },
        "0.01": {
          "tp": 527,
          "fn": 273,
          "accuracy": 0.65875
        }
      },
      "auroc": 0.8129166666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        }
      },
      "auroc": 0.5060416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        }
      },
      "auroc": 0.6885416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        },
        "0.01": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        }
      },
      "auroc": 0.5972916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        },
        "0.01": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        }
      },
      "auroc": 0.7035416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5435416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 288,
          "accuracy": 0.28
        },
        "0.01": {
          "tp": 112,
          "fn": 288,
          "accuracy": 0.28
        }
      },
      "auroc": 0.6235416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 97,
          "fn": 303,
          "accuracy": 0.2425
        },
        "0.01": {
          "tp": 97,
          "fn": 303,
          "accuracy": 0.2425
        }
      },
      "auroc": 0.6047916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 106,
          "fn": 294,
          "accuracy": 0.265
        },
        "0.01": {
          "tp": 106,
          "fn": 294,
          "accuracy": 0.265
        }
      },
      "auroc": 0.6160416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 203,
          "fn": 597,
          "accuracy": 0.25375
        },
        "0.01": {
          "tp": 203,
          "fn": 597,
          "accuracy": 0.25375
        }
      },
      "auroc": 0.6104166666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        }
      },
      "auroc": 0.5735416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        },
        "0.01": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        }
      },
      "auroc": 0.5622916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        },
        "0.01": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        }
      },
      "auroc": 0.7085416666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        },
        "0.01": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        }
      },
      "auroc": 0.6097916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 283,
          "accuracy": 0.2925
        },
        "0.01": {
          "tp": 117,
          "fn": 283,
          "accuracy": 0.2925
        }
      },
      "auroc": 0.6297916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        },
        "0.01": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        }
      },
      "auroc": 0.5422916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 164,
          "fn": 636,
          "accuracy": 0.205
        },
        "0.01": {
          "tp": 164,
          "fn": 636,
          "accuracy": 0.205
        }
      },
      "auroc": 0.5860416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        },
        "0.01": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        }
      },
      "auroc": 0.9110416666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        },
        "0.01": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        }
      },
      "auroc": 0.9435416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 355,
          "fn": 45,
          "accuracy": 0.8875
        },
        "0.01": {
          "tp": 355,
          "fn": 45,
          "accuracy": 0.8875
        }
      },
      "auroc": 0.9272916666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 162,
          "fn": 38,
          "accuracy": 0.81
        },
        "0.01": {
          "tp": 162,
          "fn": 38,
          "accuracy": 0.81
        }
      },
      "auroc": 0.8885416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        },
        "0.01": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        }
      },
      "auroc": 0.7935416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 286,
          "fn": 114,
          "accuracy": 0.715
        },
        "0.01": {
          "tp": 286,
          "fn": 114,
          "accuracy": 0.715
        }
      },
      "auroc": 0.8410416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 333,
          "fn": 67,
          "accuracy": 0.8325
        },
        "0.01": {
          "tp": 333,
          "fn": 67,
          "accuracy": 0.8325
        }
      },
      "auroc": 0.8997916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 308,
          "fn": 92,
          "accuracy": 0.77
        },
        "0.01": {
          "tp": 308,
          "fn": 92,
          "accuracy": 0.77
        }
      },
      "auroc": 0.8685416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 641,
          "fn": 159,
          "accuracy": 0.80125
        },
        "0.01": {
          "tp": 641,
          "fn": 159,
          "accuracy": 0.80125
        }
      },
      "auroc": 0.8841666666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        },
        "0.01": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        }
      },
      "auroc": 0.9410416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        },
        "0.01": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        }
      },
      "auroc": 0.9410416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 189,
          "fn": 11,
          "accuracy": 0.945
        },
        "0.01": {
          "tp": 189,
          "fn": 11,
          "accuracy": 0.945
        }
      },
      "auroc": 0.9560416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 189,
          "fn": 11,
          "accuracy": 0.945
        },
        "0.01": {
          "tp": 189,
          "fn": 11,
          "accuracy": 0.945
        }
      },
      "auroc": 0.9560416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 372,
          "fn": 28,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 372,
          "fn": 28,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 372,
          "fn": 28,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 372,
          "fn": 28,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        },
        "0.01": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        }
      },
      "auroc": 0.7335416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        },
        "0.01": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        }
      },
      "auroc": 0.7335416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 210,
          "fn": 190,
          "accuracy": 0.525
        },
        "0.01": {
          "tp": 210,
          "fn": 190,
          "accuracy": 0.525
        }
      },
      "auroc": 0.7460416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 210,
          "fn": 190,
          "accuracy": 0.525
        },
        "0.01": {
          "tp": 210,
          "fn": 190,
          "accuracy": 0.525
        }
      },
      "auroc": 0.7460416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        },
        "0.01": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        }
      },
      "auroc": 0.7810416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        },
        "0.01": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        }
      },
      "auroc": 0.7810416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        },
        "0.01": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        }
      },
      "auroc": 0.7885416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        },
        "0.01": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        }
      },
      "auroc": 0.7885416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 241,
          "fn": 159,
          "accuracy": 0.6025
        },
        "0.01": {
          "tp": 241,
          "fn": 159,
          "accuracy": 0.6025
        }
      },
      "auroc": 0.7847916666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 241,
          "fn": 159,
          "accuracy": 0.6025
        },
        "0.01": {
          "tp": 241,
          "fn": 159,
          "accuracy": 0.6025
        }
      },
      "auroc": 0.7847916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        },
        "0.01": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        }
      },
      "auroc": 0.9510416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        },
        "0.01": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        }
      },
      "auroc": 0.9510416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        },
        "0.01": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        }
      },
      "auroc": 0.9285416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        },
        "0.01": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        }
      },
      "auroc": 0.9285416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 365,
          "fn": 35,
          "accuracy": 0.9125
        },
        "0.01": {
          "tp": 365,
          "fn": 35,
          "accuracy": 0.9125
        }
      },
      "auroc": 0.9397916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 365,
          "fn": 35,
          "accuracy": 0.9125
        },
        "0.01": {
          "tp": 365,
          "fn": 35,
          "accuracy": 0.9125
        }
      },
      "auroc": 0.9397916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 127,
          "fn": 73,
          "accuracy": 0.635
        },
        "0.01": {
          "tp": 127,
          "fn": 73,
          "accuracy": 0.635
        }
      },
      "auroc": 0.8010416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 127,
          "fn": 73,
          "accuracy": 0.635
        },
        "0.01": {
          "tp": 127,
          "fn": 73,
          "accuracy": 0.635
        }
      },
      "auroc": 0.8010416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 237,
          "fn": 163,
          "accuracy": 0.5925
        },
        "0.01": {
          "tp": 237,
          "fn": 163,
          "accuracy": 0.5925
        }
      },
      "auroc": 0.7797916666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 237,
          "fn": 163,
          "accuracy": 0.5925
        },
        "0.01": {
          "tp": 237,
          "fn": 163,
          "accuracy": 0.5925
        }
      },
      "auroc": 0.7797916666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1308,
          "fn": 892,
          "accuracy": 0.5945454545454546
        },
        "0.01": {
          "tp": 1308,
          "fn": 892,
          "accuracy": 0.5945454545454546
        }
      },
      "auroc": 0.780814393939394
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 626,
          "fn": 574,
          "accuracy": 0.5216666666666666
        },
        "0.01": {
          "tp": 626,
          "fn": 574,
          "accuracy": 0.5216666666666666
        }
      },
      "auroc": 0.7443749999999999
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1934,
          "fn": 1466,
          "accuracy": 0.5688235294117647
        },
        "0.01": {
          "tp": 1934,
          "fn": 1466,
          "accuracy": 0.5688235294117647
        }
      },
      "auroc": 0.767953431372549
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1409,
          "fn": 791,
          "accuracy": 0.6404545454545455
        },
        "0.01": {
          "tp": 1409,
          "fn": 791,
          "accuracy": 0.6404545454545455
        }
      },
      "auroc": 0.8037689393939395
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 447,
          "fn": 753,
          "accuracy": 0.3725
        },
        "0.01": {
          "tp": 447,
          "fn": 753,
          "accuracy": 0.3725
        }
      },
      "auroc": 0.6697916666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1856,
          "fn": 1544,
          "accuracy": 0.5458823529411765
        },
        "0.01": {
          "tp": 1856,
          "fn": 1544,
          "accuracy": 0.5458823529411765
        }
      },
      "auroc": 0.7564828431372549
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 2717,
          "fn": 1683,
          "accuracy": 0.6175
        },
        "0.01": {
          "tp": 2717,
          "fn": 1683,
          "accuracy": 0.6175
        }
      },
      "auroc": 0.7922916666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 1073,
          "fn": 1327,
          "accuracy": 0.44708333333333333
        },
        "0.01": {
          "tp": 1073,
          "fn": 1327,
          "accuracy": 0.44708333333333333
        }
      },
      "auroc": 0.7070833333333332
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": {
          "tp": 3790,
          "fn": 3010,
          "accuracy": 0.5573529411764706
        },
        "0.01": {
          "tp": 3790,
          "fn": 3010,
          "accuracy": 0.5573529411764706
        }
      },
      "auroc": 0.762218137254902
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        },
        "0.01": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        }
      },
      "auroc": 0.9235416666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        },
        "0.01": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        }
      },
      "auroc": 0.8860416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 337,
          "fn": 63,
          "accuracy": 0.8425
        },
        "0.01": {
          "tp": 337,
          "fn": 63,
          "accuracy": 0.8425
        }
      },
      "auroc": 0.9047916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        },
        "0.01": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        }
      },
      "auroc": 0.8785416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 142,
          "fn": 58,
          "accuracy": 0.71
        },
        "0.01": {
          "tp": 142,
          "fn": 58,
          "accuracy": 0.71
        }
      },
      "auroc": 0.8385416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 300,
          "fn": 100,
          "accuracy": 0.75
        },
        "0.01": {
          "tp": 300,
          "fn": 100,
          "accuracy": 0.75
        }
      },
      "auroc": 0.8585416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 334,
          "fn": 66,
          "accuracy": 0.835
        },
        "0.01": {
          "tp": 334,
          "fn": 66,
          "accuracy": 0.835
        }
      },
      "auroc": 0.9010416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 303,
          "fn": 97,
          "accuracy": 0.7575
        },
        "0.01": {
          "tp": 303,
          "fn": 97,
          "accuracy": 0.7575
        }
      },
      "auroc": 0.8622916666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 637,
          "fn": 163,
          "accuracy": 0.79625
        },
        "0.01": {
          "tp": 637,
          "fn": 163,
          "accuracy": 0.79625
        }
      },
      "auroc": 0.8816666666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        },
        "0.01": {
          "tp": 37,
          "fn": 163,
          "accuracy": 0.185
        }
      },
      "auroc": 0.5760416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        }
      },
      "auroc": 0.4960416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 42,
          "fn": 358,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 42,
          "fn": 358,
          "accuracy": 0.105
        }
      },
      "auroc": 0.5360416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 19,
          "fn": 181,
          "accuracy": 0.095
        },
        "0.01": {
          "tp": 19,
          "fn": 181,
          "accuracy": 0.095
        }
      },
      "auroc": 0.5310416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        },
        "0.01": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        }
      },
      "auroc": 0.5260416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 364,
          "accuracy": 0.09
        },
        "0.01": {
          "tp": 36,
          "fn": 364,
          "accuracy": 0.09
        }
      },
      "auroc": 0.5285416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5535416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 378,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 22,
          "fn": 378,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 722,
          "accuracy": 0.0975
        },
        "0.01": {
          "tp": 78,
          "fn": 722,
          "accuracy": 0.0975
        }
      },
      "auroc": 0.5322916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 63,
          "fn": 137,
          "accuracy": 0.315
        },
        "0.01": {
          "tp": 63,
          "fn": 137,
          "accuracy": 0.315
        }
      },
      "auroc": 0.6410416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        },
        "0.01": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        }
      },
      "auroc": 0.5810416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 102,
          "fn": 298,
          "accuracy": 0.255
        },
        "0.01": {
          "tp": 102,
          "fn": 298,
          "accuracy": 0.255
        }
      },
      "auroc": 0.6110416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        }
      },
      "auroc": 0.6485416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        }
      },
      "auroc": 0.5635416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 302,
          "accuracy": 0.245
        },
        "0.01": {
          "tp": 98,
          "fn": 302,
          "accuracy": 0.245
        }
      },
      "auroc": 0.6060416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 129,
          "fn": 271,
          "accuracy": 0.3225
        },
        "0.01": {
          "tp": 129,
          "fn": 271,
          "accuracy": 0.3225
        }
      },
      "auroc": 0.6447916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 329,
          "accuracy": 0.1775
        },
        "0.01": {
          "tp": 71,
          "fn": 329,
          "accuracy": 0.1775
        }
      },
      "auroc": 0.5722916666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 200,
          "fn": 600,
          "accuracy": 0.25
        },
        "0.01": {
          "tp": 200,
          "fn": 600,
          "accuracy": 0.25
        }
      },
      "auroc": 0.6085416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 21,
          "fn": 179,
          "accuracy": 0.105
        }
      },
      "auroc": 0.5360416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        },
        "0.01": {
          "tp": 48,
          "fn": 152,
          "accuracy": 0.24
        }
      },
      "auroc": 0.6035416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 69,
          "fn": 331,
          "accuracy": 0.1725
        },
        "0.01": {
          "tp": 69,
          "fn": 331,
          "accuracy": 0.1725
        }
      },
      "auroc": 0.5697916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        }
      },
      "auroc": 0.6335416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 71,
          "fn": 329,
          "accuracy": 0.1775
        },
        "0.01": {
          "tp": 71,
          "fn": 329,
          "accuracy": 0.1775
        }
      },
      "auroc": 0.5722916666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 319,
          "accuracy": 0.2025
        },
        "0.01": {
          "tp": 81,
          "fn": 319,
          "accuracy": 0.2025
        }
      },
      "auroc": 0.5847916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 341,
          "accuracy": 0.1475
        },
        "0.01": {
          "tp": 59,
          "fn": 341,
          "accuracy": 0.1475
        }
      },
      "auroc": 0.5572916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 140,
          "fn": 660,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 140,
          "fn": 660,
          "accuracy": 0.175
        }
      },
      "auroc": 0.5710416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        },
        "0.01": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        }
      },
      "auroc": 0.5285416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5385416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        },
        "0.01": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        }
      },
      "auroc": 0.5335416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        },
        "0.01": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        }
      },
      "auroc": 0.6385416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        },
        "0.01": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        }
      },
      "auroc": 0.5747916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 320,
          "accuracy": 0.2
        },
        "0.01": {
          "tp": 80,
          "fn": 320,
          "accuracy": 0.2
        }
      },
      "auroc": 0.5835416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        },
        "0.01": {
          "tp": 33,
          "fn": 367,
          "accuracy": 0.0825
        }
      },
      "auroc": 0.5247916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 113,
          "fn": 687,
          "accuracy": 0.14125
        },
        "0.01": {
          "tp": 113,
          "fn": 687,
          "accuracy": 0.14125
        }
      },
      "auroc": 0.5541666666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 125,
          "fn": 75,
          "accuracy": 0.625
        },
        "0.01": {
          "tp": 125,
          "fn": 75,
          "accuracy": 0.625
        }
      },
      "auroc": 0.7960416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        },
        "0.01": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        }
      },
      "auroc": 0.8785416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 283,
          "fn": 117,
          "accuracy": 0.7075
        },
        "0.01": {
          "tp": 283,
          "fn": 117,
          "accuracy": 0.7075
        }
      },
      "auroc": 0.8372916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 115,
          "fn": 85,
          "accuracy": 0.575
        },
        "0.01": {
          "tp": 115,
          "fn": 85,
          "accuracy": 0.575
        }
      },
      "auroc": 0.7710416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        },
        "0.01": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        }
      },
      "auroc": 0.6910416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 198,
          "fn": 202,
          "accuracy": 0.495
        },
        "0.01": {
          "tp": 198,
          "fn": 202,
          "accuracy": 0.495
        }
      },
      "auroc": 0.7310416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 240,
          "fn": 160,
          "accuracy": 0.6
        },
        "0.01": {
          "tp": 240,
          "fn": 160,
          "accuracy": 0.6
        }
      },
      "auroc": 0.7835416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 241,
          "fn": 159,
          "accuracy": 0.6025
        },
        "0.01": {
          "tp": 241,
          "fn": 159,
          "accuracy": 0.6025
        }
      },
      "auroc": 0.7847916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 481,
          "fn": 319,
          "accuracy": 0.60125
        },
        "0.01": {
          "tp": 481,
          "fn": 319,
          "accuracy": 0.60125
        }
      },
      "auroc": 0.7841666666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 44,
          "accuracy": 0.78
        },
        "0.01": {
          "tp": 156,
          "fn": 44,
          "accuracy": 0.78
        }
      },
      "auroc": 0.8735416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 44,
          "accuracy": 0.78
        },
        "0.01": {
          "tp": 156,
          "fn": 44,
          "accuracy": 0.78
        }
      },
      "auroc": 0.8735416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        },
        "0.01": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        }
      },
      "auroc": 0.8785416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        },
        "0.01": {
          "tp": 158,
          "fn": 42,
          "accuracy": 0.79
        }
      },
      "auroc": 0.8785416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        },
        "0.01": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        }
      },
      "auroc": 0.8760416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        },
        "0.01": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        }
      },
      "auroc": 0.8760416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        },
        "0.01": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        }
      },
      "auroc": 0.6435416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        },
        "0.01": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        }
      },
      "auroc": 0.6435416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        },
        "0.01": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        }
      },
      "auroc": 0.6385416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        },
        "0.01": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        }
      },
      "auroc": 0.6385416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 126,
          "fn": 274,
          "accuracy": 0.315
        },
        "0.01": {
          "tp": 126,
          "fn": 274,
          "accuracy": 0.315
        }
      },
      "auroc": 0.6410416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 126,
          "fn": 274,
          "accuracy": 0.315
        },
        "0.01": {
          "tp": 126,
          "fn": 274,
          "accuracy": 0.315
        }
      },
      "auroc": 0.6410416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 151,
          "accuracy": 0.245
        },
        "0.01": {
          "tp": 49,
          "fn": 151,
          "accuracy": 0.245
        }
      },
      "auroc": 0.6060416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 151,
          "accuracy": 0.245
        },
        "0.01": {
          "tp": 49,
          "fn": 151,
          "accuracy": 0.245
        }
      },
      "auroc": 0.6060416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        },
        "0.01": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        }
      },
      "auroc": 0.6260416666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        },
        "0.01": {
          "tp": 57,
          "fn": 143,
          "accuracy": 0.285
        }
      },
      "auroc": 0.6260416666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 106,
          "fn": 294,
          "accuracy": 0.265
        },
        "0.01": {
          "tp": 106,
          "fn": 294,
          "accuracy": 0.265
        }
      },
      "auroc": 0.6160416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 106,
          "fn": 294,
          "accuracy": 0.265
        },
        "0.01": {
          "tp": 106,
          "fn": 294,
          "accuracy": 0.265
        }
      },
      "auroc": 0.6160416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        },
        "0.01": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        }
      },
      "auroc": 0.7760416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        },
        "0.01": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        }
      },
      "auroc": 0.7760416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        },
        "0.01": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        }
      },
      "auroc": 0.7885416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        },
        "0.01": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        }
      },
      "auroc": 0.7885416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 239,
          "fn": 161,
          "accuracy": 0.5975
        },
        "0.01": {
          "tp": 239,
          "fn": 161,
          "accuracy": 0.5975
        }
      },
      "auroc": 0.7822916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 239,
          "fn": 161,
          "accuracy": 0.5975
        },
        "0.01": {
          "tp": 239,
          "fn": 161,
          "accuracy": 0.5975
        }
      },
      "auroc": 0.7822916666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        }
      },
      "auroc": 0.6485416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        }
      },
      "auroc": 0.6485416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        },
        "0.01": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        }
      },
      "auroc": 0.6385416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        },
        "0.01": {
          "tp": 62,
          "fn": 138,
          "accuracy": 0.31
        }
      },
      "auroc": 0.6385416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 272,
          "accuracy": 0.32
        },
        "0.01": {
          "tp": 128,
          "fn": 272,
          "accuracy": 0.32
        }
      },
      "auroc": 0.6435416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 128,
          "fn": 272,
          "accuracy": 0.32
        },
        "0.01": {
          "tp": 128,
          "fn": 272,
          "accuracy": 0.32
        }
      },
      "auroc": 0.6435416666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 892,
          "fn": 1308,
          "accuracy": 0.40545454545454546
        },
        "0.01": {
          "tp": 892,
          "fn": 1308,
          "accuracy": 0.40545454545454546
        }
      },
      "auroc": 0.6862689393939394
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 433,
          "fn": 767,
          "accuracy": 0.36083333333333334
        },
        "0.01": {
          "tp": 433,
          "fn": 767,
          "accuracy": 0.36083333333333334
        }
      },
      "auroc": 0.6639583333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 1325,
          "fn": 2075,
          "accuracy": 0.3897058823529412
        },
        "0.01": {
          "tp": 1325,
          "fn": 2075,
          "accuracy": 0.3897058823529412
        }
      },
      "auroc": 0.6783946078431372
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 941,
          "fn": 1259,
          "accuracy": 0.42772727272727273
        },
        "0.01": {
          "tp": 941,
          "fn": 1259,
          "accuracy": 0.42772727272727273
        }
      },
      "auroc": 0.697405303030303
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 296,
          "fn": 904,
          "accuracy": 0.24666666666666667
        },
        "0.01": {
          "tp": 296,
          "fn": 904,
          "accuracy": 0.24666666666666667
        }
      },
      "auroc": 0.6068749999999999
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 1237,
          "fn": 2163,
          "accuracy": 0.3638235294117647
        },
        "0.01": {
          "tp": 1237,
          "fn": 2163,
          "accuracy": 0.3638235294117647
        }
      },
      "auroc": 0.665453431372549
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 1833,
          "fn": 2567,
          "accuracy": 0.41659090909090907
        },
        "0.01": {
          "tp": 1833,
          "fn": 2567,
          "accuracy": 0.41659090909090907
        }
      },
      "auroc": 0.6918371212121212
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 729,
          "fn": 1671,
          "accuracy": 0.30375
        },
        "0.01": {
          "tp": 729,
          "fn": 1671,
          "accuracy": 0.30375
        }
      },
      "auroc": 0.6354166666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": {
          "tp": 2562,
          "fn": 4238,
          "accuracy": 0.37676470588235295
        },
        "0.01": {
          "tp": 2562,
          "fn": 4238,
          "accuracy": 0.37676470588235295
        }
      },
      "auroc": 0.6719240196078431
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 191,
          "fn": 9,
          "accuracy": 0.955
        },
        "0.01": {
          "tp": 191,
          "fn": 9,
          "accuracy": 0.955
        }
      },
      "auroc": 0.9610416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 377,
          "fn": 23,
          "accuracy": 0.9425
        },
        "0.01": {
          "tp": 377,
          "fn": 23,
          "accuracy": 0.9425
        }
      },
      "auroc": 0.9547916666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 180,
          "fn": 20,
          "accuracy": 0.9
        },
        "0.01": {
          "tp": 180,
          "fn": 20,
          "accuracy": 0.9
        }
      },
      "auroc": 0.9335416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        },
        "0.01": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        }
      },
      "auroc": 0.8985416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 346,
          "fn": 54,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 346,
          "fn": 54,
          "accuracy": 0.865
        }
      },
      "auroc": 0.9160416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 371,
          "fn": 29,
          "accuracy": 0.9275
        },
        "0.01": {
          "tp": 371,
          "fn": 29,
          "accuracy": 0.9275
        }
      },
      "auroc": 0.9472916666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 352,
          "fn": 48,
          "accuracy": 0.88
        },
        "0.01": {
          "tp": 352,
          "fn": 48,
          "accuracy": 0.88
        }
      },
      "auroc": 0.9235416666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 723,
          "fn": 77,
          "accuracy": 0.90375
        },
        "0.01": {
          "tp": 723,
          "fn": 77,
          "accuracy": 0.90375
        }
      },
      "auroc": 0.9354166666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5535416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        }
      },
      "auroc": 0.5085416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 38,
          "fn": 362,
          "accuracy": 0.095
        },
        "0.01": {
          "tp": 38,
          "fn": 362,
          "accuracy": 0.095
        }
      },
      "auroc": 0.5310416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 19,
          "fn": 181,
          "accuracy": 0.095
        },
        "0.01": {
          "tp": 19,
          "fn": 181,
          "accuracy": 0.095
        }
      },
      "auroc": 0.5310416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 354,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 46,
          "fn": 354,
          "accuracy": 0.115
        }
      },
      "auroc": 0.5410416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        },
        "0.01": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        }
      },
      "auroc": 0.5522916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 371,
          "accuracy": 0.0725
        },
        "0.01": {
          "tp": 29,
          "fn": 371,
          "accuracy": 0.0725
        }
      },
      "auroc": 0.5197916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 716,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 84,
          "fn": 716,
          "accuracy": 0.105
        }
      },
      "auroc": 0.5360416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 141,
          "fn": 59,
          "accuracy": 0.705
        },
        "0.01": {
          "tp": 141,
          "fn": 59,
          "accuracy": 0.705
        }
      },
      "auroc": 0.8360416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        }
      },
      "auroc": 0.7535416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 249,
          "fn": 151,
          "accuracy": 0.6225
        },
        "0.01": {
          "tp": 249,
          "fn": 151,
          "accuracy": 0.6225
        }
      },
      "auroc": 0.7947916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        },
        "0.01": {
          "tp": 134,
          "fn": 66,
          "accuracy": 0.67
        }
      },
      "auroc": 0.8185416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        }
      },
      "auroc": 0.6885416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 216,
          "fn": 184,
          "accuracy": 0.54
        },
        "0.01": {
          "tp": 216,
          "fn": 184,
          "accuracy": 0.54
        }
      },
      "auroc": 0.7535416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 275,
          "fn": 125,
          "accuracy": 0.6875
        },
        "0.01": {
          "tp": 275,
          "fn": 125,
          "accuracy": 0.6875
        }
      },
      "auroc": 0.8272916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 190,
          "fn": 210,
          "accuracy": 0.475
        },
        "0.01": {
          "tp": 190,
          "fn": 210,
          "accuracy": 0.475
        }
      },
      "auroc": 0.7210416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 465,
          "fn": 335,
          "accuracy": 0.58125
        },
        "0.01": {
          "tp": 465,
          "fn": 335,
          "accuracy": 0.58125
        }
      },
      "auroc": 0.7741666666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        },
        "0.01": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        }
      },
      "auroc": 0.6585416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 319,
          "accuracy": 0.2025
        },
        "0.01": {
          "tp": 81,
          "fn": 319,
          "accuracy": 0.2025
        }
      },
      "auroc": 0.5847916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        }
      },
      "auroc": 0.6860416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5385416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 297,
          "accuracy": 0.2575
        },
        "0.01": {
          "tp": 103,
          "fn": 297,
          "accuracy": 0.2575
        }
      },
      "auroc": 0.6122916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 308,
          "accuracy": 0.23
        },
        "0.01": {
          "tp": 92,
          "fn": 308,
          "accuracy": 0.23
        }
      },
      "auroc": 0.5985416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 308,
          "accuracy": 0.23
        },
        "0.01": {
          "tp": 92,
          "fn": 308,
          "accuracy": 0.23
        }
      },
      "auroc": 0.5985416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 616,
          "accuracy": 0.23
        },
        "0.01": {
          "tp": 184,
          "fn": 616,
          "accuracy": 0.23
        }
      },
      "auroc": 0.5985416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5435416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        }
      },
      "auroc": 0.5610416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        },
        "0.01": {
          "tp": 55,
          "fn": 345,
          "accuracy": 0.1375
        }
      },
      "auroc": 0.5522916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        },
        "0.01": {
          "tp": 83,
          "fn": 117,
          "accuracy": 0.415
        }
      },
      "auroc": 0.6910416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        }
      },
      "auroc": 0.5085416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 307,
          "accuracy": 0.2325
        },
        "0.01": {
          "tp": 93,
          "fn": 307,
          "accuracy": 0.2325
        }
      },
      "auroc": 0.5997916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 293,
          "accuracy": 0.2675
        },
        "0.01": {
          "tp": 107,
          "fn": 293,
          "accuracy": 0.2675
        }
      },
      "auroc": 0.6172916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 41,
          "fn": 359,
          "accuracy": 0.1025
        },
        "0.01": {
          "tp": 41,
          "fn": 359,
          "accuracy": 0.1025
        }
      },
      "auroc": 0.5347916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 148,
          "fn": 652,
          "accuracy": 0.185
        },
        "0.01": {
          "tp": 148,
          "fn": 652,
          "accuracy": 0.185
        }
      },
      "auroc": 0.5760416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        },
        "0.01": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        }
      },
      "auroc": 0.8960416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        },
        "0.01": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        }
      },
      "auroc": 0.9210416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 340,
          "fn": 60,
          "accuracy": 0.85
        },
        "0.01": {
          "tp": 340,
          "fn": 60,
          "accuracy": 0.85
        }
      },
      "auroc": 0.9085416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 148,
          "fn": 52,
          "accuracy": 0.74
        },
        "0.01": {
          "tp": 148,
          "fn": 52,
          "accuracy": 0.74
        }
      },
      "auroc": 0.8535416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        }
      },
      "auroc": 0.7535416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 256,
          "fn": 144,
          "accuracy": 0.64
        },
        "0.01": {
          "tp": 256,
          "fn": 144,
          "accuracy": 0.64
        }
      },
      "auroc": 0.8035416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 313,
          "fn": 87,
          "accuracy": 0.7825
        },
        "0.01": {
          "tp": 313,
          "fn": 87,
          "accuracy": 0.7825
        }
      },
      "auroc": 0.8747916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 283,
          "fn": 117,
          "accuracy": 0.7075
        },
        "0.01": {
          "tp": 283,
          "fn": 117,
          "accuracy": 0.7075
        }
      },
      "auroc": 0.8372916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 596,
          "fn": 204,
          "accuracy": 0.745
        },
        "0.01": {
          "tp": 596,
          "fn": 204,
          "accuracy": 0.745
        }
      },
      "auroc": 0.8560416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        },
        "0.01": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        }
      },
      "auroc": 0.9285416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        },
        "0.01": {
          "tp": 178,
          "fn": 22,
          "accuracy": 0.89
        }
      },
      "auroc": 0.9285416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        },
        "0.01": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        }
      },
      "auroc": 0.9385416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        },
        "0.01": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        }
      },
      "auroc": 0.9385416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 360,
          "fn": 40,
          "accuracy": 0.9
        },
        "0.01": {
          "tp": 360,
          "fn": 40,
          "accuracy": 0.9
        }
      },
      "auroc": 0.9335416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 360,
          "fn": 40,
          "accuracy": 0.9
        },
        "0.01": {
          "tp": 360,
          "fn": 40,
          "accuracy": 0.9
        }
      },
      "auroc": 0.9335416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 99,
          "accuracy": 0.505
        },
        "0.01": {
          "tp": 101,
          "fn": 99,
          "accuracy": 0.505
        }
      },
      "auroc": 0.7360416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 99,
          "accuracy": 0.505
        },
        "0.01": {
          "tp": 101,
          "fn": 99,
          "accuracy": 0.505
        }
      },
      "auroc": 0.7360416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        }
      },
      "auroc": 0.7010416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        }
      },
      "auroc": 0.7010416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 188,
          "fn": 212,
          "accuracy": 0.47
        },
        "0.01": {
          "tp": 188,
          "fn": 212,
          "accuracy": 0.47
        }
      },
      "auroc": 0.7185416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 188,
          "fn": 212,
          "accuracy": 0.47
        },
        "0.01": {
          "tp": 188,
          "fn": 212,
          "accuracy": 0.47
        }
      },
      "auroc": 0.7185416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        },
        "0.01": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        }
      },
      "auroc": 0.7460416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        },
        "0.01": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        }
      },
      "auroc": 0.7460416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 102,
          "fn": 98,
          "accuracy": 0.51
        },
        "0.01": {
          "tp": 102,
          "fn": 98,
          "accuracy": 0.51
        }
      },
      "auroc": 0.7385416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 102,
          "fn": 98,
          "accuracy": 0.51
        },
        "0.01": {
          "tp": 102,
          "fn": 98,
          "accuracy": 0.51
        }
      },
      "auroc": 0.7385416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 207,
          "fn": 193,
          "accuracy": 0.5175
        },
        "0.01": {
          "tp": 207,
          "fn": 193,
          "accuracy": 0.5175
        }
      },
      "auroc": 0.7422916666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 207,
          "fn": 193,
          "accuracy": 0.5175
        },
        "0.01": {
          "tp": 207,
          "fn": 193,
          "accuracy": 0.5175
        }
      },
      "auroc": 0.7422916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 180,
          "fn": 20,
          "accuracy": 0.9
        },
        "0.01": {
          "tp": 180,
          "fn": 20,
          "accuracy": 0.9
        }
      },
      "auroc": 0.9335416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 180,
          "fn": 20,
          "accuracy": 0.9
        },
        "0.01": {
          "tp": 180,
          "fn": 20,
          "accuracy": 0.9
        }
      },
      "auroc": 0.9335416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        },
        "0.01": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        }
      },
      "auroc": 0.8960416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        },
        "0.01": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        }
      },
      "auroc": 0.8960416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 345,
          "fn": 55,
          "accuracy": 0.8625
        },
        "0.01": {
          "tp": 345,
          "fn": 55,
          "accuracy": 0.8625
        }
      },
      "auroc": 0.9147916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 345,
          "fn": 55,
          "accuracy": 0.8625
        },
        "0.01": {
          "tp": 345,
          "fn": 55,
          "accuracy": 0.8625
        }
      },
      "auroc": 0.9147916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        },
        "0.01": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        }
      },
      "auroc": 0.7785416666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        },
        "0.01": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        }
      },
      "auroc": 0.7785416666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7410416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7410416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 221,
          "fn": 179,
          "accuracy": 0.5525
        },
        "0.01": {
          "tp": 221,
          "fn": 179,
          "accuracy": 0.5525
        }
      },
      "auroc": 0.7597916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 221,
          "fn": 179,
          "accuracy": 0.5525
        },
        "0.01": {
          "tp": 221,
          "fn": 179,
          "accuracy": 0.5525
        }
      },
      "auroc": 0.7597916666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 1242,
          "fn": 958,
          "accuracy": 0.5645454545454546
        },
        "0.01": {
          "tp": 1242,
          "fn": 958,
          "accuracy": 0.5645454545454546
        }
      },
      "auroc": 0.7658143939393939
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 580,
          "fn": 620,
          "accuracy": 0.48333333333333334
        },
        "0.01": {
          "tp": 580,
          "fn": 620,
          "accuracy": 0.48333333333333334
        }
      },
      "auroc": 0.7252083333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 1822,
          "fn": 1578,
          "accuracy": 0.5358823529411765
        },
        "0.01": {
          "tp": 1822,
          "fn": 1578,
          "accuracy": 0.5358823529411765
        }
      },
      "auroc": 0.7514828431372549
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 1292,
          "fn": 908,
          "accuracy": 0.5872727272727273
        },
        "0.01": {
          "tp": 1292,
          "fn": 908,
          "accuracy": 0.5872727272727273
        }
      },
      "auroc": 0.7771780303030303
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 407,
          "fn": 793,
          "accuracy": 0.33916666666666667
        },
        "0.01": {
          "tp": 407,
          "fn": 793,
          "accuracy": 0.33916666666666667
        }
      },
      "auroc": 0.653125
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 1699,
          "fn": 1701,
          "accuracy": 0.49970588235294117
        },
        "0.01": {
          "tp": 1699,
          "fn": 1701,
          "accuracy": 0.49970588235294117
        }
      },
      "auroc": 0.7333946078431373
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 2534,
          "fn": 1866,
          "accuracy": 0.5759090909090909
        },
        "0.01": {
          "tp": 2534,
          "fn": 1866,
          "accuracy": 0.5759090909090909
        }
      },
      "auroc": 0.771496212121212
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 987,
          "fn": 1413,
          "accuracy": 0.41125
        },
        "0.01": {
          "tp": 987,
          "fn": 1413,
          "accuracy": 0.41125
        }
      },
      "auroc": 0.6891666666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": {
          "tp": 3521,
          "fn": 3279,
          "accuracy": 0.5177941176470588
        },
        "0.01": {
          "tp": 3521,
          "fn": 3279,
          "accuracy": 0.5177941176470588
        }
      },
      "auroc": 0.742438725490196
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 189,
          "fn": 11,
          "accuracy": 0.945
        },
        "0.01": {
          "tp": 189,
          "fn": 11,
          "accuracy": 0.945
        }
      },
      "auroc": 0.9560416666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 185,
          "fn": 15,
          "accuracy": 0.925
        },
        "0.01": {
          "tp": 185,
          "fn": 15,
          "accuracy": 0.925
        }
      },
      "auroc": 0.9460416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 374,
          "fn": 26,
          "accuracy": 0.935
        },
        "0.01": {
          "tp": 374,
          "fn": 26,
          "accuracy": 0.935
        }
      },
      "auroc": 0.9510416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        },
        "0.01": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        }
      },
      "auroc": 0.9435416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 162,
          "fn": 38,
          "accuracy": 0.81
        },
        "0.01": {
          "tp": 162,
          "fn": 38,
          "accuracy": 0.81
        }
      },
      "auroc": 0.8885416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 346,
          "fn": 54,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 346,
          "fn": 54,
          "accuracy": 0.865
        }
      },
      "auroc": 0.9160416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 373,
          "fn": 27,
          "accuracy": 0.9325
        },
        "0.01": {
          "tp": 373,
          "fn": 27,
          "accuracy": 0.9325
        }
      },
      "auroc": 0.9497916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 347,
          "fn": 53,
          "accuracy": 0.8675
        },
        "0.01": {
          "tp": 347,
          "fn": 53,
          "accuracy": 0.8675
        }
      },
      "auroc": 0.9172916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 720,
          "fn": 80,
          "accuracy": 0.9
        },
        "0.01": {
          "tp": 720,
          "fn": 80,
          "accuracy": 0.9
        }
      },
      "auroc": 0.9335416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        }
      },
      "auroc": 0.5085416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 363,
          "accuracy": 0.0925
        },
        "0.01": {
          "tp": 37,
          "fn": 363,
          "accuracy": 0.0925
        }
      },
      "auroc": 0.5297916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 19,
          "fn": 181,
          "accuracy": 0.095
        },
        "0.01": {
          "tp": 19,
          "fn": 181,
          "accuracy": 0.095
        }
      },
      "auroc": 0.5310416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 354,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 46,
          "fn": 354,
          "accuracy": 0.115
        }
      },
      "auroc": 0.5410416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 54,
          "fn": 346,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 54,
          "fn": 346,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 371,
          "accuracy": 0.0725
        },
        "0.01": {
          "tp": 29,
          "fn": 371,
          "accuracy": 0.0725
        }
      },
      "auroc": 0.5197916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 83,
          "fn": 717,
          "accuracy": 0.10375
        },
        "0.01": {
          "tp": 83,
          "fn": 717,
          "accuracy": 0.10375
        }
      },
      "auroc": 0.5354166666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 125,
          "fn": 75,
          "accuracy": 0.625
        },
        "0.01": {
          "tp": 125,
          "fn": 75,
          "accuracy": 0.625
        }
      },
      "auroc": 0.7960416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 99,
          "fn": 101,
          "accuracy": 0.495
        },
        "0.01": {
          "tp": 99,
          "fn": 101,
          "accuracy": 0.495
        }
      },
      "auroc": 0.7310416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 224,
          "fn": 176,
          "accuracy": 0.56
        },
        "0.01": {
          "tp": 224,
          "fn": 176,
          "accuracy": 0.56
        }
      },
      "auroc": 0.7635416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 125,
          "fn": 75,
          "accuracy": 0.625
        },
        "0.01": {
          "tp": 125,
          "fn": 75,
          "accuracy": 0.625
        }
      },
      "auroc": 0.7960416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        },
        "0.01": {
          "tp": 70,
          "fn": 130,
          "accuracy": 0.35
        }
      },
      "auroc": 0.6585416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 195,
          "fn": 205,
          "accuracy": 0.4875
        },
        "0.01": {
          "tp": 195,
          "fn": 205,
          "accuracy": 0.4875
        }
      },
      "auroc": 0.7272916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 250,
          "fn": 150,
          "accuracy": 0.625
        },
        "0.01": {
          "tp": 250,
          "fn": 150,
          "accuracy": 0.625
        }
      },
      "auroc": 0.7960416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 169,
          "fn": 231,
          "accuracy": 0.4225
        },
        "0.01": {
          "tp": 169,
          "fn": 231,
          "accuracy": 0.4225
        }
      },
      "auroc": 0.6947916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 419,
          "fn": 381,
          "accuracy": 0.52375
        },
        "0.01": {
          "tp": 419,
          "fn": 381,
          "accuracy": 0.52375
        }
      },
      "auroc": 0.7454166666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        }
      },
      "auroc": 0.5060416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        },
        "0.01": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        }
      },
      "auroc": 0.6435416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        },
        "0.01": {
          "tp": 73,
          "fn": 327,
          "accuracy": 0.1825
        }
      },
      "auroc": 0.5747916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        },
        "0.01": {
          "tp": 84,
          "fn": 116,
          "accuracy": 0.42
        }
      },
      "auroc": 0.6935416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5435416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        }
      },
      "auroc": 0.6185416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 307,
          "accuracy": 0.2325
        },
        "0.01": {
          "tp": 93,
          "fn": 307,
          "accuracy": 0.2325
        }
      },
      "auroc": 0.5997916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 312,
          "accuracy": 0.22
        },
        "0.01": {
          "tp": 88,
          "fn": 312,
          "accuracy": 0.22
        }
      },
      "auroc": 0.5935416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 181,
          "fn": 619,
          "accuracy": 0.22625
        },
        "0.01": {
          "tp": 181,
          "fn": 619,
          "accuracy": 0.22625
        }
      },
      "auroc": 0.5966666666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        },
        "0.01": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        }
      },
      "auroc": 0.5285416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        }
      },
      "auroc": 0.5560416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        },
        "0.01": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        }
      },
      "auroc": 0.5422916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        }
      },
      "auroc": 0.6835416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 312,
          "accuracy": 0.22
        },
        "0.01": {
          "tp": 88,
          "fn": 312,
          "accuracy": 0.22
        }
      },
      "auroc": 0.5935416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 302,
          "accuracy": 0.245
        },
        "0.01": {
          "tp": 98,
          "fn": 302,
          "accuracy": 0.245
        }
      },
      "auroc": 0.6060416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 363,
          "accuracy": 0.0925
        },
        "0.01": {
          "tp": 37,
          "fn": 363,
          "accuracy": 0.0925
        }
      },
      "auroc": 0.5297916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 135,
          "fn": 665,
          "accuracy": 0.16875
        },
        "0.01": {
          "tp": 135,
          "fn": 665,
          "accuracy": 0.16875
        }
      },
      "auroc": 0.5679166666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 50,
          "accuracy": 0.75
        },
        "0.01": {
          "tp": 150,
          "fn": 50,
          "accuracy": 0.75
        }
      },
      "auroc": 0.8585416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 163,
          "fn": 37,
          "accuracy": 0.815
        },
        "0.01": {
          "tp": 163,
          "fn": 37,
          "accuracy": 0.815
        }
      },
      "auroc": 0.8910416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 313,
          "fn": 87,
          "accuracy": 0.7825
        },
        "0.01": {
          "tp": 313,
          "fn": 87,
          "accuracy": 0.7825
        }
      },
      "auroc": 0.8747916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 137,
          "fn": 63,
          "accuracy": 0.685
        },
        "0.01": {
          "tp": 137,
          "fn": 63,
          "accuracy": 0.685
        }
      },
      "auroc": 0.8260416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        },
        "0.01": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        }
      },
      "auroc": 0.7610416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 248,
          "fn": 152,
          "accuracy": 0.62
        },
        "0.01": {
          "tp": 248,
          "fn": 152,
          "accuracy": 0.62
        }
      },
      "auroc": 0.7935416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 287,
          "fn": 113,
          "accuracy": 0.7175
        },
        "0.01": {
          "tp": 287,
          "fn": 113,
          "accuracy": 0.7175
        }
      },
      "auroc": 0.8422916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 274,
          "fn": 126,
          "accuracy": 0.685
        },
        "0.01": {
          "tp": 274,
          "fn": 126,
          "accuracy": 0.685
        }
      },
      "auroc": 0.8260416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 561,
          "fn": 239,
          "accuracy": 0.70125
        },
        "0.01": {
          "tp": 561,
          "fn": 239,
          "accuracy": 0.70125
        }
      },
      "auroc": 0.8341666666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        },
        "0.01": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        }
      },
      "auroc": 0.9060416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        },
        "0.01": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        }
      },
      "auroc": 0.9060416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        }
      },
      "auroc": 0.9160416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        }
      },
      "auroc": 0.9160416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 342,
          "fn": 58,
          "accuracy": 0.855
        },
        "0.01": {
          "tp": 342,
          "fn": 58,
          "accuracy": 0.855
        }
      },
      "auroc": 0.9110416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 342,
          "fn": 58,
          "accuracy": 0.855
        },
        "0.01": {
          "tp": 342,
          "fn": 58,
          "accuracy": 0.855
        }
      },
      "auroc": 0.9110416666666665
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        }
      },
      "auroc": 0.7135416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 92,
          "fn": 108,
          "accuracy": 0.46
        }
      },
      "auroc": 0.7135416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        },
        "0.01": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        }
      },
      "auroc": 0.7035416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        },
        "0.01": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        }
      },
      "auroc": 0.7035416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 180,
          "fn": 220,
          "accuracy": 0.45
        },
        "0.01": {
          "tp": 180,
          "fn": 220,
          "accuracy": 0.45
        }
      },
      "auroc": 0.7085416666666665
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 180,
          "fn": 220,
          "accuracy": 0.45
        },
        "0.01": {
          "tp": 180,
          "fn": 220,
          "accuracy": 0.45
        }
      },
      "auroc": 0.7085416666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        }
      },
      "auroc": 0.6835416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        }
      },
      "auroc": 0.6835416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.6985416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.6985416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 234,
          "accuracy": 0.415
        },
        "0.01": {
          "tp": 166,
          "fn": 234,
          "accuracy": 0.415
        }
      },
      "auroc": 0.6910416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 234,
          "accuracy": 0.415
        },
        "0.01": {
          "tp": 166,
          "fn": 234,
          "accuracy": 0.415
        }
      },
      "auroc": 0.6910416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        },
        "0.01": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        }
      },
      "auroc": 0.9210416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        },
        "0.01": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        }
      },
      "auroc": 0.9210416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        },
        "0.01": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        }
      },
      "auroc": 0.8985416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        },
        "0.01": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        }
      },
      "auroc": 0.8985416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 341,
          "fn": 59,
          "accuracy": 0.8525
        },
        "0.01": {
          "tp": 341,
          "fn": 59,
          "accuracy": 0.8525
        }
      },
      "auroc": 0.9097916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 341,
          "fn": 59,
          "accuracy": 0.8525
        },
        "0.01": {
          "tp": 341,
          "fn": 59,
          "accuracy": 0.8525
        }
      },
      "auroc": 0.9097916666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        }
      },
      "auroc": 0.7635416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        }
      },
      "auroc": 0.7635416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 99,
          "fn": 101,
          "accuracy": 0.495
        },
        "0.01": {
          "tp": 99,
          "fn": 101,
          "accuracy": 0.495
        }
      },
      "auroc": 0.7310416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 99,
          "fn": 101,
          "accuracy": 0.495
        },
        "0.01": {
          "tp": 99,
          "fn": 101,
          "accuracy": 0.495
        }
      },
      "auroc": 0.7310416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 211,
          "fn": 189,
          "accuracy": 0.5275
        },
        "0.01": {
          "tp": 211,
          "fn": 189,
          "accuracy": 0.5275
        }
      },
      "auroc": 0.7472916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 211,
          "fn": 189,
          "accuracy": 0.5275
        },
        "0.01": {
          "tp": 211,
          "fn": 189,
          "accuracy": 0.5275
        }
      },
      "auroc": 0.7472916666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 1146,
          "fn": 1054,
          "accuracy": 0.5209090909090909
        },
        "0.01": {
          "tp": 1146,
          "fn": 1054,
          "accuracy": 0.5209090909090909
        }
      },
      "auroc": 0.7439962121212121
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 550,
          "fn": 650,
          "accuracy": 0.4583333333333333
        },
        "0.01": {
          "tp": 550,
          "fn": 650,
          "accuracy": 0.4583333333333333
        }
      },
      "auroc": 0.7127083333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 1696,
          "fn": 1704,
          "accuracy": 0.4988235294117647
        },
        "0.01": {
          "tp": 1696,
          "fn": 1704,
          "accuracy": 0.4988235294117647
        }
      },
      "auroc": 0.732953431372549
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 1249,
          "fn": 951,
          "accuracy": 0.5677272727272727
        },
        "0.01": {
          "tp": 1249,
          "fn": 951,
          "accuracy": 0.5677272727272727
        }
      },
      "auroc": 0.7674053030303031
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 394,
          "fn": 806,
          "accuracy": 0.3283333333333333
        },
        "0.01": {
          "tp": 394,
          "fn": 806,
          "accuracy": 0.3283333333333333
        }
      },
      "auroc": 0.6477083333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 1643,
          "fn": 1757,
          "accuracy": 0.48323529411764704
        },
        "0.01": {
          "tp": 1643,
          "fn": 1757,
          "accuracy": 0.48323529411764704
        }
      },
      "auroc": 0.7251593137254901
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 2395,
          "fn": 2005,
          "accuracy": 0.5443181818181818
        },
        "0.01": {
          "tp": 2395,
          "fn": 2005,
          "accuracy": 0.5443181818181818
        }
      },
      "auroc": 0.7557007575757576
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 944,
          "fn": 1456,
          "accuracy": 0.3933333333333333
        },
        "0.01": {
          "tp": 944,
          "fn": 1456,
          "accuracy": 0.3933333333333333
        }
      },
      "auroc": 0.6802083333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": {
          "tp": 3339,
          "fn": 3461,
          "accuracy": 0.4910294117647059
        },
        "0.01": {
          "tp": 3339,
          "fn": 3461,
          "accuracy": 0.4910294117647059
        }
      },
      "auroc": 0.7290563725490196
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 194,
          "fn": 6,
          "accuracy": 0.97
        },
        "0.01": {
          "tp": 194,
          "fn": 6,
          "accuracy": 0.97
        }
      },
      "auroc": 0.9685416666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 188,
          "fn": 12,
          "accuracy": 0.94
        },
        "0.01": {
          "tp": 188,
          "fn": 12,
          "accuracy": 0.94
        }
      },
      "auroc": 0.9535416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 382,
          "fn": 18,
          "accuracy": 0.955
        },
        "0.01": {
          "tp": 382,
          "fn": 18,
          "accuracy": 0.955
        }
      },
      "auroc": 0.9610416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        },
        "0.01": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        }
      },
      "auroc": 0.9060416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 355,
          "fn": 45,
          "accuracy": 0.8875
        },
        "0.01": {
          "tp": 355,
          "fn": 45,
          "accuracy": 0.8875
        }
      },
      "auroc": 0.9272916666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 380,
          "fn": 20,
          "accuracy": 0.95
        },
        "0.01": {
          "tp": 380,
          "fn": 20,
          "accuracy": 0.95
        }
      },
      "auroc": 0.9585416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 357,
          "fn": 43,
          "accuracy": 0.8925
        },
        "0.01": {
          "tp": 357,
          "fn": 43,
          "accuracy": 0.8925
        }
      },
      "auroc": 0.9297916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 737,
          "fn": 63,
          "accuracy": 0.92125
        },
        "0.01": {
          "tp": 737,
          "fn": 63,
          "accuracy": 0.92125
        }
      },
      "auroc": 0.9441666666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        },
        "0.01": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        }
      },
      "auroc": 0.5585416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        }
      },
      "auroc": 0.5085416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        },
        "0.01": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        }
      },
      "auroc": 0.5335416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        }
      },
      "auroc": 0.5610416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        },
        "0.01": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        }
      },
      "auroc": 0.5335416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        },
        "0.01": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        }
      },
      "auroc": 0.5472916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 61,
          "fn": 339,
          "accuracy": 0.1525
        },
        "0.01": {
          "tp": 61,
          "fn": 339,
          "accuracy": 0.1525
        }
      },
      "auroc": 0.5597916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        }
      },
      "auroc": 0.5210416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 709,
          "accuracy": 0.11375
        },
        "0.01": {
          "tp": 91,
          "fn": 709,
          "accuracy": 0.11375
        }
      },
      "auroc": 0.5404166666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 50,
          "accuracy": 0.75
        },
        "0.01": {
          "tp": 150,
          "fn": 50,
          "accuracy": 0.75
        }
      },
      "auroc": 0.8585416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        },
        "0.01": {
          "tp": 112,
          "fn": 88,
          "accuracy": 0.56
        }
      },
      "auroc": 0.7635416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 262,
          "fn": 138,
          "accuracy": 0.655
        },
        "0.01": {
          "tp": 262,
          "fn": 138,
          "accuracy": 0.655
        }
      },
      "auroc": 0.8110416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 147,
          "fn": 53,
          "accuracy": 0.735
        },
        "0.01": {
          "tp": 147,
          "fn": 53,
          "accuracy": 0.735
        }
      },
      "auroc": 0.8510416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.6985416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 233,
          "fn": 167,
          "accuracy": 0.5825
        },
        "0.01": {
          "tp": 233,
          "fn": 167,
          "accuracy": 0.5825
        }
      },
      "auroc": 0.7747916666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 297,
          "fn": 103,
          "accuracy": 0.7425
        },
        "0.01": {
          "tp": 297,
          "fn": 103,
          "accuracy": 0.7425
        }
      },
      "auroc": 0.8547916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 198,
          "fn": 202,
          "accuracy": 0.495
        },
        "0.01": {
          "tp": 198,
          "fn": 202,
          "accuracy": 0.495
        }
      },
      "auroc": 0.7310416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 495,
          "fn": 305,
          "accuracy": 0.61875
        },
        "0.01": {
          "tp": 495,
          "fn": 305,
          "accuracy": 0.61875
        }
      },
      "auroc": 0.7929166666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        }
      },
      "auroc": 0.5060416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        }
      },
      "auroc": 0.6835416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 89,
          "fn": 311,
          "accuracy": 0.2225
        },
        "0.01": {
          "tp": 89,
          "fn": 311,
          "accuracy": 0.2225
        }
      },
      "auroc": 0.5947916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.6985416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 22,
          "fn": 178,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5385416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        },
        "0.01": {
          "tp": 108,
          "fn": 292,
          "accuracy": 0.27
        }
      },
      "auroc": 0.6185416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 95,
          "fn": 305,
          "accuracy": 0.2375
        },
        "0.01": {
          "tp": 95,
          "fn": 305,
          "accuracy": 0.2375
        }
      },
      "auroc": 0.6022916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 102,
          "fn": 298,
          "accuracy": 0.255
        },
        "0.01": {
          "tp": 102,
          "fn": 298,
          "accuracy": 0.255
        }
      },
      "auroc": 0.6110416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 197,
          "fn": 603,
          "accuracy": 0.24625
        },
        "0.01": {
          "tp": 197,
          "fn": 603,
          "accuracy": 0.24625
        }
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5435416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        }
      },
      "auroc": 0.5660416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 57,
          "fn": 343,
          "accuracy": 0.1425
        },
        "0.01": {
          "tp": 57,
          "fn": 343,
          "accuracy": 0.1425
        }
      },
      "auroc": 0.5547916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 86,
          "fn": 114,
          "accuracy": 0.43
        }
      },
      "auroc": 0.6985416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 97,
          "fn": 303,
          "accuracy": 0.2425
        },
        "0.01": {
          "tp": 97,
          "fn": 303,
          "accuracy": 0.2425
        }
      },
      "auroc": 0.6047916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 290,
          "accuracy": 0.275
        },
        "0.01": {
          "tp": 110,
          "fn": 290,
          "accuracy": 0.275
        }
      },
      "auroc": 0.6210416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5385416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 154,
          "fn": 646,
          "accuracy": 0.1925
        },
        "0.01": {
          "tp": 154,
          "fn": 646,
          "accuracy": 0.1925
        }
      },
      "auroc": 0.5797916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        },
        "0.01": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        }
      },
      "auroc": 0.9060416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        },
        "0.01": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        }
      },
      "auroc": 0.9410416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 352,
          "fn": 48,
          "accuracy": 0.88
        },
        "0.01": {
          "tp": 352,
          "fn": 48,
          "accuracy": 0.88
        }
      },
      "auroc": 0.9235416666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 44,
          "accuracy": 0.78
        },
        "0.01": {
          "tp": 156,
          "fn": 44,
          "accuracy": 0.78
        }
      },
      "auroc": 0.8735416666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        },
        "0.01": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        }
      },
      "auroc": 0.7785416666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 274,
          "fn": 126,
          "accuracy": 0.685
        },
        "0.01": {
          "tp": 274,
          "fn": 126,
          "accuracy": 0.685
        }
      },
      "auroc": 0.8260416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 325,
          "fn": 75,
          "accuracy": 0.8125
        },
        "0.01": {
          "tp": 325,
          "fn": 75,
          "accuracy": 0.8125
        }
      },
      "auroc": 0.8897916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        },
        "0.01": {
          "tp": 301,
          "fn": 99,
          "accuracy": 0.7525
        }
      },
      "auroc": 0.8597916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 626,
          "fn": 174,
          "accuracy": 0.7825
        },
        "0.01": {
          "tp": 626,
          "fn": 174,
          "accuracy": 0.7825
        }
      },
      "auroc": 0.8747916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        },
        "0.01": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        }
      },
      "auroc": 0.9385416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        },
        "0.01": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        }
      },
      "auroc": 0.9385416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 185,
          "fn": 15,
          "accuracy": 0.925
        },
        "0.01": {
          "tp": 185,
          "fn": 15,
          "accuracy": 0.925
        }
      },
      "auroc": 0.9460416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 185,
          "fn": 15,
          "accuracy": 0.925
        },
        "0.01": {
          "tp": 185,
          "fn": 15,
          "accuracy": 0.925
        }
      },
      "auroc": 0.9460416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 367,
          "fn": 33,
          "accuracy": 0.9175
        },
        "0.01": {
          "tp": 367,
          "fn": 33,
          "accuracy": 0.9175
        }
      },
      "auroc": 0.9422916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 367,
          "fn": 33,
          "accuracy": 0.9175
        },
        "0.01": {
          "tp": 367,
          "fn": 33,
          "accuracy": 0.9175
        }
      },
      "auroc": 0.9422916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        },
        "0.01": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        }
      },
      "auroc": 0.7460416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        },
        "0.01": {
          "tp": 105,
          "fn": 95,
          "accuracy": 0.525
        }
      },
      "auroc": 0.7460416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 97,
          "fn": 103,
          "accuracy": 0.485
        },
        "0.01": {
          "tp": 97,
          "fn": 103,
          "accuracy": 0.485
        }
      },
      "auroc": 0.7260416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 97,
          "fn": 103,
          "accuracy": 0.485
        },
        "0.01": {
          "tp": 97,
          "fn": 103,
          "accuracy": 0.485
        }
      },
      "auroc": 0.7260416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 202,
          "fn": 198,
          "accuracy": 0.505
        },
        "0.01": {
          "tp": 202,
          "fn": 198,
          "accuracy": 0.505
        }
      },
      "auroc": 0.7360416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 202,
          "fn": 198,
          "accuracy": 0.505
        },
        "0.01": {
          "tp": 202,
          "fn": 198,
          "accuracy": 0.505
        }
      },
      "auroc": 0.7360416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        },
        "0.01": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        }
      },
      "auroc": 0.7560416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        },
        "0.01": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        }
      },
      "auroc": 0.7560416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        },
        "0.01": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        }
      },
      "auroc": 0.7610416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        },
        "0.01": {
          "tp": 111,
          "fn": 89,
          "accuracy": 0.555
        }
      },
      "auroc": 0.7610416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 220,
          "fn": 180,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 220,
          "fn": 180,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 220,
          "fn": 180,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 220,
          "fn": 180,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        },
        "0.01": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        }
      },
      "auroc": 0.9435416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        },
        "0.01": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        }
      },
      "auroc": 0.9435416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        },
        "0.01": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        }
      },
      "auroc": 0.9210416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        },
        "0.01": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        }
      },
      "auroc": 0.9210416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 359,
          "fn": 41,
          "accuracy": 0.8975
        },
        "0.01": {
          "tp": 359,
          "fn": 41,
          "accuracy": 0.8975
        }
      },
      "auroc": 0.9322916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 359,
          "fn": 41,
          "accuracy": 0.8975
        },
        "0.01": {
          "tp": 359,
          "fn": 41,
          "accuracy": 0.8975
        }
      },
      "auroc": 0.9322916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        },
        "0.01": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        }
      },
      "auroc": 0.7935416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        },
        "0.01": {
          "tp": 124,
          "fn": 76,
          "accuracy": 0.62
        }
      },
      "auroc": 0.7935416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        },
        "0.01": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        }
      },
      "auroc": 0.7560416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        },
        "0.01": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        }
      },
      "auroc": 0.7560416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 233,
          "fn": 167,
          "accuracy": 0.5825
        },
        "0.01": {
          "tp": 233,
          "fn": 167,
          "accuracy": 0.5825
        }
      },
      "auroc": 0.7747916666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 233,
          "fn": 167,
          "accuracy": 0.5825
        },
        "0.01": {
          "tp": 233,
          "fn": 167,
          "accuracy": 0.5825
        }
      },
      "auroc": 0.7747916666666665
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1280,
          "fn": 920,
          "accuracy": 0.5818181818181818
        },
        "0.01": {
          "tp": 1280,
          "fn": 920,
          "accuracy": 0.5818181818181818
        }
      },
      "auroc": 0.7744507575757575
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 606,
          "fn": 594,
          "accuracy": 0.505
        },
        "0.01": {
          "tp": 606,
          "fn": 594,
          "accuracy": 0.505
        }
      },
      "auroc": 0.7360416666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1886,
          "fn": 1514,
          "accuracy": 0.5547058823529412
        },
        "0.01": {
          "tp": 1886,
          "fn": 1514,
          "accuracy": 0.5547058823529412
        }
      },
      "auroc": 0.7608946078431372
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1369,
          "fn": 831,
          "accuracy": 0.6222727272727273
        },
        "0.01": {
          "tp": 1369,
          "fn": 831,
          "accuracy": 0.6222727272727273
        }
      },
      "auroc": 0.7946780303030303
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 426,
          "fn": 774,
          "accuracy": 0.355
        },
        "0.01": {
          "tp": 426,
          "fn": 774,
          "accuracy": 0.355
        }
      },
      "auroc": 0.6610416666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1795,
          "fn": 1605,
          "accuracy": 0.5279411764705882
        },
        "0.01": {
          "tp": 1795,
          "fn": 1605,
          "accuracy": 0.5279411764705882
        }
      },
      "auroc": 0.7475122549019607
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 2649,
          "fn": 1751,
          "accuracy": 0.6020454545454546
        },
        "0.01": {
          "tp": 2649,
          "fn": 1751,
          "accuracy": 0.6020454545454546
        }
      },
      "auroc": 0.7845643939393938
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 1032,
          "fn": 1368,
          "accuracy": 0.43
        },
        "0.01": {
          "tp": 1032,
          "fn": 1368,
          "accuracy": 0.43
        }
      },
      "auroc": 0.6985416666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": {
          "tp": 3681,
          "fn": 3119,
          "accuracy": 0.5413235294117648
        },
        "0.01": {
          "tp": 3681,
          "fn": 3119,
          "accuracy": 0.5413235294117648
        }
      },
      "auroc": 0.754203431372549
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        }
      },
      "auroc": 0.5710416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        },
        "0.01": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        }
      },
      "auroc": 0.5260416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 52,
          "fn": 348,
          "accuracy": 0.13
        },
        "0.01": {
          "tp": 52,
          "fn": 348,
          "accuracy": 0.13
        }
      },
      "auroc": 0.5485416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 26,
          "fn": 174,
          "accuracy": 0.13
        },
        "0.01": {
          "tp": 26,
          "fn": 174,
          "accuracy": 0.13
        }
      },
      "auroc": 0.5485416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 53,
          "fn": 347,
          "accuracy": 0.1325
        },
        "0.01": {
          "tp": 53,
          "fn": 347,
          "accuracy": 0.1325
        }
      },
      "auroc": 0.5497916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 61,
          "fn": 339,
          "accuracy": 0.1525
        },
        "0.01": {
          "tp": 61,
          "fn": 339,
          "accuracy": 0.1525
        }
      },
      "auroc": 0.5597916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        },
        "0.01": {
          "tp": 44,
          "fn": 356,
          "accuracy": 0.11
        }
      },
      "auroc": 0.5385416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 695,
          "accuracy": 0.13125
        },
        "0.01": {
          "tp": 105,
          "fn": 695,
          "accuracy": 0.13125
        }
      },
      "auroc": 0.5491666666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        },
        "0.01": {
          "tp": 18,
          "fn": 182,
          "accuracy": 0.09
        }
      },
      "auroc": 0.5285416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        }
      },
      "auroc": 0.5610416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 351,
          "accuracy": 0.1225
        },
        "0.01": {
          "tp": 49,
          "fn": 351,
          "accuracy": 0.1225
        }
      },
      "auroc": 0.5447916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        },
        "0.01": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        }
      },
      "auroc": 0.5135416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        },
        "0.01": {
          "tp": 39,
          "fn": 161,
          "accuracy": 0.195
        }
      },
      "auroc": 0.5810416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        },
        "0.01": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        }
      },
      "auroc": 0.5472916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        }
      },
      "auroc": 0.5210416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 70,
          "fn": 330,
          "accuracy": 0.175
        }
      },
      "auroc": 0.5710416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 700,
          "accuracy": 0.125
        },
        "0.01": {
          "tp": 100,
          "fn": 700,
          "accuracy": 0.125
        }
      },
      "auroc": 0.5460416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 133,
          "fn": 67,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8160416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 121,
          "fn": 79,
          "accuracy": 0.605
        },
        "0.01": {
          "tp": 121,
          "fn": 79,
          "accuracy": 0.605
        }
      },
      "auroc": 0.7860416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 254,
          "fn": 146,
          "accuracy": 0.635
        },
        "0.01": {
          "tp": 254,
          "fn": 146,
          "accuracy": 0.635
        }
      },
      "auroc": 0.8010416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 126,
          "fn": 74,
          "accuracy": 0.63
        },
        "0.01": {
          "tp": 126,
          "fn": 74,
          "accuracy": 0.63
        }
      },
      "auroc": 0.7985416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 99,
          "fn": 101,
          "accuracy": 0.495
        },
        "0.01": {
          "tp": 99,
          "fn": 101,
          "accuracy": 0.495
        }
      },
      "auroc": 0.7310416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 225,
          "fn": 175,
          "accuracy": 0.5625
        },
        "0.01": {
          "tp": 225,
          "fn": 175,
          "accuracy": 0.5625
        }
      },
      "auroc": 0.7647916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        },
        "0.01": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        }
      },
      "auroc": 0.8072916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 220,
          "fn": 180,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 220,
          "fn": 180,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 479,
          "fn": 321,
          "accuracy": 0.59875
        },
        "0.01": {
          "tp": 479,
          "fn": 321,
          "accuracy": 0.59875
        }
      },
      "auroc": 0.7829166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 193,
          "accuracy": 0.035
        },
        "0.01": {
          "tp": 7,
          "fn": 193,
          "accuracy": 0.035
        }
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        }
      },
      "auroc": 0.5660416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        },
        "0.01": {
          "tp": 40,
          "fn": 360,
          "accuracy": 0.1
        }
      },
      "auroc": 0.5335416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        },
        "0.01": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        }
      },
      "auroc": 0.5185416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        },
        "0.01": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        }
      },
      "auroc": 0.5185416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 372,
          "accuracy": 0.07
        },
        "0.01": {
          "tp": 28,
          "fn": 372,
          "accuracy": 0.07
        }
      },
      "auroc": 0.5185416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 379,
          "accuracy": 0.0525
        },
        "0.01": {
          "tp": 21,
          "fn": 379,
          "accuracy": 0.0525
        }
      },
      "auroc": 0.5097916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        },
        "0.01": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        }
      },
      "auroc": 0.5422916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 68,
          "fn": 732,
          "accuracy": 0.085
        },
        "0.01": {
          "tp": 68,
          "fn": 732,
          "accuracy": 0.085
        }
      },
      "auroc": 0.5260416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        },
        "0.01": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        }
      },
      "auroc": 0.5260416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 375,
          "accuracy": 0.0625
        },
        "0.01": {
          "tp": 25,
          "fn": 375,
          "accuracy": 0.0625
        }
      },
      "auroc": 0.5147916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        }
      },
      "auroc": 0.5210416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        },
        "0.01": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        }
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 21,
          "fn": 379,
          "accuracy": 0.0525
        },
        "0.01": {
          "tp": 21,
          "fn": 379,
          "accuracy": 0.0525
        }
      },
      "auroc": 0.5097916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 368,
          "accuracy": 0.08
        },
        "0.01": {
          "tp": 32,
          "fn": 368,
          "accuracy": 0.08
        }
      },
      "auroc": 0.5235416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 386,
          "accuracy": 0.035
        },
        "0.01": {
          "tp": 14,
          "fn": 386,
          "accuracy": 0.035
        }
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 46,
          "fn": 754,
          "accuracy": 0.0575
        },
        "0.01": {
          "tp": 46,
          "fn": 754,
          "accuracy": 0.0575
        }
      },
      "auroc": 0.5122916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        }
      },
      "auroc": 0.6960416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 65,
          "fn": 135,
          "accuracy": 0.325
        },
        "0.01": {
          "tp": 65,
          "fn": 135,
          "accuracy": 0.325
        }
      },
      "auroc": 0.6460416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        },
        "0.01": {
          "tp": 150,
          "fn": 250,
          "accuracy": 0.375
        }
      },
      "auroc": 0.6710416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        },
        "0.01": {
          "tp": 64,
          "fn": 136,
          "accuracy": 0.32
        }
      },
      "auroc": 0.6435416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 153,
          "accuracy": 0.235
        },
        "0.01": {
          "tp": 47,
          "fn": 153,
          "accuracy": 0.235
        }
      },
      "auroc": 0.6010416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 289,
          "accuracy": 0.2775
        },
        "0.01": {
          "tp": 111,
          "fn": 289,
          "accuracy": 0.2775
        }
      },
      "auroc": 0.6222916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 149,
          "fn": 251,
          "accuracy": 0.3725
        },
        "0.01": {
          "tp": 149,
          "fn": 251,
          "accuracy": 0.3725
        }
      },
      "auroc": 0.6697916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 288,
          "accuracy": 0.28
        },
        "0.01": {
          "tp": 112,
          "fn": 288,
          "accuracy": 0.28
        }
      },
      "auroc": 0.6235416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 261,
          "fn": 539,
          "accuracy": 0.32625
        },
        "0.01": {
          "tp": 261,
          "fn": 539,
          "accuracy": 0.32625
        }
      },
      "auroc": 0.6466666666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        },
        "0.01": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        }
      },
      "auroc": 0.7760416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        },
        "0.01": {
          "tp": 117,
          "fn": 83,
          "accuracy": 0.585
        }
      },
      "auroc": 0.7760416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        },
        "0.01": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        }
      },
      "auroc": 0.7335416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        },
        "0.01": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        }
      },
      "auroc": 0.7335416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 217,
          "fn": 183,
          "accuracy": 0.5425
        },
        "0.01": {
          "tp": 217,
          "fn": 183,
          "accuracy": 0.5425
        }
      },
      "auroc": 0.7547916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 217,
          "fn": 183,
          "accuracy": 0.5425
        },
        "0.01": {
          "tp": 217,
          "fn": 183,
          "accuracy": 0.5425
        }
      },
      "auroc": 0.7547916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        }
      },
      "auroc": 0.5560416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        },
        "0.01": {
          "tp": 29,
          "fn": 171,
          "accuracy": 0.145
        }
      },
      "auroc": 0.5560416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5535416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5535416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        }
      },
      "auroc": 0.6485416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        },
        "0.01": {
          "tp": 66,
          "fn": 134,
          "accuracy": 0.33
        }
      },
      "auroc": 0.6485416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        }
      },
      "auroc": 0.6335416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        },
        "0.01": {
          "tp": 60,
          "fn": 140,
          "accuracy": 0.3
        }
      },
      "auroc": 0.6335416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 126,
          "fn": 274,
          "accuracy": 0.315
        },
        "0.01": {
          "tp": 126,
          "fn": 274,
          "accuracy": 0.315
        }
      },
      "auroc": 0.6410416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 126,
          "fn": 274,
          "accuracy": 0.315
        },
        "0.01": {
          "tp": 126,
          "fn": 274,
          "accuracy": 0.315
        }
      },
      "auroc": 0.6410416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        }
      },
      "auroc": 0.5660416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        }
      },
      "auroc": 0.5660416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        }
      },
      "auroc": 0.5610416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        }
      },
      "auroc": 0.5610416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        }
      },
      "auroc": 0.5635416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        }
      },
      "auroc": 0.5635416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 149,
          "accuracy": 0.255
        },
        "0.01": {
          "tp": 51,
          "fn": 149,
          "accuracy": 0.255
        }
      },
      "auroc": 0.6110416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 149,
          "accuracy": 0.255
        },
        "0.01": {
          "tp": 51,
          "fn": 149,
          "accuracy": 0.255
        }
      },
      "auroc": 0.6110416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        },
        "0.01": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        }
      },
      "auroc": 0.6310416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        },
        "0.01": {
          "tp": 59,
          "fn": 141,
          "accuracy": 0.295
        }
      },
      "auroc": 0.6310416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 290,
          "accuracy": 0.275
        },
        "0.01": {
          "tp": 110,
          "fn": 290,
          "accuracy": 0.275
        }
      },
      "auroc": 0.6210416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 290,
          "accuracy": 0.275
        },
        "0.01": {
          "tp": 110,
          "fn": 290,
          "accuracy": 0.275
        }
      },
      "auroc": 0.6210416666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 591,
          "fn": 1609,
          "accuracy": 0.2686363636363636
        },
        "0.01": {
          "tp": 591,
          "fn": 1609,
          "accuracy": 0.2686363636363636
        }
      },
      "auroc": 0.6178598484848484
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 275,
          "fn": 925,
          "accuracy": 0.22916666666666666
        },
        "0.01": {
          "tp": 275,
          "fn": 925,
          "accuracy": 0.22916666666666666
        }
      },
      "auroc": 0.598125
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 866,
          "fn": 2534,
          "accuracy": 0.25470588235294117
        },
        "0.01": {
          "tp": 866,
          "fn": 2534,
          "accuracy": 0.25470588235294117
        }
      },
      "auroc": 0.6108946078431372
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 534,
          "fn": 1666,
          "accuracy": 0.24272727272727274
        },
        "0.01": {
          "tp": 534,
          "fn": 1666,
          "accuracy": 0.24272727272727274
        }
      },
      "auroc": 0.604905303030303
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 232,
          "fn": 968,
          "accuracy": 0.19333333333333333
        },
        "0.01": {
          "tp": 232,
          "fn": 968,
          "accuracy": 0.19333333333333333
        }
      },
      "auroc": 0.5802083333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 766,
          "fn": 2634,
          "accuracy": 0.2252941176470588
        },
        "0.01": {
          "tp": 766,
          "fn": 2634,
          "accuracy": 0.2252941176470588
        }
      },
      "auroc": 0.5961887254901961
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 1125,
          "fn": 3275,
          "accuracy": 0.2556818181818182
        },
        "0.01": {
          "tp": 1125,
          "fn": 3275,
          "accuracy": 0.2556818181818182
        }
      },
      "auroc": 0.6113825757575756
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 507,
          "fn": 1893,
          "accuracy": 0.21125
        },
        "0.01": {
          "tp": 507,
          "fn": 1893,
          "accuracy": 0.21125
        }
      },
      "auroc": 0.5891666666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": {
          "tp": 1632,
          "fn": 5168,
          "accuracy": 0.24
        },
        "0.01": {
          "tp": 1632,
          "fn": 5168,
          "accuracy": 0.24
        }
      },
      "auroc": 0.6035416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 192,
          "fn": 8,
          "accuracy": 0.96
        },
        "0.01": {
          "tp": 192,
          "fn": 8,
          "accuracy": 0.96
        }
      },
      "auroc": 0.9635416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 191,
          "fn": 9,
          "accuracy": 0.955
        },
        "0.01": {
          "tp": 191,
          "fn": 9,
          "accuracy": 0.955
        }
      },
      "auroc": 0.9610416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 383,
          "fn": 17,
          "accuracy": 0.9575
        },
        "0.01": {
          "tp": 383,
          "fn": 17,
          "accuracy": 0.9575
        }
      },
      "auroc": 0.9622916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 172,
          "fn": 28,
          "accuracy": 0.86
        },
        "0.01": {
          "tp": 172,
          "fn": 28,
          "accuracy": 0.86
        }
      },
      "auroc": 0.9135416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 358,
          "fn": 42,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 358,
          "fn": 42,
          "accuracy": 0.895
        }
      },
      "auroc": 0.9310416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 378,
          "fn": 22,
          "accuracy": 0.945
        },
        "0.01": {
          "tp": 378,
          "fn": 22,
          "accuracy": 0.945
        }
      },
      "auroc": 0.9560416666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 363,
          "fn": 37,
          "accuracy": 0.9075
        },
        "0.01": {
          "tp": 363,
          "fn": 37,
          "accuracy": 0.9075
        }
      },
      "auroc": 0.9372916666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 741,
          "fn": 59,
          "accuracy": 0.92625
        },
        "0.01": {
          "tp": 741,
          "fn": 59,
          "accuracy": 0.92625
        }
      },
      "auroc": 0.9466666666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5535416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 39,
          "fn": 361,
          "accuracy": 0.0975
        },
        "0.01": {
          "tp": 39,
          "fn": 361,
          "accuracy": 0.0975
        }
      },
      "auroc": 0.5322916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        }
      },
      "auroc": 0.5610416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        },
        "0.01": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        }
      },
      "auroc": 0.5335416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        },
        "0.01": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        }
      },
      "auroc": 0.5472916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 59,
          "fn": 341,
          "accuracy": 0.1475
        },
        "0.01": {
          "tp": 59,
          "fn": 341,
          "accuracy": 0.1475
        }
      },
      "auroc": 0.5572916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        },
        "0.01": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        }
      },
      "auroc": 0.5222916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 710,
          "accuracy": 0.1125
        },
        "0.01": {
          "tp": 90,
          "fn": 710,
          "accuracy": 0.1125
        }
      },
      "auroc": 0.5397916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 155,
          "fn": 45,
          "accuracy": 0.775
        },
        "0.01": {
          "tp": 155,
          "fn": 45,
          "accuracy": 0.775
        }
      },
      "auroc": 0.8710416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.7910416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 278,
          "fn": 122,
          "accuracy": 0.695
        },
        "0.01": {
          "tp": 278,
          "fn": 122,
          "accuracy": 0.695
        }
      },
      "auroc": 0.8310416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 152,
          "fn": 48,
          "accuracy": 0.76
        },
        "0.01": {
          "tp": 152,
          "fn": 48,
          "accuracy": 0.76
        }
      },
      "auroc": 0.8635416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 95,
          "fn": 105,
          "accuracy": 0.475
        },
        "0.01": {
          "tp": 95,
          "fn": 105,
          "accuracy": 0.475
        }
      },
      "auroc": 0.7210416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 247,
          "fn": 153,
          "accuracy": 0.6175
        },
        "0.01": {
          "tp": 247,
          "fn": 153,
          "accuracy": 0.6175
        }
      },
      "auroc": 0.7922916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 307,
          "fn": 93,
          "accuracy": 0.7675
        },
        "0.01": {
          "tp": 307,
          "fn": 93,
          "accuracy": 0.7675
        }
      },
      "auroc": 0.8672916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 218,
          "fn": 182,
          "accuracy": 0.545
        },
        "0.01": {
          "tp": 218,
          "fn": 182,
          "accuracy": 0.545
        }
      },
      "auroc": 0.7560416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 525,
          "fn": 275,
          "accuracy": 0.65625
        },
        "0.01": {
          "tp": 525,
          "fn": 275,
          "accuracy": 0.65625
        }
      },
      "auroc": 0.8116666666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        }
      },
      "auroc": 0.5060416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        }
      },
      "auroc": 0.6885416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        },
        "0.01": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        }
      },
      "auroc": 0.5972916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        }
      },
      "auroc": 0.7010416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5435416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 289,
          "accuracy": 0.2775
        },
        "0.01": {
          "tp": 111,
          "fn": 289,
          "accuracy": 0.2775
        }
      },
      "auroc": 0.6222916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 96,
          "fn": 304,
          "accuracy": 0.24
        },
        "0.01": {
          "tp": 96,
          "fn": 304,
          "accuracy": 0.24
        }
      },
      "auroc": 0.6035416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 106,
          "fn": 294,
          "accuracy": 0.265
        },
        "0.01": {
          "tp": 106,
          "fn": 294,
          "accuracy": 0.265
        }
      },
      "auroc": 0.6160416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 202,
          "fn": 598,
          "accuracy": 0.2525
        },
        "0.01": {
          "tp": 202,
          "fn": 598,
          "accuracy": 0.2525
        }
      },
      "auroc": 0.6097916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 28,
          "fn": 172,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5535416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        }
      },
      "auroc": 0.5735416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 64,
          "fn": 336,
          "accuracy": 0.16
        }
      },
      "auroc": 0.5635416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        },
        "0.01": {
          "tp": 90,
          "fn": 110,
          "accuracy": 0.45
        }
      },
      "auroc": 0.7085416666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        },
        "0.01": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        }
      },
      "auroc": 0.6097916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 118,
          "fn": 282,
          "accuracy": 0.295
        },
        "0.01": {
          "tp": 118,
          "fn": 282,
          "accuracy": 0.295
        }
      },
      "auroc": 0.6310416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        },
        "0.01": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        }
      },
      "auroc": 0.5422916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 635,
          "accuracy": 0.20625
        },
        "0.01": {
          "tp": 165,
          "fn": 635,
          "accuracy": 0.20625
        }
      },
      "auroc": 0.5866666666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        },
        "0.01": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        }
      },
      "auroc": 0.9110416666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        },
        "0.01": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        }
      },
      "auroc": 0.9435416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 355,
          "fn": 45,
          "accuracy": 0.8875
        },
        "0.01": {
          "tp": 355,
          "fn": 45,
          "accuracy": 0.8875
        }
      },
      "auroc": 0.9272916666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 162,
          "fn": 38,
          "accuracy": 0.81
        },
        "0.01": {
          "tp": 162,
          "fn": 38,
          "accuracy": 0.81
        }
      },
      "auroc": 0.8885416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.7910416666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 285,
          "fn": 115,
          "accuracy": 0.7125
        },
        "0.01": {
          "tp": 285,
          "fn": 115,
          "accuracy": 0.7125
        }
      },
      "auroc": 0.8397916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 333,
          "fn": 67,
          "accuracy": 0.8325
        },
        "0.01": {
          "tp": 333,
          "fn": 67,
          "accuracy": 0.8325
        }
      },
      "auroc": 0.8997916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 307,
          "fn": 93,
          "accuracy": 0.7675
        },
        "0.01": {
          "tp": 307,
          "fn": 93,
          "accuracy": 0.7675
        }
      },
      "auroc": 0.8672916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 640,
          "fn": 160,
          "accuracy": 0.8
        },
        "0.01": {
          "tp": 640,
          "fn": 160,
          "accuracy": 0.8
        }
      },
      "auroc": 0.8835416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        },
        "0.01": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        }
      },
      "auroc": 0.9410416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        },
        "0.01": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        }
      },
      "auroc": 0.9410416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 189,
          "fn": 11,
          "accuracy": 0.945
        },
        "0.01": {
          "tp": 189,
          "fn": 11,
          "accuracy": 0.945
        }
      },
      "auroc": 0.9560416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 189,
          "fn": 11,
          "accuracy": 0.945
        },
        "0.01": {
          "tp": 189,
          "fn": 11,
          "accuracy": 0.945
        }
      },
      "auroc": 0.9560416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 372,
          "fn": 28,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 372,
          "fn": 28,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 372,
          "fn": 28,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 372,
          "fn": 28,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 99,
          "accuracy": 0.505
        },
        "0.01": {
          "tp": 101,
          "fn": 99,
          "accuracy": 0.505
        }
      },
      "auroc": 0.7360416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 99,
          "accuracy": 0.505
        },
        "0.01": {
          "tp": 101,
          "fn": 99,
          "accuracy": 0.505
        }
      },
      "auroc": 0.7360416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 211,
          "fn": 189,
          "accuracy": 0.5275
        },
        "0.01": {
          "tp": 211,
          "fn": 189,
          "accuracy": 0.5275
        }
      },
      "auroc": 0.7472916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 211,
          "fn": 189,
          "accuracy": 0.5275
        },
        "0.01": {
          "tp": 211,
          "fn": 189,
          "accuracy": 0.5275
        }
      },
      "auroc": 0.7472916666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        },
        "0.01": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        }
      },
      "auroc": 0.7810416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        },
        "0.01": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        }
      },
      "auroc": 0.7810416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        },
        "0.01": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        }
      },
      "auroc": 0.7885416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        },
        "0.01": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        }
      },
      "auroc": 0.7885416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 241,
          "fn": 159,
          "accuracy": 0.6025
        },
        "0.01": {
          "tp": 241,
          "fn": 159,
          "accuracy": 0.6025
        }
      },
      "auroc": 0.7847916666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 241,
          "fn": 159,
          "accuracy": 0.6025
        },
        "0.01": {
          "tp": 241,
          "fn": 159,
          "accuracy": 0.6025
        }
      },
      "auroc": 0.7847916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        },
        "0.01": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        }
      },
      "auroc": 0.9510416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        },
        "0.01": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        }
      },
      "auroc": 0.9510416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        }
      },
      "auroc": 0.9310416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        }
      },
      "auroc": 0.9310416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 366,
          "fn": 34,
          "accuracy": 0.915
        },
        "0.01": {
          "tp": 366,
          "fn": 34,
          "accuracy": 0.915
        }
      },
      "auroc": 0.9410416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 366,
          "fn": 34,
          "accuracy": 0.915
        },
        "0.01": {
          "tp": 366,
          "fn": 34,
          "accuracy": 0.915
        }
      },
      "auroc": 0.9410416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 127,
          "fn": 73,
          "accuracy": 0.635
        },
        "0.01": {
          "tp": 127,
          "fn": 73,
          "accuracy": 0.635
        }
      },
      "auroc": 0.8010416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 127,
          "fn": 73,
          "accuracy": 0.635
        },
        "0.01": {
          "tp": 127,
          "fn": 73,
          "accuracy": 0.635
        }
      },
      "auroc": 0.8010416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        }
      },
      "auroc": 0.7535416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        }
      },
      "auroc": 0.7535416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 235,
          "fn": 165,
          "accuracy": 0.5875
        },
        "0.01": {
          "tp": 235,
          "fn": 165,
          "accuracy": 0.5875
        }
      },
      "auroc": 0.7772916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 235,
          "fn": 165,
          "accuracy": 0.5875
        },
        "0.01": {
          "tp": 235,
          "fn": 165,
          "accuracy": 0.5875
        }
      },
      "auroc": 0.7772916666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1309,
          "fn": 891,
          "accuracy": 0.595
        },
        "0.01": {
          "tp": 1309,
          "fn": 891,
          "accuracy": 0.595
        }
      },
      "auroc": 0.7810416666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 627,
          "fn": 573,
          "accuracy": 0.5225
        },
        "0.01": {
          "tp": 627,
          "fn": 573,
          "accuracy": 0.5225
        }
      },
      "auroc": 0.7447916666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1936,
          "fn": 1464,
          "accuracy": 0.5694117647058824
        },
        "0.01": {
          "tp": 1936,
          "fn": 1464,
          "accuracy": 0.5694117647058824
        }
      },
      "auroc": 0.7682475490196078
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1407,
          "fn": 793,
          "accuracy": 0.6395454545454545
        },
        "0.01": {
          "tp": 1407,
          "fn": 793,
          "accuracy": 0.6395454545454545
        }
      },
      "auroc": 0.803314393939394
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 445,
          "fn": 755,
          "accuracy": 0.37083333333333335
        },
        "0.01": {
          "tp": 445,
          "fn": 755,
          "accuracy": 0.37083333333333335
        }
      },
      "auroc": 0.6689583333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1852,
          "fn": 1548,
          "accuracy": 0.5447058823529412
        },
        "0.01": {
          "tp": 1852,
          "fn": 1548,
          "accuracy": 0.5447058823529412
        }
      },
      "auroc": 0.7558946078431372
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 2716,
          "fn": 1684,
          "accuracy": 0.6172727272727273
        },
        "0.01": {
          "tp": 2716,
          "fn": 1684,
          "accuracy": 0.6172727272727273
        }
      },
      "auroc": 0.7921780303030302
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 1072,
          "fn": 1328,
          "accuracy": 0.44666666666666666
        },
        "0.01": {
          "tp": 1072,
          "fn": 1328,
          "accuracy": 0.44666666666666666
        }
      },
      "auroc": 0.706875
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": {
          "tp": 3788,
          "fn": 3012,
          "accuracy": 0.5570588235294117
        },
        "0.01": {
          "tp": 3788,
          "fn": 3012,
          "accuracy": 0.5570588235294117
        }
      },
      "auroc": 0.7620710784313726
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        },
        "0.01": {
          "tp": 175,
          "fn": 25,
          "accuracy": 0.875
        }
      },
      "auroc": 0.9210416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        },
        "0.01": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        }
      },
      "auroc": 0.9035416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 343,
          "fn": 57,
          "accuracy": 0.8575
        },
        "0.01": {
          "tp": 343,
          "fn": 57,
          "accuracy": 0.8575
        }
      },
      "auroc": 0.9122916666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        },
        "0.01": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        }
      },
      "auroc": 0.9035416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        },
        "0.01": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        }
      },
      "auroc": 0.8860416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        },
        "0.01": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        }
      },
      "auroc": 0.8947916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 343,
          "fn": 57,
          "accuracy": 0.8575
        },
        "0.01": {
          "tp": 343,
          "fn": 57,
          "accuracy": 0.8575
        }
      },
      "auroc": 0.9122916666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        },
        "0.01": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        }
      },
      "auroc": 0.8947916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 672,
          "fn": 128,
          "accuracy": 0.84
        },
        "0.01": {
          "tp": 672,
          "fn": 128,
          "accuracy": 0.84
        }
      },
      "auroc": 0.9035416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        },
        "0.01": {
          "tp": 35,
          "fn": 165,
          "accuracy": 0.175
        }
      },
      "auroc": 0.5710416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        },
        "0.01": {
          "tp": 32,
          "fn": 168,
          "accuracy": 0.16
        }
      },
      "auroc": 0.5635416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 67,
          "fn": 333,
          "accuracy": 0.1675
        },
        "0.01": {
          "tp": 67,
          "fn": 333,
          "accuracy": 0.1675
        }
      },
      "auroc": 0.5672916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 74,
          "fn": 126,
          "accuracy": 0.37
        },
        "0.01": {
          "tp": 74,
          "fn": 126,
          "accuracy": 0.37
        }
      },
      "auroc": 0.6685416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 26,
          "fn": 174,
          "accuracy": 0.13
        },
        "0.01": {
          "tp": 26,
          "fn": 174,
          "accuracy": 0.13
        }
      },
      "auroc": 0.5485416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 300,
          "accuracy": 0.25
        },
        "0.01": {
          "tp": 100,
          "fn": 300,
          "accuracy": 0.25
        }
      },
      "auroc": 0.6085416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 291,
          "accuracy": 0.2725
        },
        "0.01": {
          "tp": 109,
          "fn": 291,
          "accuracy": 0.2725
        }
      },
      "auroc": 0.6197916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 58,
          "fn": 342,
          "accuracy": 0.145
        },
        "0.01": {
          "tp": 58,
          "fn": 342,
          "accuracy": 0.145
        }
      },
      "auroc": 0.5560416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 167,
          "fn": 633,
          "accuracy": 0.20875
        },
        "0.01": {
          "tp": 167,
          "fn": 633,
          "accuracy": 0.20875
        }
      },
      "auroc": 0.5879166666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        },
        "0.01": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        }
      },
      "auroc": 0.9385416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        },
        "0.01": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        }
      },
      "auroc": 0.8985416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 348,
          "fn": 52,
          "accuracy": 0.87
        },
        "0.01": {
          "tp": 348,
          "fn": 52,
          "accuracy": 0.87
        }
      },
      "auroc": 0.9185416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        }
      },
      "auroc": 0.9160416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 154,
          "fn": 46,
          "accuracy": 0.77
        },
        "0.01": {
          "tp": 154,
          "fn": 46,
          "accuracy": 0.77
        }
      },
      "auroc": 0.8685416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 327,
          "fn": 73,
          "accuracy": 0.8175
        },
        "0.01": {
          "tp": 327,
          "fn": 73,
          "accuracy": 0.8175
        }
      },
      "auroc": 0.8922916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 355,
          "fn": 45,
          "accuracy": 0.8875
        },
        "0.01": {
          "tp": 355,
          "fn": 45,
          "accuracy": 0.8875
        }
      },
      "auroc": 0.9272916666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 320,
          "fn": 80,
          "accuracy": 0.8
        },
        "0.01": {
          "tp": 320,
          "fn": 80,
          "accuracy": 0.8
        }
      },
      "auroc": 0.8835416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 675,
          "fn": 125,
          "accuracy": 0.84375
        },
        "0.01": {
          "tp": 675,
          "fn": 125,
          "accuracy": 0.84375
        }
      },
      "auroc": 0.9054166666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        },
        "0.01": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        }
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.7910416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 129,
          "fn": 271,
          "accuracy": 0.3225
        },
        "0.01": {
          "tp": 129,
          "fn": 271,
          "accuracy": 0.3225
        }
      },
      "auroc": 0.6447916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        },
        "0.01": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        }
      },
      "auroc": 0.7335416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 61,
          "fn": 139,
          "accuracy": 0.305
        },
        "0.01": {
          "tp": 61,
          "fn": 139,
          "accuracy": 0.305
        }
      },
      "auroc": 0.6360416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 161,
          "fn": 239,
          "accuracy": 0.4025
        },
        "0.01": {
          "tp": 161,
          "fn": 239,
          "accuracy": 0.4025
        }
      },
      "auroc": 0.6847916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 106,
          "fn": 294,
          "accuracy": 0.265
        },
        "0.01": {
          "tp": 106,
          "fn": 294,
          "accuracy": 0.265
        }
      },
      "auroc": 0.6160416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        },
        "0.01": {
          "tp": 184,
          "fn": 216,
          "accuracy": 0.46
        }
      },
      "auroc": 0.7135416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 290,
          "fn": 510,
          "accuracy": 0.3625
        },
        "0.01": {
          "tp": 290,
          "fn": 510,
          "accuracy": 0.3625
        }
      },
      "auroc": 0.6647916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        },
        "0.01": {
          "tp": 43,
          "fn": 157,
          "accuracy": 0.215
        }
      },
      "auroc": 0.5910416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 87,
          "fn": 113,
          "accuracy": 0.435
        }
      },
      "auroc": 0.7010416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 270,
          "accuracy": 0.325
        },
        "0.01": {
          "tp": 130,
          "fn": 270,
          "accuracy": 0.325
        }
      },
      "auroc": 0.6460416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        },
        "0.01": {
          "tp": 82,
          "fn": 118,
          "accuracy": 0.41
        }
      },
      "auroc": 0.6885416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        },
        "0.01": {
          "tp": 33,
          "fn": 167,
          "accuracy": 0.165
        }
      },
      "auroc": 0.5660416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 115,
          "fn": 285,
          "accuracy": 0.2875
        },
        "0.01": {
          "tp": 115,
          "fn": 285,
          "accuracy": 0.2875
        }
      },
      "auroc": 0.6272916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 125,
          "fn": 275,
          "accuracy": 0.3125
        },
        "0.01": {
          "tp": 125,
          "fn": 275,
          "accuracy": 0.3125
        }
      },
      "auroc": 0.6397916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 120,
          "fn": 280,
          "accuracy": 0.3
        },
        "0.01": {
          "tp": 120,
          "fn": 280,
          "accuracy": 0.3
        }
      },
      "auroc": 0.6335416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 245,
          "fn": 555,
          "accuracy": 0.30625
        },
        "0.01": {
          "tp": 245,
          "fn": 555,
          "accuracy": 0.30625
        }
      },
      "auroc": 0.6366666666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 164,
          "fn": 36,
          "accuracy": 0.82
        },
        "0.01": {
          "tp": 164,
          "fn": 36,
          "accuracy": 0.82
        }
      },
      "auroc": 0.8935416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 159,
          "fn": 41,
          "accuracy": 0.795
        },
        "0.01": {
          "tp": 159,
          "fn": 41,
          "accuracy": 0.795
        }
      },
      "auroc": 0.8810416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 323,
          "fn": 77,
          "accuracy": 0.8075
        },
        "0.01": {
          "tp": 323,
          "fn": 77,
          "accuracy": 0.8075
        }
      },
      "auroc": 0.8872916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        },
        "0.01": {
          "tp": 165,
          "fn": 35,
          "accuracy": 0.825
        }
      },
      "auroc": 0.8960416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        },
        "0.01": {
          "tp": 145,
          "fn": 55,
          "accuracy": 0.725
        }
      },
      "auroc": 0.8460416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 310,
          "fn": 90,
          "accuracy": 0.775
        },
        "0.01": {
          "tp": 310,
          "fn": 90,
          "accuracy": 0.775
        }
      },
      "auroc": 0.8710416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        },
        "0.01": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        }
      },
      "auroc": 0.8947916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 304,
          "fn": 96,
          "accuracy": 0.76
        },
        "0.01": {
          "tp": 304,
          "fn": 96,
          "accuracy": 0.76
        }
      },
      "auroc": 0.8635416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 633,
          "fn": 167,
          "accuracy": 0.79125
        },
        "0.01": {
          "tp": 633,
          "fn": 167,
          "accuracy": 0.79125
        }
      },
      "auroc": 0.8791666666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        }
      },
      "auroc": 0.9160416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        }
      },
      "auroc": 0.9160416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        },
        "0.01": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        }
      },
      "auroc": 0.9235416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        },
        "0.01": {
          "tp": 176,
          "fn": 24,
          "accuracy": 0.88
        }
      },
      "auroc": 0.9235416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 349,
          "fn": 51,
          "accuracy": 0.8725
        },
        "0.01": {
          "tp": 349,
          "fn": 51,
          "accuracy": 0.8725
        }
      },
      "auroc": 0.9197916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 349,
          "fn": 51,
          "accuracy": 0.8725
        },
        "0.01": {
          "tp": 349,
          "fn": 51,
          "accuracy": 0.8725
        }
      },
      "auroc": 0.9197916666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        },
        "0.01": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        }
      },
      "auroc": 0.7560416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        },
        "0.01": {
          "tp": 109,
          "fn": 91,
          "accuracy": 0.545
        }
      },
      "auroc": 0.7560416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        }
      },
      "auroc": 0.7510416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        }
      },
      "auroc": 0.7510416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 216,
          "fn": 184,
          "accuracy": 0.54
        },
        "0.01": {
          "tp": 216,
          "fn": 184,
          "accuracy": 0.54
        }
      },
      "auroc": 0.7535416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 216,
          "fn": 184,
          "accuracy": 0.54
        },
        "0.01": {
          "tp": 216,
          "fn": 184,
          "accuracy": 0.54
        }
      },
      "auroc": 0.7535416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        },
        "0.01": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        }
      },
      "auroc": 0.9060416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        },
        "0.01": {
          "tp": 169,
          "fn": 31,
          "accuracy": 0.845
        }
      },
      "auroc": 0.9060416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        },
        "0.01": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        }
      },
      "auroc": 0.8985416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        },
        "0.01": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        }
      },
      "auroc": 0.8985416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 335,
          "fn": 65,
          "accuracy": 0.8375
        },
        "0.01": {
          "tp": 335,
          "fn": 65,
          "accuracy": 0.8375
        }
      },
      "auroc": 0.9022916666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 335,
          "fn": 65,
          "accuracy": 0.8375
        },
        "0.01": {
          "tp": 335,
          "fn": 65,
          "accuracy": 0.8375
        }
      },
      "auroc": 0.9022916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 163,
          "fn": 37,
          "accuracy": 0.815
        },
        "0.01": {
          "tp": 163,
          "fn": 37,
          "accuracy": 0.815
        }
      },
      "auroc": 0.8910416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 163,
          "fn": 37,
          "accuracy": 0.815
        },
        "0.01": {
          "tp": 163,
          "fn": 37,
          "accuracy": 0.815
        }
      },
      "auroc": 0.8910416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.7910416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.7910416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 286,
          "fn": 114,
          "accuracy": 0.715
        },
        "0.01": {
          "tp": 286,
          "fn": 114,
          "accuracy": 0.715
        }
      },
      "auroc": 0.8410416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 286,
          "fn": 114,
          "accuracy": 0.715
        },
        "0.01": {
          "tp": 286,
          "fn": 114,
          "accuracy": 0.715
        }
      },
      "auroc": 0.8410416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        },
        "0.01": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        }
      },
      "auroc": 0.8085416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        },
        "0.01": {
          "tp": 130,
          "fn": 70,
          "accuracy": 0.65
        }
      },
      "auroc": 0.8085416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 129,
          "fn": 71,
          "accuracy": 0.645
        },
        "0.01": {
          "tp": 129,
          "fn": 71,
          "accuracy": 0.645
        }
      },
      "auroc": 0.8060416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 129,
          "fn": 71,
          "accuracy": 0.645
        },
        "0.01": {
          "tp": 129,
          "fn": 71,
          "accuracy": 0.645
        }
      },
      "auroc": 0.8060416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        },
        "0.01": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        }
      },
      "auroc": 0.8072916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        },
        "0.01": {
          "tp": 259,
          "fn": 141,
          "accuracy": 0.6475
        }
      },
      "auroc": 0.8072916666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 1349,
          "fn": 851,
          "accuracy": 0.6131818181818182
        },
        "0.01": {
          "tp": 1349,
          "fn": 851,
          "accuracy": 0.6131818181818182
        }
      },
      "auroc": 0.7901325757575758
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 735,
          "fn": 465,
          "accuracy": 0.6125
        },
        "0.01": {
          "tp": 735,
          "fn": 465,
          "accuracy": 0.6125
        }
      },
      "auroc": 0.7897916666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 2084,
          "fn": 1316,
          "accuracy": 0.6129411764705882
        },
        "0.01": {
          "tp": 2084,
          "fn": 1316,
          "accuracy": 0.6129411764705882
        }
      },
      "auroc": 0.7900122549019607
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 1463,
          "fn": 737,
          "accuracy": 0.665
        },
        "0.01": {
          "tp": 1463,
          "fn": 737,
          "accuracy": 0.665
        }
      },
      "auroc": 0.8160416666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 580,
          "fn": 620,
          "accuracy": 0.48333333333333334
        },
        "0.01": {
          "tp": 580,
          "fn": 620,
          "accuracy": 0.48333333333333334
        }
      },
      "auroc": 0.7252083333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 2043,
          "fn": 1357,
          "accuracy": 0.6008823529411764
        },
        "0.01": {
          "tp": 2043,
          "fn": 1357,
          "accuracy": 0.6008823529411764
        }
      },
      "auroc": 0.7839828431372549
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 2812,
          "fn": 1588,
          "accuracy": 0.639090909090909
        },
        "0.01": {
          "tp": 2812,
          "fn": 1588,
          "accuracy": 0.639090909090909
        }
      },
      "auroc": 0.8030871212121212
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 1315,
          "fn": 1085,
          "accuracy": 0.5479166666666667
        },
        "0.01": {
          "tp": 1315,
          "fn": 1085,
          "accuracy": 0.5479166666666667
        }
      },
      "auroc": 0.7575
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": {
          "tp": 4127,
          "fn": 2673,
          "accuracy": 0.6069117647058824
        },
        "0.01": {
          "tp": 4127,
          "fn": 2673,
          "accuracy": 0.6069117647058824
        }
      },
      "auroc": 0.7869975490196078
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        }
      },
      "auroc": 0.5085416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        },
        "0.01": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        }
      },
      "auroc": 0.5185416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 376,
          "accuracy": 0.06
        },
        "0.01": {
          "tp": 24,
          "fn": 376,
          "accuracy": 0.06
        }
      },
      "auroc": 0.5135416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        },
        "0.01": {
          "tp": 12,
          "fn": 188,
          "accuracy": 0.06
        }
      },
      "auroc": 0.5135416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 20,
          "fn": 380,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 20,
          "fn": 380,
          "accuracy": 0.05
        }
      },
      "auroc": 0.5085416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 382,
          "accuracy": 0.045
        },
        "0.01": {
          "tp": 18,
          "fn": 382,
          "accuracy": 0.045
        }
      },
      "auroc": 0.5060416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 26,
          "fn": 374,
          "accuracy": 0.065
        },
        "0.01": {
          "tp": 26,
          "fn": 374,
          "accuracy": 0.065
        }
      },
      "auroc": 0.5160416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 44,
          "fn": 756,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 44,
          "fn": 756,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        },
        "0.01": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        }
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        },
        "0.01": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        }
      },
      "auroc": 0.4922916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        }
      },
      "auroc": 0.4960416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        },
        "0.01": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        }
      },
      "auroc": 0.4910416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 392,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 8,
          "fn": 392,
          "accuracy": 0.02
        }
      },
      "auroc": 0.49354166666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 389,
          "accuracy": 0.0275
        },
        "0.01": {
          "tp": 11,
          "fn": 389,
          "accuracy": 0.0275
        }
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 396,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 4,
          "fn": 396,
          "accuracy": 0.01
        }
      },
      "auroc": 0.48854166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 785,
          "accuracy": 0.01875
        },
        "0.01": {
          "tp": 15,
          "fn": 785,
          "accuracy": 0.01875
        }
      },
      "auroc": 0.49291666666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.4847916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.4847916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 799,
          "accuracy": 0.00125
        },
        "0.01": {
          "tp": 1,
          "fn": 799,
          "accuracy": 0.00125
        }
      },
      "auroc": 0.48416666666666663
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        },
        "0.01": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        }
      },
      "auroc": 0.4910416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.49354166666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        },
        "0.01": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        }
      },
      "auroc": 0.4922916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        },
        "0.01": {
          "tp": 14,
          "fn": 186,
          "accuracy": 0.07
        }
      },
      "auroc": 0.5185416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.48854166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 16,
          "fn": 384,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 16,
          "fn": 384,
          "accuracy": 0.04
        }
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 383,
          "accuracy": 0.0425
        },
        "0.01": {
          "tp": 17,
          "fn": 383,
          "accuracy": 0.0425
        }
      },
      "auroc": 0.5047916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 394,
          "accuracy": 0.015
        },
        "0.01": {
          "tp": 6,
          "fn": 394,
          "accuracy": 0.015
        }
      },
      "auroc": 0.4910416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 777,
          "accuracy": 0.02875
        },
        "0.01": {
          "tp": 23,
          "fn": 777,
          "accuracy": 0.02875
        }
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.48854166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        },
        "0.01": {
          "tp": 3,
          "fn": 397,
          "accuracy": 0.0075
        }
      },
      "auroc": 0.4872916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        }
      },
      "auroc": 0.5210416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 385,
          "accuracy": 0.0375
        },
        "0.01": {
          "tp": 15,
          "fn": 385,
          "accuracy": 0.0375
        }
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 16,
          "fn": 384,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 16,
          "fn": 384,
          "accuracy": 0.04
        }
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 782,
          "accuracy": 0.0225
        },
        "0.01": {
          "tp": 18,
          "fn": 782,
          "accuracy": 0.0225
        }
      },
      "auroc": 0.49479166666666663
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.49354166666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 4,
          "fn": 196,
          "accuracy": 0.02
        }
      },
      "auroc": 0.49354166666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 392,
          "accuracy": 0.02
        },
        "0.01": {
          "tp": 8,
          "fn": 392,
          "accuracy": 0.02
        }
      },
      "auroc": 0.49354166666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 193,
          "accuracy": 0.035
        },
        "0.01": {
          "tp": 7,
          "fn": 193,
          "accuracy": 0.035
        }
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        },
        "0.01": {
          "tp": 7,
          "fn": 393,
          "accuracy": 0.0175
        }
      },
      "auroc": 0.4922916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 389,
          "accuracy": 0.0275
        },
        "0.01": {
          "tp": 11,
          "fn": 389,
          "accuracy": 0.0275
        }
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 4,
          "fn": 396,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 4,
          "fn": 396,
          "accuracy": 0.01
        }
      },
      "auroc": 0.48854166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 785,
          "accuracy": 0.01875
        },
        "0.01": {
          "tp": 15,
          "fn": 785,
          "accuracy": 0.01875
        }
      },
      "auroc": 0.49291666666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        }
      },
      "auroc": 0.5210416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 15,
          "fn": 185,
          "accuracy": 0.075
        }
      },
      "auroc": 0.5210416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 42,
          "fn": 358,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 42,
          "fn": 358,
          "accuracy": 0.105
        }
      },
      "auroc": 0.5360416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 42,
          "fn": 358,
          "accuracy": 0.105
        },
        "0.01": {
          "tp": 42,
          "fn": 358,
          "accuracy": 0.105
        }
      },
      "auroc": 0.5360416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        }
      },
      "auroc": 0.4960416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        },
        "0.01": {
          "tp": 5,
          "fn": 195,
          "accuracy": 0.025
        }
      },
      "auroc": 0.4960416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 387,
          "accuracy": 0.0325
        },
        "0.01": {
          "tp": 13,
          "fn": 387,
          "accuracy": 0.0325
        }
      },
      "auroc": 0.49979166666666663
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 13,
          "fn": 387,
          "accuracy": 0.0325
        },
        "0.01": {
          "tp": 13,
          "fn": 387,
          "accuracy": 0.0325
        }
      },
      "auroc": 0.49979166666666663
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 2,
          "fn": 398,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.48854166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        },
        "0.01": {
          "tp": 2,
          "fn": 198,
          "accuracy": 0.01
        }
      },
      "auroc": 0.48854166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        },
        "0.01": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        }
      },
      "auroc": 0.4910416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        },
        "0.01": {
          "tp": 3,
          "fn": 197,
          "accuracy": 0.015
        }
      },
      "auroc": 0.4910416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 395,
          "accuracy": 0.0125
        },
        "0.01": {
          "tp": 5,
          "fn": 395,
          "accuracy": 0.0125
        }
      },
      "auroc": 0.4897916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 5,
          "fn": 395,
          "accuracy": 0.0125
        },
        "0.01": {
          "tp": 5,
          "fn": 395,
          "accuracy": 0.0125
        }
      },
      "auroc": 0.4897916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        },
        "0.01": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        }
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        },
        "0.01": {
          "tp": 6,
          "fn": 194,
          "accuracy": 0.03
        }
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        },
        "0.01": {
          "tp": 8,
          "fn": 192,
          "accuracy": 0.04
        }
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 386,
          "accuracy": 0.035
        },
        "0.01": {
          "tp": 14,
          "fn": 386,
          "accuracy": 0.035
        }
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 14,
          "fn": 386,
          "accuracy": 0.035
        },
        "0.01": {
          "tp": 14,
          "fn": 386,
          "accuracy": 0.035
        }
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 2144,
          "accuracy": 0.025454545454545455
        },
        "0.01": {
          "tp": 56,
          "fn": 2144,
          "accuracy": 0.025454545454545455
        }
      },
      "auroc": 0.49626893939393935
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 25,
          "fn": 1175,
          "accuracy": 0.020833333333333332
        },
        "0.01": {
          "tp": 25,
          "fn": 1175,
          "accuracy": 0.020833333333333332
        }
      },
      "auroc": 0.4939583333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 3319,
          "accuracy": 0.023823529411764705
        },
        "0.01": {
          "tp": 81,
          "fn": 3319,
          "accuracy": 0.023823529411764705
        }
      },
      "auroc": 0.49545343137254905
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 93,
          "fn": 2107,
          "accuracy": 0.042272727272727274
        },
        "0.01": {
          "tp": 93,
          "fn": 2107,
          "accuracy": 0.042272727272727274
        }
      },
      "auroc": 0.5046780303030303
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 18,
          "fn": 1182,
          "accuracy": 0.015
        },
        "0.01": {
          "tp": 18,
          "fn": 1182,
          "accuracy": 0.015
        }
      },
      "auroc": 0.4910416666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 111,
          "fn": 3289,
          "accuracy": 0.03264705882352941
        },
        "0.01": {
          "tp": 111,
          "fn": 3289,
          "accuracy": 0.03264705882352941
        }
      },
      "auroc": 0.4998651960784314
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 149,
          "fn": 4251,
          "accuracy": 0.03386363636363637
        },
        "0.01": {
          "tp": 149,
          "fn": 4251,
          "accuracy": 0.03386363636363637
        }
      },
      "auroc": 0.5004734848484849
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 43,
          "fn": 2357,
          "accuracy": 0.017916666666666668
        },
        "0.01": {
          "tp": 43,
          "fn": 2357,
          "accuracy": 0.017916666666666668
        }
      },
      "auroc": 0.49249999999999994
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": {
          "tp": 192,
          "fn": 6608,
          "accuracy": 0.02823529411764706
        },
        "0.01": {
          "tp": 192,
          "fn": 6608,
          "accuracy": 0.02823529411764706
        }
      },
      "auroc": 0.4976593137254902
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 191,
          "fn": 9,
          "accuracy": 0.955
        },
        "0.01": {
          "tp": 191,
          "fn": 9,
          "accuracy": 0.955
        }
      },
      "auroc": 0.9610416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 190,
          "fn": 10,
          "accuracy": 0.95
        },
        "0.01": {
          "tp": 190,
          "fn": 10,
          "accuracy": 0.95
        }
      },
      "auroc": 0.9585416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 381,
          "fn": 19,
          "accuracy": 0.9525
        },
        "0.01": {
          "tp": 381,
          "fn": 19,
          "accuracy": 0.9525
        }
      },
      "auroc": 0.9597916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        },
        "0.01": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        }
      },
      "auroc": 0.9510416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        },
        "0.01": {
          "tp": 171,
          "fn": 29,
          "accuracy": 0.855
        }
      },
      "auroc": 0.9110416666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 358,
          "fn": 42,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 358,
          "fn": 42,
          "accuracy": 0.895
        }
      },
      "auroc": 0.9310416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 378,
          "fn": 22,
          "accuracy": 0.945
        },
        "0.01": {
          "tp": 378,
          "fn": 22,
          "accuracy": 0.945
        }
      },
      "auroc": 0.9560416666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 361,
          "fn": 39,
          "accuracy": 0.9025
        },
        "0.01": {
          "tp": 361,
          "fn": 39,
          "accuracy": 0.9025
        }
      },
      "auroc": 0.9347916666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 739,
          "fn": 61,
          "accuracy": 0.92375
        },
        "0.01": {
          "tp": 739,
          "fn": 61,
          "accuracy": 0.92375
        }
      },
      "auroc": 0.9454166666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 38,
          "fn": 362,
          "accuracy": 0.095
        },
        "0.01": {
          "tp": 38,
          "fn": 362,
          "accuracy": 0.095
        }
      },
      "auroc": 0.5310416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        },
        "0.01": {
          "tp": 31,
          "fn": 169,
          "accuracy": 0.155
        }
      },
      "auroc": 0.5610416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        },
        "0.01": {
          "tp": 20,
          "fn": 180,
          "accuracy": 0.1
        }
      },
      "auroc": 0.5335416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        },
        "0.01": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        }
      },
      "auroc": 0.5472916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 58,
          "fn": 342,
          "accuracy": 0.145
        },
        "0.01": {
          "tp": 58,
          "fn": 342,
          "accuracy": 0.145
        }
      },
      "auroc": 0.5560416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        },
        "0.01": {
          "tp": 31,
          "fn": 369,
          "accuracy": 0.0775
        }
      },
      "auroc": 0.5222916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 89,
          "fn": 711,
          "accuracy": 0.11125
        },
        "0.01": {
          "tp": 89,
          "fn": 711,
          "accuracy": 0.11125
        }
      },
      "auroc": 0.5391666666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 151,
          "fn": 49,
          "accuracy": 0.755
        },
        "0.01": {
          "tp": 151,
          "fn": 49,
          "accuracy": 0.755
        }
      },
      "auroc": 0.8610416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        },
        "0.01": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        }
      },
      "auroc": 0.7785416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 269,
          "fn": 131,
          "accuracy": 0.6725
        },
        "0.01": {
          "tp": 269,
          "fn": 131,
          "accuracy": 0.6725
        }
      },
      "auroc": 0.8197916666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 137,
          "fn": 63,
          "accuracy": 0.685
        },
        "0.01": {
          "tp": 137,
          "fn": 63,
          "accuracy": 0.685
        }
      },
      "auroc": 0.8260416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        }
      },
      "auroc": 0.7110416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 228,
          "fn": 172,
          "accuracy": 0.57
        },
        "0.01": {
          "tp": 228,
          "fn": 172,
          "accuracy": 0.57
        }
      },
      "auroc": 0.7685416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 288,
          "fn": 112,
          "accuracy": 0.72
        },
        "0.01": {
          "tp": 288,
          "fn": 112,
          "accuracy": 0.72
        }
      },
      "auroc": 0.8435416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 209,
          "fn": 191,
          "accuracy": 0.5225
        },
        "0.01": {
          "tp": 209,
          "fn": 191,
          "accuracy": 0.5225
        }
      },
      "auroc": 0.7447916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 497,
          "fn": 303,
          "accuracy": 0.62125
        },
        "0.01": {
          "tp": 497,
          "fn": 303,
          "accuracy": 0.62125
        }
      },
      "auroc": 0.7941666666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        },
        "0.01": {
          "tp": 10,
          "fn": 190,
          "accuracy": 0.05
        }
      },
      "auroc": 0.5085416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        },
        "0.01": {
          "tp": 78,
          "fn": 122,
          "accuracy": 0.39
        }
      },
      "auroc": 0.6785416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 312,
          "accuracy": 0.22
        },
        "0.01": {
          "tp": 88,
          "fn": 312,
          "accuracy": 0.22
        }
      },
      "auroc": 0.5935416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        }
      },
      "auroc": 0.6860416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        },
        "0.01": {
          "tp": 23,
          "fn": 177,
          "accuracy": 0.115
        }
      },
      "auroc": 0.5410416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 104,
          "fn": 296,
          "accuracy": 0.26
        },
        "0.01": {
          "tp": 104,
          "fn": 296,
          "accuracy": 0.26
        }
      },
      "auroc": 0.6135416666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        },
        "0.01": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        }
      },
      "auroc": 0.5972916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        },
        "0.01": {
          "tp": 101,
          "fn": 299,
          "accuracy": 0.2525
        }
      },
      "auroc": 0.6097916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 192,
          "fn": 608,
          "accuracy": 0.24
        },
        "0.01": {
          "tp": 192,
          "fn": 608,
          "accuracy": 0.24
        }
      },
      "auroc": 0.6035416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        },
        "0.01": {
          "tp": 17,
          "fn": 183,
          "accuracy": 0.085
        }
      },
      "auroc": 0.5260416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        },
        "0.01": {
          "tp": 34,
          "fn": 166,
          "accuracy": 0.17
        }
      },
      "auroc": 0.5685416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        },
        "0.01": {
          "tp": 51,
          "fn": 349,
          "accuracy": 0.1275
        }
      },
      "auroc": 0.5472916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        },
        "0.01": {
          "tp": 80,
          "fn": 120,
          "accuracy": 0.4
        }
      },
      "auroc": 0.6835416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        },
        "0.01": {
          "tp": 91,
          "fn": 309,
          "accuracy": 0.2275
        }
      },
      "auroc": 0.5972916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 97,
          "fn": 303,
          "accuracy": 0.2425
        },
        "0.01": {
          "tp": 97,
          "fn": 303,
          "accuracy": 0.2425
        }
      },
      "auroc": 0.6047916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 45,
          "fn": 355,
          "accuracy": 0.1125
        },
        "0.01": {
          "tp": 45,
          "fn": 355,
          "accuracy": 0.1125
        }
      },
      "auroc": 0.5397916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 142,
          "fn": 658,
          "accuracy": 0.1775
        },
        "0.01": {
          "tp": 142,
          "fn": 658,
          "accuracy": 0.1775
        }
      },
      "auroc": 0.5722916666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        },
        "0.01": {
          "tp": 166,
          "fn": 34,
          "accuracy": 0.83
        }
      },
      "auroc": 0.8985416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        },
        "0.01": {
          "tp": 182,
          "fn": 18,
          "accuracy": 0.91
        }
      },
      "auroc": 0.9385416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 348,
          "fn": 52,
          "accuracy": 0.87
        },
        "0.01": {
          "tp": 348,
          "fn": 52,
          "accuracy": 0.87
        }
      },
      "auroc": 0.9185416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 148,
          "fn": 52,
          "accuracy": 0.74
        },
        "0.01": {
          "tp": 148,
          "fn": 52,
          "accuracy": 0.74
        }
      },
      "auroc": 0.8535416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 121,
          "fn": 79,
          "accuracy": 0.605
        },
        "0.01": {
          "tp": 121,
          "fn": 79,
          "accuracy": 0.605
        }
      },
      "auroc": 0.7860416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 269,
          "fn": 131,
          "accuracy": 0.6725
        },
        "0.01": {
          "tp": 269,
          "fn": 131,
          "accuracy": 0.6725
        }
      },
      "auroc": 0.8197916666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        },
        "0.01": {
          "tp": 314,
          "fn": 86,
          "accuracy": 0.785
        }
      },
      "auroc": 0.8760416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 303,
          "fn": 97,
          "accuracy": 0.7575
        },
        "0.01": {
          "tp": 303,
          "fn": 97,
          "accuracy": 0.7575
        }
      },
      "auroc": 0.8622916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 617,
          "fn": 183,
          "accuracy": 0.77125
        },
        "0.01": {
          "tp": 617,
          "fn": 183,
          "accuracy": 0.77125
        }
      },
      "auroc": 0.8691666666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        }
      },
      "auroc": 0.9310416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        },
        "0.01": {
          "tp": 179,
          "fn": 21,
          "accuracy": 0.895
        }
      },
      "auroc": 0.9310416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 365,
          "fn": 35,
          "accuracy": 0.9125
        },
        "0.01": {
          "tp": 365,
          "fn": 35,
          "accuracy": 0.9125
        }
      },
      "auroc": 0.9397916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 365,
          "fn": 35,
          "accuracy": 0.9125
        },
        "0.01": {
          "tp": 365,
          "fn": 35,
          "accuracy": 0.9125
        }
      },
      "auroc": 0.9397916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7410416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7410416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        },
        "0.01": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        }
      },
      "auroc": 0.7285416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        },
        "0.01": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        }
      },
      "auroc": 0.7285416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 201,
          "fn": 199,
          "accuracy": 0.5025
        },
        "0.01": {
          "tp": 201,
          "fn": 199,
          "accuracy": 0.5025
        }
      },
      "auroc": 0.7347916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 201,
          "fn": 199,
          "accuracy": 0.5025
        },
        "0.01": {
          "tp": 201,
          "fn": 199,
          "accuracy": 0.5025
        }
      },
      "auroc": 0.7347916666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        },
        "0.01": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        }
      },
      "auroc": 0.7335416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        },
        "0.01": {
          "tp": 100,
          "fn": 100,
          "accuracy": 0.5
        }
      },
      "auroc": 0.7335416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        }
      },
      "auroc": 0.7510416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        },
        "0.01": {
          "tp": 107,
          "fn": 93,
          "accuracy": 0.535
        }
      },
      "auroc": 0.7510416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 207,
          "fn": 193,
          "accuracy": 0.5175
        },
        "0.01": {
          "tp": 207,
          "fn": 193,
          "accuracy": 0.5175
        }
      },
      "auroc": 0.7422916666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 207,
          "fn": 193,
          "accuracy": 0.5175
        },
        "0.01": {
          "tp": 207,
          "fn": 193,
          "accuracy": 0.5175
        }
      },
      "auroc": 0.7422916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 181,
          "fn": 19,
          "accuracy": 0.905
        },
        "0.01": {
          "tp": 181,
          "fn": 19,
          "accuracy": 0.905
        }
      },
      "auroc": 0.9360416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 181,
          "fn": 19,
          "accuracy": 0.905
        },
        "0.01": {
          "tp": 181,
          "fn": 19,
          "accuracy": 0.905
        }
      },
      "auroc": 0.9360416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        }
      },
      "auroc": 0.9160416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        },
        "0.01": {
          "tp": 173,
          "fn": 27,
          "accuracy": 0.865
        }
      },
      "auroc": 0.9160416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 354,
          "fn": 46,
          "accuracy": 0.885
        },
        "0.01": {
          "tp": 354,
          "fn": 46,
          "accuracy": 0.885
        }
      },
      "auroc": 0.9260416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 354,
          "fn": 46,
          "accuracy": 0.885
        },
        "0.01": {
          "tp": 354,
          "fn": 46,
          "accuracy": 0.885
        }
      },
      "auroc": 0.9260416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 114,
          "fn": 86,
          "accuracy": 0.57
        },
        "0.01": {
          "tp": 114,
          "fn": 86,
          "accuracy": 0.57
        }
      },
      "auroc": 0.7685416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 114,
          "fn": 86,
          "accuracy": 0.57
        },
        "0.01": {
          "tp": 114,
          "fn": 86,
          "accuracy": 0.57
        }
      },
      "auroc": 0.7685416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7410416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 103,
          "fn": 97,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7410416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 217,
          "fn": 183,
          "accuracy": 0.5425
        },
        "0.01": {
          "tp": 217,
          "fn": 183,
          "accuracy": 0.5425
        }
      },
      "auroc": 0.7547916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 217,
          "fn": 183,
          "accuracy": 0.5425
        },
        "0.01": {
          "tp": 217,
          "fn": 183,
          "accuracy": 0.5425
        }
      },
      "auroc": 0.7547916666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1239,
          "fn": 961,
          "accuracy": 0.5631818181818182
        },
        "0.01": {
          "tp": 1239,
          "fn": 961,
          "accuracy": 0.5631818181818182
        }
      },
      "auroc": 0.7651325757575758
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 613,
          "fn": 587,
          "accuracy": 0.5108333333333334
        },
        "0.01": {
          "tp": 613,
          "fn": 587,
          "accuracy": 0.5108333333333334
        }
      },
      "auroc": 0.7389583333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1852,
          "fn": 1548,
          "accuracy": 0.5447058823529412
        },
        "0.01": {
          "tp": 1852,
          "fn": 1548,
          "accuracy": 0.5447058823529412
        }
      },
      "auroc": 0.7558946078431372
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1331,
          "fn": 869,
          "accuracy": 0.605
        },
        "0.01": {
          "tp": 1331,
          "fn": 869,
          "accuracy": 0.605
        }
      },
      "auroc": 0.7860416666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 437,
          "fn": 763,
          "accuracy": 0.3641666666666667
        },
        "0.01": {
          "tp": 437,
          "fn": 763,
          "accuracy": 0.3641666666666667
        }
      },
      "auroc": 0.665625
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1768,
          "fn": 1632,
          "accuracy": 0.52
        },
        "0.01": {
          "tp": 1768,
          "fn": 1632,
          "accuracy": 0.52
        }
      },
      "auroc": 0.7435416666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 2570,
          "fn": 1830,
          "accuracy": 0.5840909090909091
        },
        "0.01": {
          "tp": 2570,
          "fn": 1830,
          "accuracy": 0.5840909090909091
        }
      },
      "auroc": 0.7755871212121211
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 1050,
          "fn": 1350,
          "accuracy": 0.4375
        },
        "0.01": {
          "tp": 1050,
          "fn": 1350,
          "accuracy": 0.4375
        }
      },
      "auroc": 0.7022916666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": {
          "tp": 3620,
          "fn": 3180,
          "accuracy": 0.5323529411764706
        },
        "0.01": {
          "tp": 3620,
          "fn": 3180,
          "accuracy": 0.5323529411764706
        }
      },
      "auroc": 0.7497181372549019
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 192,
          "fn": 8,
          "accuracy": 0.96
        },
        "0.01": {
          "tp": 192,
          "fn": 8,
          "accuracy": 0.96
        }
      },
      "auroc": 0.9635416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 190,
          "fn": 10,
          "accuracy": 0.95
        },
        "0.01": {
          "tp": 190,
          "fn": 10,
          "accuracy": 0.95
        }
      },
      "auroc": 0.9585416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 382,
          "fn": 18,
          "accuracy": 0.955
        },
        "0.01": {
          "tp": 382,
          "fn": 18,
          "accuracy": 0.955
        }
      },
      "auroc": 0.9610416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        },
        "0.01": {
          "tp": 184,
          "fn": 16,
          "accuracy": 0.92
        }
      },
      "auroc": 0.9435416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        },
        "0.01": {
          "tp": 170,
          "fn": 30,
          "accuracy": 0.85
        }
      },
      "auroc": 0.9085416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 354,
          "fn": 46,
          "accuracy": 0.885
        },
        "0.01": {
          "tp": 354,
          "fn": 46,
          "accuracy": 0.885
        }
      },
      "auroc": 0.9260416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 376,
          "fn": 24,
          "accuracy": 0.94
        },
        "0.01": {
          "tp": 376,
          "fn": 24,
          "accuracy": 0.94
        }
      },
      "auroc": 0.9535416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 360,
          "fn": 40,
          "accuracy": 0.9
        },
        "0.01": {
          "tp": 360,
          "fn": 40,
          "accuracy": 0.9
        }
      },
      "auroc": 0.9335416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 736,
          "fn": 64,
          "accuracy": 0.92
        },
        "0.01": {
          "tp": 736,
          "fn": 64,
          "accuracy": 0.92
        }
      },
      "auroc": 0.9435416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 26,
          "fn": 174,
          "accuracy": 0.13
        },
        "0.01": {
          "tp": 26,
          "fn": 174,
          "accuracy": 0.13
        }
      },
      "auroc": 0.5485416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 37,
          "fn": 363,
          "accuracy": 0.0925
        },
        "0.01": {
          "tp": 37,
          "fn": 363,
          "accuracy": 0.0925
        }
      },
      "auroc": 0.5297916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        },
        "0.01": {
          "tp": 30,
          "fn": 170,
          "accuracy": 0.15
        }
      },
      "auroc": 0.5585416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 19,
          "fn": 181,
          "accuracy": 0.095
        },
        "0.01": {
          "tp": 19,
          "fn": 181,
          "accuracy": 0.095
        }
      },
      "auroc": 0.5310416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 49,
          "fn": 351,
          "accuracy": 0.1225
        },
        "0.01": {
          "tp": 49,
          "fn": 351,
          "accuracy": 0.1225
        }
      },
      "auroc": 0.5447916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        },
        "0.01": {
          "tp": 56,
          "fn": 344,
          "accuracy": 0.14
        }
      },
      "auroc": 0.5535416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        },
        "0.01": {
          "tp": 30,
          "fn": 370,
          "accuracy": 0.075
        }
      },
      "auroc": 0.5210416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 86,
          "fn": 714,
          "accuracy": 0.1075
        },
        "0.01": {
          "tp": 86,
          "fn": 714,
          "accuracy": 0.1075
        }
      },
      "auroc": 0.5372916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 156,
          "fn": 44,
          "accuracy": 0.78
        },
        "0.01": {
          "tp": 156,
          "fn": 44,
          "accuracy": 0.78
        }
      },
      "auroc": 0.8735416666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 121,
          "fn": 79,
          "accuracy": 0.605
        },
        "0.01": {
          "tp": 121,
          "fn": 79,
          "accuracy": 0.605
        }
      },
      "auroc": 0.7860416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 277,
          "fn": 123,
          "accuracy": 0.6925
        },
        "0.01": {
          "tp": 277,
          "fn": 123,
          "accuracy": 0.6925
        }
      },
      "auroc": 0.8297916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 148,
          "fn": 52,
          "accuracy": 0.74
        },
        "0.01": {
          "tp": 148,
          "fn": 52,
          "accuracy": 0.74
        }
      },
      "auroc": 0.8535416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        },
        "0.01": {
          "tp": 91,
          "fn": 109,
          "accuracy": 0.455
        }
      },
      "auroc": 0.7110416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 239,
          "fn": 161,
          "accuracy": 0.5975
        },
        "0.01": {
          "tp": 239,
          "fn": 161,
          "accuracy": 0.5975
        }
      },
      "auroc": 0.7822916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 304,
          "fn": 96,
          "accuracy": 0.76
        },
        "0.01": {
          "tp": 304,
          "fn": 96,
          "accuracy": 0.76
        }
      },
      "auroc": 0.8635416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 212,
          "fn": 188,
          "accuracy": 0.53
        },
        "0.01": {
          "tp": 212,
          "fn": 188,
          "accuracy": 0.53
        }
      },
      "auroc": 0.7485416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 516,
          "fn": 284,
          "accuracy": 0.645
        },
        "0.01": {
          "tp": 516,
          "fn": 284,
          "accuracy": 0.645
        }
      },
      "auroc": 0.8060416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        },
        "0.01": {
          "tp": 9,
          "fn": 191,
          "accuracy": 0.045
        }
      },
      "auroc": 0.5060416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        },
        "0.01": {
          "tp": 81,
          "fn": 119,
          "accuracy": 0.405
        }
      },
      "auroc": 0.6860416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 90,
          "fn": 310,
          "accuracy": 0.225
        },
        "0.01": {
          "tp": 90,
          "fn": 310,
          "accuracy": 0.225
        }
      },
      "auroc": 0.5960416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        },
        "0.01": {
          "tp": 88,
          "fn": 112,
          "accuracy": 0.44
        }
      },
      "auroc": 0.7035416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        },
        "0.01": {
          "tp": 24,
          "fn": 176,
          "accuracy": 0.12
        }
      },
      "auroc": 0.5435416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 288,
          "accuracy": 0.28
        },
        "0.01": {
          "tp": 112,
          "fn": 288,
          "accuracy": 0.28
        }
      },
      "auroc": 0.6235416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 97,
          "fn": 303,
          "accuracy": 0.2425
        },
        "0.01": {
          "tp": 97,
          "fn": 303,
          "accuracy": 0.2425
        }
      },
      "auroc": 0.6047916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 105,
          "fn": 295,
          "accuracy": 0.2625
        },
        "0.01": {
          "tp": 105,
          "fn": 295,
          "accuracy": 0.2625
        }
      },
      "auroc": 0.6147916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 202,
          "fn": 598,
          "accuracy": 0.2525
        },
        "0.01": {
          "tp": 202,
          "fn": 598,
          "accuracy": 0.2525
        }
      },
      "auroc": 0.6097916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        },
        "0.01": {
          "tp": 27,
          "fn": 173,
          "accuracy": 0.135
        }
      },
      "auroc": 0.5510416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        },
        "0.01": {
          "tp": 36,
          "fn": 164,
          "accuracy": 0.18
        }
      },
      "auroc": 0.5735416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        },
        "0.01": {
          "tp": 63,
          "fn": 337,
          "accuracy": 0.1575
        }
      },
      "auroc": 0.5622916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        },
        "0.01": {
          "tp": 85,
          "fn": 115,
          "accuracy": 0.425
        }
      },
      "auroc": 0.6960416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        },
        "0.01": {
          "tp": 11,
          "fn": 189,
          "accuracy": 0.055
        }
      },
      "auroc": 0.5110416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 96,
          "fn": 304,
          "accuracy": 0.24
        },
        "0.01": {
          "tp": 96,
          "fn": 304,
          "accuracy": 0.24
        }
      },
      "auroc": 0.6035416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 112,
          "fn": 288,
          "accuracy": 0.28
        },
        "0.01": {
          "tp": 112,
          "fn": 288,
          "accuracy": 0.28
        }
      },
      "auroc": 0.6235416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        },
        "0.01": {
          "tp": 47,
          "fn": 353,
          "accuracy": 0.1175
        }
      },
      "auroc": 0.5422916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 159,
          "fn": 641,
          "accuracy": 0.19875
        },
        "0.01": {
          "tp": 159,
          "fn": 641,
          "accuracy": 0.19875
        }
      },
      "auroc": 0.5829166666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        },
        "0.01": {
          "tp": 168,
          "fn": 32,
          "accuracy": 0.84
        }
      },
      "auroc": 0.9035416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        },
        "0.01": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        }
      },
      "auroc": 0.9410416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 351,
          "fn": 49,
          "accuracy": 0.8775
        },
        "0.01": {
          "tp": 351,
          "fn": 49,
          "accuracy": 0.8775
        }
      },
      "auroc": 0.9222916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        },
        "0.01": {
          "tp": 161,
          "fn": 39,
          "accuracy": 0.805
        }
      },
      "auroc": 0.8860416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        },
        "0.01": {
          "tp": 122,
          "fn": 78,
          "accuracy": 0.61
        }
      },
      "auroc": 0.7885416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 283,
          "fn": 117,
          "accuracy": 0.7075
        },
        "0.01": {
          "tp": 283,
          "fn": 117,
          "accuracy": 0.7075
        }
      },
      "auroc": 0.8372916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        },
        "0.01": {
          "tp": 329,
          "fn": 71,
          "accuracy": 0.8225
        }
      },
      "auroc": 0.8947916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 305,
          "fn": 95,
          "accuracy": 0.7625
        },
        "0.01": {
          "tp": 305,
          "fn": 95,
          "accuracy": 0.7625
        }
      },
      "auroc": 0.8647916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 634,
          "fn": 166,
          "accuracy": 0.7925
        },
        "0.01": {
          "tp": 634,
          "fn": 166,
          "accuracy": 0.7925
        }
      },
      "auroc": 0.8797916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        },
        "0.01": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        }
      },
      "auroc": 0.9410416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        },
        "0.01": {
          "tp": 183,
          "fn": 17,
          "accuracy": 0.915
        }
      },
      "auroc": 0.9410416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        },
        "0.01": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        }
      },
      "auroc": 0.9510416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        },
        "0.01": {
          "tp": 187,
          "fn": 13,
          "accuracy": 0.935
        }
      },
      "auroc": 0.9510416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 370,
          "fn": 30,
          "accuracy": 0.925
        },
        "0.01": {
          "tp": 370,
          "fn": 30,
          "accuracy": 0.925
        }
      },
      "auroc": 0.9460416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 370,
          "fn": 30,
          "accuracy": 0.925
        },
        "0.01": {
          "tp": 370,
          "fn": 30,
          "accuracy": 0.925
        }
      },
      "auroc": 0.9460416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        }
      },
      "auroc": 0.7535416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        },
        "0.01": {
          "tp": 108,
          "fn": 92,
          "accuracy": 0.54
        }
      },
      "auroc": 0.7535416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        },
        "0.01": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        }
      },
      "auroc": 0.7285416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        },
        "0.01": {
          "tp": 98,
          "fn": 102,
          "accuracy": 0.49
        }
      },
      "auroc": 0.7285416666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 206,
          "fn": 194,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 206,
          "fn": 194,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7410416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 206,
          "fn": 194,
          "accuracy": 0.515
        },
        "0.01": {
          "tp": 206,
          "fn": 194,
          "accuracy": 0.515
        }
      },
      "auroc": 0.7410416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        },
        "0.01": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        }
      },
      "auroc": 0.7785416666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        },
        "0.01": {
          "tp": 118,
          "fn": 82,
          "accuracy": 0.59
        }
      },
      "auroc": 0.7785416666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        },
        "0.01": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        }
      },
      "auroc": 0.7810416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        },
        "0.01": {
          "tp": 119,
          "fn": 81,
          "accuracy": 0.595
        }
      },
      "auroc": 0.7810416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 237,
          "fn": 163,
          "accuracy": 0.5925
        },
        "0.01": {
          "tp": 237,
          "fn": 163,
          "accuracy": 0.5925
        }
      },
      "auroc": 0.7797916666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 237,
          "fn": 163,
          "accuracy": 0.5925
        },
        "0.01": {
          "tp": 237,
          "fn": 163,
          "accuracy": 0.5925
        }
      },
      "auroc": 0.7797916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        },
        "0.01": {
          "tp": 186,
          "fn": 14,
          "accuracy": 0.93
        }
      },
      "auroc": 0.9485416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 177,
          "fn": 23,
          "accuracy": 0.885
        },
        "0.01": {
          "tp": 177,
          "fn": 23,
          "accuracy": 0.885
        }
      },
      "auroc": 0.9260416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 177,
          "fn": 23,
          "accuracy": 0.885
        },
        "0.01": {
          "tp": 177,
          "fn": 23,
          "accuracy": 0.885
        }
      },
      "auroc": 0.9260416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 363,
          "fn": 37,
          "accuracy": 0.9075
        },
        "0.01": {
          "tp": 363,
          "fn": 37,
          "accuracy": 0.9075
        }
      },
      "auroc": 0.9372916666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 363,
          "fn": 37,
          "accuracy": 0.9075
        },
        "0.01": {
          "tp": 363,
          "fn": 37,
          "accuracy": 0.9075
        }
      },
      "auroc": 0.9372916666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.7910416666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        },
        "0.01": {
          "tp": 123,
          "fn": 77,
          "accuracy": 0.615
        }
      },
      "auroc": 0.7910416666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        },
        "0.01": {
          "tp": 110,
          "fn": 90,
          "accuracy": 0.55
        }
      },
      "auroc": 0.7585416666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 233,
          "fn": 167,
          "accuracy": 0.5825
        },
        "0.01": {
          "tp": 233,
          "fn": 167,
          "accuracy": 0.5825
        }
      },
      "auroc": 0.7747916666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 233,
          "fn": 167,
          "accuracy": 0.5825
        },
        "0.01": {
          "tp": 233,
          "fn": 167,
          "accuracy": 0.5825
        }
      },
      "auroc": 0.7747916666666665
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1296,
          "fn": 904,
          "accuracy": 0.5890909090909091
        },
        "0.01": {
          "tp": 1296,
          "fn": 904,
          "accuracy": 0.5890909090909091
        }
      },
      "auroc": 0.7780871212121212
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 622,
          "fn": 578,
          "accuracy": 0.5183333333333333
        },
        "0.01": {
          "tp": 622,
          "fn": 578,
          "accuracy": 0.5183333333333333
        }
      },
      "auroc": 0.7427083333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1918,
          "fn": 1482,
          "accuracy": 0.5641176470588235
        },
        "0.01": {
          "tp": 1918,
          "fn": 1482,
          "accuracy": 0.5641176470588235
        }
      },
      "auroc": 0.7656004901960783
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1387,
          "fn": 813,
          "accuracy": 0.6304545454545455
        },
        "0.01": {
          "tp": 1387,
          "fn": 813,
          "accuracy": 0.6304545454545455
        }
      },
      "auroc": 0.7987689393939393
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 437,
          "fn": 763,
          "accuracy": 0.3641666666666667
        },
        "0.01": {
          "tp": 437,
          "fn": 763,
          "accuracy": 0.3641666666666667
        }
      },
      "auroc": 0.665625
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1824,
          "fn": 1576,
          "accuracy": 0.5364705882352941
        },
        "0.01": {
          "tp": 1824,
          "fn": 1576,
          "accuracy": 0.5364705882352941
        }
      },
      "auroc": 0.7517769607843138
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 2683,
          "fn": 1717,
          "accuracy": 0.6097727272727272
        },
        "0.01": {
          "tp": 2683,
          "fn": 1717,
          "accuracy": 0.6097727272727272
        }
      },
      "auroc": 0.7884280303030303
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 1059,
          "fn": 1341,
          "accuracy": 0.44125
        },
        "0.01": {
          "tp": 1059,
          "fn": 1341,
          "accuracy": 0.44125
        }
      },
      "auroc": 0.7041666666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": {
          "tp": 3742,
          "fn": 3058,
          "accuracy": 0.5502941176470588
        },
        "0.01": {
          "tp": 3742,
          "fn": 3058,
          "accuracy": 0.5502941176470588
        }
      },
      "auroc": 0.7586887254901961
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        },
        "0.01": {
          "tp": 1,
          "fn": 199,
          "accuracy": 0.005
        }
      },
      "auroc": 0.4860416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.4847916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        },
        "0.01": {
          "tp": 1,
          "fn": 399,
          "accuracy": 0.0025
        }
      },
      "auroc": 0.4847916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 799,
          "accuracy": 0.00125
        },
        "0.01": {
          "tp": 1,
          "fn": 799,
          "accuracy": 0.00125
        }
      },
      "auroc": 0.48416666666666663
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 800,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 2200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 2200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 1200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 1200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 3400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 3400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 2200,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 2200,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 1199,
          "accuracy": 0.0008333333333333334
        },
        "0.01": {
          "tp": 1,
          "fn": 1199,
          "accuracy": 0.0008333333333333334
        }
      },
      "auroc": 0.48395833333333327
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 3399,
          "accuracy": 0.0002941176470588235
        },
        "0.01": {
          "tp": 1,
          "fn": 3399,
          "accuracy": 0.0002941176470588235
        }
      },
      "auroc": 0.48368872549019604
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 0,
          "fn": 4400,
          "accuracy": 0.0
        },
        "0.01": {
          "tp": 0,
          "fn": 4400,
          "accuracy": 0.0
        }
      },
      "auroc": 0.48354166666666665
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 2399,
          "accuracy": 0.0004166666666666667
        },
        "0.01": {
          "tp": 1,
          "fn": 2399,
          "accuracy": 0.0004166666666666667
        }
      },
      "auroc": 0.48375
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": {
          "tp": 1,
          "fn": 6799,
          "accuracy": 0.00014705882352941175
        },
        "0.01": {
          "tp": 1,
          "fn": 6799,
          "accuracy": 0.00014705882352941175
        }
      },
      "auroc": 0.4836151960784314
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1737,
          "fn": 663,
          "accuracy": 0.72375
        },
        "0.01": {
          "tp": 1737,
          "fn": 663,
          "accuracy": 0.72375
        }
      },
      "auroc": 0.8454166666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1680,
          "fn": 720,
          "accuracy": 0.7
        },
        "0.01": {
          "tp": 1680,
          "fn": 720,
          "accuracy": 0.7
        }
      },
      "auroc": 0.8335416666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3417,
          "fn": 1383,
          "accuracy": 0.711875
        },
        "0.01": {
          "tp": 3417,
          "fn": 1383,
          "accuracy": 0.711875
        }
      },
      "auroc": 0.8394791666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1653,
          "fn": 747,
          "accuracy": 0.68875
        },
        "0.01": {
          "tp": 1653,
          "fn": 747,
          "accuracy": 0.68875
        }
      },
      "auroc": 0.8279166666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1524,
          "fn": 876,
          "accuracy": 0.635
        },
        "0.01": {
          "tp": 1524,
          "fn": 876,
          "accuracy": 0.635
        }
      },
      "auroc": 0.8010416666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3177,
          "fn": 1623,
          "accuracy": 0.661875
        },
        "0.01": {
          "tp": 3177,
          "fn": 1623,
          "accuracy": 0.661875
        }
      },
      "auroc": 0.8144791666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3390,
          "fn": 1410,
          "accuracy": 0.70625
        },
        "0.01": {
          "tp": 3390,
          "fn": 1410,
          "accuracy": 0.70625
        }
      },
      "auroc": 0.8366666666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3204,
          "fn": 1596,
          "accuracy": 0.6675
        },
        "0.01": {
          "tp": 3204,
          "fn": 1596,
          "accuracy": 0.6675
        }
      },
      "auroc": 0.8172916666666666
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 6594,
          "fn": 3006,
          "accuracy": 0.686875
        },
        "0.01": {
          "tp": 6594,
          "fn": 3006,
          "accuracy": 0.686875
        }
      },
      "auroc": 0.8269791666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 289,
          "fn": 2111,
          "accuracy": 0.12041666666666667
        },
        "0.01": {
          "tp": 289,
          "fn": 2111,
          "accuracy": 0.12041666666666667
        }
      },
      "auroc": 0.54375
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 143,
          "fn": 2257,
          "accuracy": 0.059583333333333335
        },
        "0.01": {
          "tp": 143,
          "fn": 2257,
          "accuracy": 0.059583333333333335
        }
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 432,
          "fn": 4368,
          "accuracy": 0.09
        },
        "0.01": {
          "tp": 432,
          "fn": 4368,
          "accuracy": 0.09
        }
      },
      "auroc": 0.5285416666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 319,
          "fn": 2081,
          "accuracy": 0.13291666666666666
        },
        "0.01": {
          "tp": 319,
          "fn": 2081,
          "accuracy": 0.13291666666666666
        }
      },
      "auroc": 0.5499999999999999
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 222,
          "fn": 2178,
          "accuracy": 0.0925
        },
        "0.01": {
          "tp": 222,
          "fn": 2178,
          "accuracy": 0.0925
        }
      },
      "auroc": 0.5297916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 541,
          "fn": 4259,
          "accuracy": 0.11270833333333333
        },
        "0.01": {
          "tp": 541,
          "fn": 4259,
          "accuracy": 0.11270833333333333
        }
      },
      "auroc": 0.5398958333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 608,
          "fn": 4192,
          "accuracy": 0.12666666666666668
        },
        "0.01": {
          "tp": 608,
          "fn": 4192,
          "accuracy": 0.12666666666666668
        }
      },
      "auroc": 0.546875
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 365,
          "fn": 4435,
          "accuracy": 0.07604166666666666
        },
        "0.01": {
          "tp": 365,
          "fn": 4435,
          "accuracy": 0.07604166666666666
        }
      },
      "auroc": 0.5215624999999999
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 973,
          "fn": 8627,
          "accuracy": 0.10135416666666666
        },
        "0.01": {
          "tp": 973,
          "fn": 8627,
          "accuracy": 0.10135416666666666
        }
      },
      "auroc": 0.53421875
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1412,
          "fn": 988,
          "accuracy": 0.5883333333333334
        },
        "0.01": {
          "tp": 1412,
          "fn": 988,
          "accuracy": 0.5883333333333334
        }
      },
      "auroc": 0.7777083333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1130,
          "fn": 1270,
          "accuracy": 0.4708333333333333
        },
        "0.01": {
          "tp": 1130,
          "fn": 1270,
          "accuracy": 0.4708333333333333
        }
      },
      "auroc": 0.7189583333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2542,
          "fn": 2258,
          "accuracy": 0.5295833333333333
        },
        "0.01": {
          "tp": 2542,
          "fn": 2258,
          "accuracy": 0.5295833333333333
        }
      },
      "auroc": 0.7483333333333332
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1360,
          "fn": 1040,
          "accuracy": 0.5666666666666667
        },
        "0.01": {
          "tp": 1360,
          "fn": 1040,
          "accuracy": 0.5666666666666667
        }
      },
      "auroc": 0.766875
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 898,
          "fn": 1502,
          "accuracy": 0.37416666666666665
        },
        "0.01": {
          "tp": 898,
          "fn": 1502,
          "accuracy": 0.37416666666666665
        }
      },
      "auroc": 0.6706249999999999
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2258,
          "fn": 2542,
          "accuracy": 0.47041666666666665
        },
        "0.01": {
          "tp": 2258,
          "fn": 2542,
          "accuracy": 0.47041666666666665
        }
      },
      "auroc": 0.71875
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2772,
          "fn": 2028,
          "accuracy": 0.5775
        },
        "0.01": {
          "tp": 2772,
          "fn": 2028,
          "accuracy": 0.5775
        }
      },
      "auroc": 0.7722916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2028,
          "fn": 2772,
          "accuracy": 0.4225
        },
        "0.01": {
          "tp": 2028,
          "fn": 2772,
          "accuracy": 0.4225
        }
      },
      "auroc": 0.6947916666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 4800,
          "fn": 4800,
          "accuracy": 0.5
        },
        "0.01": {
          "tp": 4800,
          "fn": 4800,
          "accuracy": 0.5
        }
      },
      "auroc": 0.7335416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 103,
          "fn": 2297,
          "accuracy": 0.042916666666666665
        },
        "0.01": {
          "tp": 103,
          "fn": 2297,
          "accuracy": 0.042916666666666665
        }
      },
      "auroc": 0.505
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 745,
          "fn": 1655,
          "accuracy": 0.3104166666666667
        },
        "0.01": {
          "tp": 745,
          "fn": 1655,
          "accuracy": 0.3104166666666667
        }
      },
      "auroc": 0.63875
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 848,
          "fn": 3952,
          "accuracy": 0.17666666666666667
        },
        "0.01": {
          "tp": 848,
          "fn": 3952,
          "accuracy": 0.17666666666666667
        }
      },
      "auroc": 0.571875
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 783,
          "fn": 1617,
          "accuracy": 0.32625
        },
        "0.01": {
          "tp": 783,
          "fn": 1617,
          "accuracy": 0.32625
        }
      },
      "auroc": 0.6466666666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 251,
          "fn": 2149,
          "accuracy": 0.10458333333333333
        },
        "0.01": {
          "tp": 251,
          "fn": 2149,
          "accuracy": 0.10458333333333333
        }
      },
      "auroc": 0.5358333333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1034,
          "fn": 3766,
          "accuracy": 0.21541666666666667
        },
        "0.01": {
          "tp": 1034,
          "fn": 3766,
          "accuracy": 0.21541666666666667
        }
      },
      "auroc": 0.5912499999999999
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 886,
          "fn": 3914,
          "accuracy": 0.18458333333333332
        },
        "0.01": {
          "tp": 886,
          "fn": 3914,
          "accuracy": 0.18458333333333332
        }
      },
      "auroc": 0.5758333333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 996,
          "fn": 3804,
          "accuracy": 0.2075
        },
        "0.01": {
          "tp": 996,
          "fn": 3804,
          "accuracy": 0.2075
        }
      },
      "auroc": 0.5872916666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1882,
          "fn": 7718,
          "accuracy": 0.19604166666666667
        },
        "0.01": {
          "tp": 1882,
          "fn": 7718,
          "accuracy": 0.19604166666666667
        }
      },
      "auroc": 0.5815625
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 244,
          "fn": 2156,
          "accuracy": 0.10166666666666667
        },
        "0.01": {
          "tp": 244,
          "fn": 2156,
          "accuracy": 0.10166666666666667
        }
      },
      "auroc": 0.5343749999999999
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 354,
          "fn": 2046,
          "accuracy": 0.1475
        },
        "0.01": {
          "tp": 354,
          "fn": 2046,
          "accuracy": 0.1475
        }
      },
      "auroc": 0.5572916666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 598,
          "fn": 4202,
          "accuracy": 0.12458333333333334
        },
        "0.01": {
          "tp": 598,
          "fn": 4202,
          "accuracy": 0.12458333333333334
        }
      },
      "auroc": 0.5458333333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 768,
          "fn": 1632,
          "accuracy": 0.32
        },
        "0.01": {
          "tp": 768,
          "fn": 1632,
          "accuracy": 0.32
        }
      },
      "auroc": 0.6435416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 123,
          "fn": 2277,
          "accuracy": 0.05125
        },
        "0.01": {
          "tp": 123,
          "fn": 2277,
          "accuracy": 0.05125
        }
      },
      "auroc": 0.5091666666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 891,
          "fn": 3909,
          "accuracy": 0.185625
        },
        "0.01": {
          "tp": 891,
          "fn": 3909,
          "accuracy": 0.185625
        }
      },
      "auroc": 0.5763541666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1012,
          "fn": 3788,
          "accuracy": 0.21083333333333334
        },
        "0.01": {
          "tp": 1012,
          "fn": 3788,
          "accuracy": 0.21083333333333334
        }
      },
      "auroc": 0.5889583333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 477,
          "fn": 4323,
          "accuracy": 0.099375
        },
        "0.01": {
          "tp": 477,
          "fn": 4323,
          "accuracy": 0.099375
        }
      },
      "auroc": 0.5332291666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1489,
          "fn": 8111,
          "accuracy": 0.15510416666666665
        },
        "0.01": {
          "tp": 1489,
          "fn": 8111,
          "accuracy": 0.15510416666666665
        }
      },
      "auroc": 0.56109375
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1538,
          "fn": 862,
          "accuracy": 0.6408333333333334
        },
        "0.01": {
          "tp": 1538,
          "fn": 862,
          "accuracy": 0.6408333333333334
        }
      },
      "auroc": 0.8039583333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1640,
          "fn": 760,
          "accuracy": 0.6833333333333333
        },
        "0.01": {
          "tp": 1640,
          "fn": 760,
          "accuracy": 0.6833333333333333
        }
      },
      "auroc": 0.8252083333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3178,
          "fn": 1622,
          "accuracy": 0.6620833333333334
        },
        "0.01": {
          "tp": 3178,
          "fn": 1622,
          "accuracy": 0.6620833333333334
        }
      },
      "auroc": 0.8145833333333332
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1425,
          "fn": 975,
          "accuracy": 0.59375
        },
        "0.01": {
          "tp": 1425,
          "fn": 975,
          "accuracy": 0.59375
        }
      },
      "auroc": 0.7804166666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1102,
          "fn": 1298,
          "accuracy": 0.45916666666666667
        },
        "0.01": {
          "tp": 1102,
          "fn": 1298,
          "accuracy": 0.45916666666666667
        }
      },
      "auroc": 0.713125
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2527,
          "fn": 2273,
          "accuracy": 0.5264583333333334
        },
        "0.01": {
          "tp": 2527,
          "fn": 2273,
          "accuracy": 0.5264583333333334
        }
      },
      "auroc": 0.7467708333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2963,
          "fn": 1837,
          "accuracy": 0.6172916666666667
        },
        "0.01": {
          "tp": 2963,
          "fn": 1837,
          "accuracy": 0.6172916666666667
        }
      },
      "auroc": 0.7921874999999999
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2742,
          "fn": 2058,
          "accuracy": 0.57125
        },
        "0.01": {
          "tp": 2742,
          "fn": 2058,
          "accuracy": 0.57125
        }
      },
      "auroc": 0.7691666666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 5705,
          "fn": 3895,
          "accuracy": 0.5942708333333333
        },
        "0.01": {
          "tp": 5705,
          "fn": 3895,
          "accuracy": 0.5942708333333333
        }
      },
      "auroc": 0.7806770833333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1718,
          "fn": 682,
          "accuracy": 0.7158333333333333
        },
        "0.01": {
          "tp": 1718,
          "fn": 682,
          "accuracy": 0.7158333333333333
        }
      },
      "auroc": 0.8414583333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1718,
          "fn": 682,
          "accuracy": 0.7158333333333333
        },
        "0.01": {
          "tp": 1718,
          "fn": 682,
          "accuracy": 0.7158333333333333
        }
      },
      "auroc": 0.8414583333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1752,
          "fn": 648,
          "accuracy": 0.73
        },
        "0.01": {
          "tp": 1752,
          "fn": 648,
          "accuracy": 0.73
        }
      },
      "auroc": 0.8485416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1752,
          "fn": 648,
          "accuracy": 0.73
        },
        "0.01": {
          "tp": 1752,
          "fn": 648,
          "accuracy": 0.73
        }
      },
      "auroc": 0.8485416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3470,
          "fn": 1330,
          "accuracy": 0.7229166666666667
        },
        "0.01": {
          "tp": 3470,
          "fn": 1330,
          "accuracy": 0.7229166666666667
        }
      },
      "auroc": 0.845
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3470,
          "fn": 1330,
          "accuracy": 0.7229166666666667
        },
        "0.01": {
          "tp": 3470,
          "fn": 1330,
          "accuracy": 0.7229166666666667
        }
      },
      "auroc": 0.845
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 939,
          "fn": 1461,
          "accuracy": 0.39125
        },
        "0.01": {
          "tp": 939,
          "fn": 1461,
          "accuracy": 0.39125
        }
      },
      "auroc": 0.6791666666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 939,
          "fn": 1461,
          "accuracy": 0.39125
        },
        "0.01": {
          "tp": 939,
          "fn": 1461,
          "accuracy": 0.39125
        }
      },
      "auroc": 0.6791666666666666
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 870,
          "fn": 1530,
          "accuracy": 0.3625
        },
        "0.01": {
          "tp": 870,
          "fn": 1530,
          "accuracy": 0.3625
        }
      },
      "auroc": 0.6647916666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 870,
          "fn": 1530,
          "accuracy": 0.3625
        },
        "0.01": {
          "tp": 870,
          "fn": 1530,
          "accuracy": 0.3625
        }
      },
      "auroc": 0.6647916666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1809,
          "fn": 2991,
          "accuracy": 0.376875
        },
        "0.01": {
          "tp": 1809,
          "fn": 2991,
          "accuracy": 0.376875
        }
      },
      "auroc": 0.6719791666666667
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1809,
          "fn": 2991,
          "accuracy": 0.376875
        },
        "0.01": {
          "tp": 1809,
          "fn": 2991,
          "accuracy": 0.376875
        }
      },
      "auroc": 0.6719791666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1035,
          "fn": 1365,
          "accuracy": 0.43125
        },
        "0.01": {
          "tp": 1035,
          "fn": 1365,
          "accuracy": 0.43125
        }
      },
      "auroc": 0.6991666666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1035,
          "fn": 1365,
          "accuracy": 0.43125
        },
        "0.01": {
          "tp": 1035,
          "fn": 1365,
          "accuracy": 0.43125
        }
      },
      "auroc": 0.6991666666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1053,
          "fn": 1347,
          "accuracy": 0.43875
        },
        "0.01": {
          "tp": 1053,
          "fn": 1347,
          "accuracy": 0.43875
        }
      },
      "auroc": 0.7029166666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1053,
          "fn": 1347,
          "accuracy": 0.43875
        },
        "0.01": {
          "tp": 1053,
          "fn": 1347,
          "accuracy": 0.43875
        }
      },
      "auroc": 0.7029166666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2088,
          "fn": 2712,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 2088,
          "fn": 2712,
          "accuracy": 0.435
        }
      },
      "auroc": 0.7010416666666667
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2088,
          "fn": 2712,
          "accuracy": 0.435
        },
        "0.01": {
          "tp": 2088,
          "fn": 2712,
          "accuracy": 0.435
        }
      },
      "auroc": 0.7010416666666667
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1595,
          "fn": 805,
          "accuracy": 0.6645833333333333
        },
        "0.01": {
          "tp": 1595,
          "fn": 805,
          "accuracy": 0.6645833333333333
        }
      },
      "auroc": 0.8158333333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1595,
          "fn": 805,
          "accuracy": 0.6645833333333333
        },
        "0.01": {
          "tp": 1595,
          "fn": 805,
          "accuracy": 0.6645833333333333
        }
      },
      "auroc": 0.8158333333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1492,
          "fn": 908,
          "accuracy": 0.6216666666666667
        },
        "0.01": {
          "tp": 1492,
          "fn": 908,
          "accuracy": 0.6216666666666667
        }
      },
      "auroc": 0.7943749999999999
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1492,
          "fn": 908,
          "accuracy": 0.6216666666666667
        },
        "0.01": {
          "tp": 1492,
          "fn": 908,
          "accuracy": 0.6216666666666667
        }
      },
      "auroc": 0.7943749999999999
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3087,
          "fn": 1713,
          "accuracy": 0.643125
        },
        "0.01": {
          "tp": 3087,
          "fn": 1713,
          "accuracy": 0.643125
        }
      },
      "auroc": 0.8051041666666666
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 3087,
          "fn": 1713,
          "accuracy": 0.643125
        },
        "0.01": {
          "tp": 3087,
          "fn": 1713,
          "accuracy": 0.643125
        }
      },
      "auroc": 0.8051041666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1098,
          "fn": 1302,
          "accuracy": 0.4575
        },
        "0.01": {
          "tp": 1098,
          "fn": 1302,
          "accuracy": 0.4575
        }
      },
      "auroc": 0.7122916666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1098,
          "fn": 1302,
          "accuracy": 0.4575
        },
        "0.01": {
          "tp": 1098,
          "fn": 1302,
          "accuracy": 0.4575
        }
      },
      "auroc": 0.7122916666666667
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1000,
          "fn": 1400,
          "accuracy": 0.4166666666666667
        },
        "0.01": {
          "tp": 1000,
          "fn": 1400,
          "accuracy": 0.4166666666666667
        }
      },
      "auroc": 0.691875
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 1000,
          "fn": 1400,
          "accuracy": 0.4166666666666667
        },
        "0.01": {
          "tp": 1000,
          "fn": 1400,
          "accuracy": 0.4166666666666667
        }
      },
      "auroc": 0.691875
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2098,
          "fn": 2702,
          "accuracy": 0.4370833333333333
        },
        "0.01": {
          "tp": 2098,
          "fn": 2702,
          "accuracy": 0.4370833333333333
        }
      },
      "auroc": 0.7020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 2098,
          "fn": 2702,
          "accuracy": 0.4370833333333333
        },
        "0.01": {
          "tp": 2098,
          "fn": 2702,
          "accuracy": 0.4370833333333333
        }
      },
      "auroc": 0.7020833333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 11708,
          "fn": 14692,
          "accuracy": 0.4434848484848485
        },
        "0.01": {
          "tp": 11708,
          "fn": 14692,
          "accuracy": 0.4434848484848485
        }
      },
      "auroc": 0.7052840909090908
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 5692,
          "fn": 8708,
          "accuracy": 0.3952777777777778
        },
        "0.01": {
          "tp": 5692,
          "fn": 8708,
          "accuracy": 0.3952777777777778
        }
      },
      "auroc": 0.6811805555555556
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 17400,
          "fn": 23400,
          "accuracy": 0.4264705882352941
        },
        "0.01": {
          "tp": 17400,
          "fn": 23400,
          "accuracy": 0.4264705882352941
        }
      },
      "auroc": 0.6967769607843136
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 12475,
          "fn": 13925,
          "accuracy": 0.4725378787878788
        },
        "0.01": {
          "tp": 12475,
          "fn": 13925,
          "accuracy": 0.4725378787878788
        }
      },
      "auroc": 0.7198106060606061
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 4120,
          "fn": 10280,
          "accuracy": 0.2861111111111111
        },
        "0.01": {
          "tp": 4120,
          "fn": 10280,
          "accuracy": 0.2861111111111111
        }
      },
      "auroc": 0.6265972222222221
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 16595,
          "fn": 24205,
          "accuracy": 0.40674019607843137
        },
        "0.01": {
          "tp": 16595,
          "fn": 24205,
          "accuracy": 0.40674019607843137
        }
      },
      "auroc": 0.6869117647058823
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 24183,
          "fn": 28617,
          "accuracy": 0.45801136363636363
        },
        "0.01": {
          "tp": 24183,
          "fn": 28617,
          "accuracy": 0.45801136363636363
        }
      },
      "auroc": 0.7125473484848485
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 9812,
          "fn": 18988,
          "accuracy": 0.34069444444444447
        },
        "0.01": {
          "tp": 9812,
          "fn": 18988,
          "accuracy": 0.34069444444444447
        }
      },
      "auroc": 0.6538888888888889
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": {
          "tp": 33995,
          "fn": 47605,
          "accuracy": 0.41660539215686276
        },
        "0.01": {
          "tp": 33995,
          "fn": 47605,
          "accuracy": 0.41660539215686276
        }
      },
      "auroc": 0.691844362745098
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9041666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9029166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8441666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8704166666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9004166666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44166666666666665
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5229166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5141666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49791666666666673
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5591666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46166666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5104166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7891666666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6741666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7316666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7866666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6191666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7029166666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7879166666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6466666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7172916666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5316666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6891666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6104166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6816666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5241666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6029166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6341666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6441666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7266666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4716666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6904166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5529166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6216666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8366666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8491666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8516666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8429166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8854166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8754166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8754166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7054166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7054166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8716666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8716666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9241666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9241666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9129166666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9129166666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8216666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8216666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7816666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7816666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7791666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7095833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7546078431372549
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7757575757575759
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325000000000001
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7251960784313726
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7774621212121212
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6710416666666668
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7399019607843138
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8416666666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8354166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8191666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7791666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7991666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8304166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8041666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8172916666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4666666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4391666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45291666666666675
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4666666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47416666666666674
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4704166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4666666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45666666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46166666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5441666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4666666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5054166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5791666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4766666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5279166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5616666666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4716666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5166666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5591666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5591666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5591666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666676
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5529166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5829166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5560416666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6741666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5391666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45166666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5404166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6516666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4954166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5735416666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7041666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8366666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7704166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6991666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7366666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7179166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7016666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7866666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7441666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7641666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7641666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7779166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7779166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5866666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5866666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5391666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5391666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5629166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5629166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7491666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7491666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7991666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7991666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7741666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7741666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8166666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8166666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7841666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7841666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8004166666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8004166666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6341666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6341666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5766666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5766666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6054166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6054166666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6698484848484849
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6116666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6493137254901962
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6603030303030304
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5695833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6282843137254903
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6650757575757575
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5906250000000001
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6387990196078431
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8804166666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8216666666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8516666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8454166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8660416666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5741666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4391666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5066666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5279166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46041666666666675
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49416666666666664
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6491666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6891666666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7316666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5916666666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6616666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7304166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6204166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6754166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5416666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6591666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6004166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6591666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5116666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5854166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6004166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5854166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5929166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6516666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6141666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6329166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6966666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4666666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5816666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6741666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5404166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6072916666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8091666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8554166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8216666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8266666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8241666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8154166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8397916666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8466666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8466666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8616666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8616666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7016666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7016666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6391666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6391666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6704166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6704166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8466666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8466666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8704166666666666
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8704166666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8791666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8791666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7841666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7841666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7141666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7141666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7491666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7491666666666668
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7559848484848486
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68875
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7322549019607844
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7496212121212121
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6166666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7026960784313726
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7528030303030303
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6527083333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7174754901960785
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8516666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8604166666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8616666666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8141666666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8379166666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8654166666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8329166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8491666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5441666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4391666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4916666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4866666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4841666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4854166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5154166666666666
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46166666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48854166666666665
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7141666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6566666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7066666666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5541666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6304166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7104166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5766666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6435416666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5341666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6441666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5891666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6591666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5166666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5879166666666666
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5966666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5804166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5885416666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6591666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6841666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4641666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5741666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5316666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6016666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7966666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8391666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7791666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8066666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7929166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7879166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8441666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8160416666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8491666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8491666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8316666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8316666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8404166666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8404166666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6916666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6916666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6441666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6441666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6679166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6679166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8391666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8391666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8791666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8791666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666666
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7891666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7891666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6941666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6941666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666668
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7443939393939394
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.717843137254902
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7375757575757576
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6913725490196079
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7409848484848485
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6379166666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7046078431372549
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9041666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8391666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8666666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8854166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44166666666666665
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5204166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5066666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4841666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4954166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5529166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46291666666666664
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5079166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7766666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7154166666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6116666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6966666666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7791666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6329166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7060416666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5341666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6791666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5216666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5966666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6029166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6004166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6016666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6266666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6404166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7241666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4716666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5979166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6891666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5491666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6191666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8316666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9141666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8416666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8491666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8454166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8366666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8616666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8616666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7316666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7316666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6616666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6616666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6966666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6966666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8666666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8666666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9191666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9091666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8141666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8141666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7466666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7466666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7804166666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7804166666666668
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7739393939393939
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7487254901960785
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7718939393939395
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6295833333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7216666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7729166666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6660416666666666
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7351960784313726
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5516666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5441666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5716666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5266666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5491666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5616666666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5316666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5466666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5516666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4841666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5179166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5204166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5279166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5104166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5191666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6841666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6341666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6441666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6391666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6591666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6491666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5241666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5591666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5416666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5441666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666676
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5216666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5341666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5316666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5191666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48916666666666675
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5091666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4666666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48791666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5141666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47791666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4960416666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6216666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5491666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5854166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5941666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5766666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5854166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6079166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5629166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5854166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7341666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7341666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7316666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7316666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5616666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5616666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5316666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5316666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5466666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5466666666666666
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6041666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6041666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5566666666666666
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5566666666666666
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5804166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5804166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5841666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5841666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5604166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5604166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6191666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6191666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5941666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5941666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5959848484848485
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5454166666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5781372549019608
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5732575757575757
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5416666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5621078431372549
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5846212121212122
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5435416666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5701225490196079
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9041666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9029166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8441666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8704166666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9004166666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44166666666666665
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5241666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5141666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49791666666666673
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5604166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46166666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5110416666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7941666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6741666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7341666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7891666666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6191666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6466666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7191666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5366666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6891666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6129166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6791666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5216666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6004166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6079166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6054166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6066666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6541666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6316666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6429166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7241666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47416666666666674
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6891666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5529166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6210416666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8366666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9166666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8491666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8516666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8429166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8854166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8779166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8779166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7054166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7054166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8716666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8716666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8891666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9216666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9016666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9116666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9116666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8216666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8216666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7391666666666669
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7391666666666669
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7804166666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7804166666666668
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7800757575757575
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7091666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7550490196078432
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7757575757575759
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6325000000000001
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7251960784313726
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7779166666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6708333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.740122549019608
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8441666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8041666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8241666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8516666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8141666666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8329166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8479166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8091666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8285416666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6916666666666668
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4591666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5754166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6441666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5741666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6679166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5747916666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8166666666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8429166666666668
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7566666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8079166666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7866666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8254166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5191666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6554166666666668
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7041666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6241666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6641666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6116666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7079166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6597916666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6341666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6091666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6216666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5216666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5966666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6529166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5654166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6091666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8816666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8441666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8629166666666669
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8666666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8091666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8379166666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8266666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8504166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8566666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8566666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8391666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8391666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8216666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8216666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7866666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7866666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8041666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8041666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7875757575757576
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7208333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7640196078431373
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7887121212121213
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7474019607843138
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7881439393939393
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.69625
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7557107843137255
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4341666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43166666666666664
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43166666666666664
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43166666666666664
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43166666666666664
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44166666666666665
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4366666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4366666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4335416666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4341666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43166666666666664
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43166666666666664
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43041666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4491666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4391666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4441666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4391666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4341666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4366666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4341666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43166666666666664
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4329166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4666666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4341666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4504166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4504166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4329166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44166666666666665
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4641666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4641666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45666666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45666666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46041666666666675
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46041666666666675
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44666666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44666666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4341666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4341666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4404166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4404166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4366666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4366666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4391666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4391666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43791666666666673
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43791666666666673
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43507575757575756
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43000000000000005
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43328431372549026
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4384848484848485
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43541666666666673
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4374019607843137
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.436780303030303
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43270833333333336
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43534313725490204
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8879166666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8241666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8616666666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8991666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8504166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8747916666666666
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5391666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44166666666666665
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4904166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5104166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46166666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4860416666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6791666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6391666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5741666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6229166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6754166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5866666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6310416666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6766666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6029166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6691666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5216666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5954166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5991666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6491666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6116666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6304166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6941666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4666666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5804166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5391666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6054166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7916666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9041666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8479166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7741666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8241666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7991666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7829166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8235416666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8466666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8466666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8579166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8579166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7066666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7066666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6491666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6491666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6779166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6779166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8516666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8516666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8766666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8641666666666669
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8941666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7816666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7816666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7041666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7041666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7429166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7429166666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7448484848484849
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.685
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7237254901960786
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666668
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6154166666666668
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6971078431372549
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7432575757575758
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6502083333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7104166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9041666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8916666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8979166666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8416666666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8691666666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9004166666666666
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8666666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8835416666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4391666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5216666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5066666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4816666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49416666666666664
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5554166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46041666666666675
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5079166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7766666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6716666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7241666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7766666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6091666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6929166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7766666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6404166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7085416666666666
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6866666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6079166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6816666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5241666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6029166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6054166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6054166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6054166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6466666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6241666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6354166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7241666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46916666666666673
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5966666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6854166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5466666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6160416666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8366666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9141666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8754166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8416666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8541666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8479166666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8391666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8841666666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8616666666666668
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8866666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8591666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7391666666666669
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7391666666666669
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6641666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6641666666666668
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7016666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7016666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8741666666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9066666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8904166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8904166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9241666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9241666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8966666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9104166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9104166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8191666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8191666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7366666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7366666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7779166666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7779166666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7764393939393941
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7045833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.751078431372549
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7718939393939395
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.63
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7218137254901962
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7741666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6672916666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7364460784313726
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43166666666666664
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4297916666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43166666666666664
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43041666666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4297916666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43000000000000005
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4294607843137255
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4295833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42931372549019614
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7814583333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7683333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7748958333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7772916666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.734375
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7558333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.779375
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7513541666666668
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7653645833333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5533333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44395833333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49864583333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49729166666666674
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4804166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4888541666666667
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5253125000000001
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4621875
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49375
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6845833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6097916666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6471875
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68125
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.576875
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6290625000000001
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6829166666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5933333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.638125
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5164583333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.624375
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5704166666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6195833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5110416666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5653125
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5680208333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5677083333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5678645833333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5700000000000001
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5875
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6400000000000001
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46562500000000007
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5528125
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6225
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5178125
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.57015625
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73375
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7864583333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7601041666666668
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73125
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7375
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.734375
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7325
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7619791666666667
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7472395833333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7845833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7845833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7685416666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7685416666666667
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7765625
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7765625
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6539583333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6539583333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6083333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6083333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6311458333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6311458333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7604166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7604166666666667
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7785416666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7785416666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7694791666666668
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7694791666666668
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7952083333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7952083333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7689583333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7689583333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7820833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7820833333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.714375
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.714375
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6585416666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6585416666666667
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6864583333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6864583333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6893750000000001
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6338194444444445
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6697671568627451
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6845075757575759
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5843055555555556
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6491421568627452
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6869412878787879
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6090625000000001
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6594546568627451
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.910625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9093750000000002
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.910625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9068750000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.910625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9087500000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.740625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43562500000000004
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.588125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.613125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.468125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.540625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.676875
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.451875
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.564375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.828125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.864375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6681250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.784375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.748125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8243750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.670625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8256249999999999
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.748125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.728125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6118750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6993750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.660625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.68
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6006250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.728125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.780625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.438125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.609375
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8181250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.519375
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6687500000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.883125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.845625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.864375
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8931250000000002
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8768750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8618750000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8618750000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9118750000000002
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9118750000000002
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9018750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9018750000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.863125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.863125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8706250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8706250000000001
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8585795454545454
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7514583333333335
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8207720588235294
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8358522727272728
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6377083333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7659191176470589
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8472159090909092
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6945833333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7933455882352941
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8906250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8806250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8931250000000002
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8806250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8918750000000002
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8743750000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.883125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.558125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42562500000000003
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49187500000000006
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.458125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.479375
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.529375
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.441875
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4856250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8806250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6431250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.761875
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.553125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.703125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.866875
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.598125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7325
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.760625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6681250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7143750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.620625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46562500000000007
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.543125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.690625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.566875
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.520625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.681875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6431250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43562500000000004
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.539375
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.743125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.478125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6106250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.883125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.845625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.780625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.813125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.864375
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.834375
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8493750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8181250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8181250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8081250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8081250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.783125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.783125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.795625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.795625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.898125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.898125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8931250000000002
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8931250000000002
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8056250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8056250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8293750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8293750000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7706250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7706250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7556250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7556250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7631249999999999
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7631249999999999
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8194886363636363
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6710416666666666
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7670955882352941
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7642613636363638
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5935416666666667
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7040073529411764
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.791875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6322916666666668
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7355514705882353
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.895625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.899375
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9018750000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9025000000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7181250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.433125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.575625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.565625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.468125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5168750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6418750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45062500000000005
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.54625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.898125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.815625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.856875
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.660625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.774375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8931250000000002
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7381250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.815625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7181250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7981250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.758125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.700625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48812500000000003
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.594375
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.709375
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6431250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.568125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.710625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.733125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.443125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.588125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.793125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6493750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9018750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8406250000000002
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.854375
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8706250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8406250000000002
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8406250000000002
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.859375
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.859375
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.863125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.863125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.910625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.910625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.896875
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.896875
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8381250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8381250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7364583333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8151838235294118
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8142613636363637
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6339583333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.750625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8361931818181819
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6852083333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7829044117647059
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9131250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.898125
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9068750000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.899375
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7156250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43562500000000004
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.575625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.568125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46562500000000007
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5168750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6418750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45062500000000005
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.54625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.898125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8056250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.851875
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8806250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.650625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.765625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.889375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.728125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.80875
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.678125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.793125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7356250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.690625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48812500000000003
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.589375
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6843750000000002
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.640625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.568125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.711875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.728125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.433125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5806250000000002
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.791875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.895625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.898125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.815625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8418750000000002
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8818750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.87
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.883125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.883125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.848125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.848125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.833125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.833125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.844375
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.844375
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.883125
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.883125
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8931250000000002
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8931250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.864375
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.864375
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8526704545454546
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7335416666666668
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.810625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8149431818181818
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.625625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.748125
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8338068181818182
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6795833333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.779375
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.904375
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9068750000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.90625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.730625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43562500000000004
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.583125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6006250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46562500000000007
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.533125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6656250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45062500000000005
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.558125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.828125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.864375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.670625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.785625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.749375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8250000000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6731250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.810625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.741875
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7156250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6943750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6531250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6737500000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5956250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7256250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.758125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.438125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.598125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.806875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5168750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.661875
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.904375
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8606250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8906250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8743750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8825000000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8756250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8756250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.848125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.848125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9118750000000002
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9118750000000002
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9131250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9131250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.899375
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.899375
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.863125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.863125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8706250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8706250000000001
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.856534090909091
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7472916666666667
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8179779411764707
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8297159090909091
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6364583333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7615073529411767
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.691875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7897426470588236
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.698125
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6831250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.690625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.688125
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.680625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6843750000000002
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6931250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.681875
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6875
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6931250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.513125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.603125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5906250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.588125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.589375
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6418750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.550625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5962500000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.688125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.671875
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6931250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.598125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.645625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.690625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.626875
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6587500000000002
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.560625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.680625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.620625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.535625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5856250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.598125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.608125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.603125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7056250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6306250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6681250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6156250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5181250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.566875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.660625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.574375
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6175
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.748125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.698125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.723125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.703125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.660625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.681875
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7256250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.679375
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.733125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.733125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.695625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.695625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7143750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7143750000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6731250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6731250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.664375
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.664375
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.695625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.695625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.688125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.688125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.691875
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.691875
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6681250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6681250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.645625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.645625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.656875
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.656875
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.740625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.740625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.703125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.703125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.721875
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.721875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6913068181818182
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6435416666666667
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6744485294117647
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6649431818181819
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.596875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6409191176470589
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.678125
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6202083333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6576838235294118
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.910625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9093750000000002
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9068750000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9068750000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9093750000000002
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7181250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43562500000000004
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.576875
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6006250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.468125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.534375
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.659375
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.451875
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.555625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8181250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.859375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6681250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.784375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.743125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8218750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.690625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8031250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7468750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7181250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.606875
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7043750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6493750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.676875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5906250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7243750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7531250000000002
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.44062500000000004
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.596875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8056250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.515625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.660625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.904375
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8806250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8406250000000002
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8606250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8906250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8743750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8825000000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731250000000002
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9118750000000002
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9118750000000002
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.883125
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.883125
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.899375
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.899375
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8756250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8756250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.863125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.863125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.869375
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.869375
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8578977272727273
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.744375
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8178308823529412
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8292613636363636
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.636875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.761360294117647
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8435795454545455
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.690625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7895955882352942
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8906250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.889375
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8718750000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.888125
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731250000000002
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8806250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7981250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.570625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6843750000000002
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.748125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5381250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6431250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.773125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5543750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6637500000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8706250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8081250000000002
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8393750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.728125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8031250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8743750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7681250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.82125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.650625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8306250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.740625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.743125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6006250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.671875
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.696875
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7156250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.70625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.810625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7531250000000002
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.781875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7456250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5381250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6418750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7781250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.645625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.711875
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8556250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.765625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.810625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.866875
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8093750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8381250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8081250000000002
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8081250000000002
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.813125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.813125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.810625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.810625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.878125
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8718750000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8718750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8606250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8606250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8231250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8231250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8418750000000002
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8418750000000002
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506250000000001
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8315340909090909
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7839583333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8147426470588237
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8222159090909091
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6714583333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7690073529411765
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.826875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7277083333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.791875
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.420625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43062500000000004
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42562500000000003
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42812500000000003
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42562500000000003
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.426875
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42437500000000006
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42812500000000003
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.420625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41937500000000005
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.420625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43062500000000004
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42562500000000003
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.420625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42437500000000006
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4225
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.416875
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43562500000000004
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42562500000000003
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43062500000000004
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.426875
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.420625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42375000000000007
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46062500000000006
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.438125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.458125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.420625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43937500000000007
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.459375
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43875
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43062500000000004
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42437500000000006
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.423125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.420625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.421875
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.420625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42562500000000003
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.423125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48812500000000003
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48812500000000003
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.448125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.448125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45562500000000006
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45562500000000006
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.451875
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.451875
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.416875
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.416875
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.416875
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.416875
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.423125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.423125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42812500000000003
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42812500000000003
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42562500000000003
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42562500000000003
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43357954545454547
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42104166666666665
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4291544117647059
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43517045454545455
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.423125
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4309191176470588
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43437500000000007
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.42208333333333337
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43003676470588237
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.898125
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.904375
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43562500000000004
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.535625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5381250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.468125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.586875
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.451875
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.519375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8181250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.859375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.883125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7693750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8918750000000002
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7368750000000002
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.814375
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.800625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.728125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6731250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.583125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.664375
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.646875
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.845625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5481250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.696875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.710625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.438125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.574375
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7781250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.635625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.898125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9018750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731250000000002
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.828125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.889375
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.863125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8762500000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731250000000002
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731250000000002
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8618750000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8618750000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.833125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.833125
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.845625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.845625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9131250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9131250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9093750000000002
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9093750000000002
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9131250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9131250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.899375
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.899375
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8606250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8606250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.845625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.845625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8422159090909092
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7347916666666667
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8043014705882353
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8088068181818183
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6318750000000001
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7463602941176471
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8255113636363637
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6833333333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7753308823529411
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9068750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.733125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.43562500000000004
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.584375
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.608125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47062500000000007
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.539375
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.670625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.453125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.561875
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8231250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.863125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6656250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.783125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9018750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.744375
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8231250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.670625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8181250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.744375
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7256250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.609375
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.698125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.655625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.676875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.853125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5956250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7243750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.773125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.438125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.605625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.813125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5168750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.665
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.905625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9031250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8806250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.843125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8618750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8906250000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8743750000000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8825000000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.865625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8756250000000001
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8756250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8581250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8506250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.854375
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.854375
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9081250000000001
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9118750000000002
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9118750000000002
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.915625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.885625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.900625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8756250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8756250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8606250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8606250000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.868125
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8563068181818182
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7477083333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8179779411764707
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8328977272727273
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6364583333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7635661764705882
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8446022727272727
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6920833333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7907720588235294
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.416875
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.416875
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41812499999999997
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.416875
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.416875
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.415625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41585227272727276
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41604166666666664
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.41591911764705886
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4157386363636364
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4158333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4157720588235294
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8060416666666668
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8037500000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8048958333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.801875
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7993750000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.800625
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8039583333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8015625000000002
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8027604166666668
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6564583333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4491666666666667
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5528125
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5641666666666667
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4756250000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5198958333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6103125000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46239583333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5363541666666667
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7977083333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7229166666666668
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7603125000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7925000000000001
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7025
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7951041666666666
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6677083333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.73140625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6302083333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7216666666666667
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6759375
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6502083333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4910416666666667
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.570625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6402083333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6063541666666666
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.62328125
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7677083333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.566875
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6672916666666668
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4497916666666667
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5630208333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7219791666666667
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6151562500000001
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8045833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8010416666666668
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8028125000000002
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.78125
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666667
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7614583333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7929166666666667
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7713541666666667
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7821354166666666
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.793125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.793125
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666667
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7691666666666667
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7811458333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7811458333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7679166666666667
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7679166666666667
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7556250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7556250000000002
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7617708333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7617708333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8083333333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8083333333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8020833333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8020833333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8052083333333335
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8052083333333335
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8004166666666667
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8004166666666667
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7747916666666667
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7747916666666667
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7876041666666668
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7876041666666668
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7768750000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7768750000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7612500000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7612500000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7690625000000001
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7690625000000001
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7644886363636364
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6775694444444444
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7338112745098039
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7390151515151515
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5950000000000001
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.688186274509804
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.751751893939394
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6362847222222222
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.710998774509804
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8876822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8817447916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8847135416666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8870572916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8545572916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8708072916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8873697916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8681510416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8777604166666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6833072916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858072916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5845572916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6167447916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4986197916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5576822916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6500260416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49221354166666664
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5711197916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8492447916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6789322916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7640885416666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8326822916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6058072916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7192447916666668
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8409635416666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6423697916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7416666666666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5892447916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7711197916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6801822916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7420572916666668
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5514322916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6467447916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6656510416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6612760416666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6634635416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6945572916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6229947916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6587760416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7148697916666668
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864322916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6006510416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7047135416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5547135416666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6297135416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8570572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8548697916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8559635416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8364322916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7645572916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8004947916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8467447916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8097135416666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8282291666666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8770572916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8770572916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8689322916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8689322916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729947916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729947916666666
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7558072916666666
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7558072916666666
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7289322916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7289322916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7423697916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7423697916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8336197916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8336197916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8229947916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8229947916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8283072916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8283072916666666
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8951822916666666
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8951822916666666
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8279947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8279947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8615885416666668
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8615885416666668
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7979947916666666
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7979947916666666
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7636197916666666
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7636197916666666
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7808072916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7808072916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7927959280303031
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7159114583333335
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7656602328431373
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7856652462121213
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6269010416666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7296308210784314
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7892305871212121
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.67140625
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7476455269607843
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8267447916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8108072916666668
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8187760416666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8208072916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7820572916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8014322916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8237760416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7964322916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8101041666666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6308072916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47768229166666665
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5542447916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5492447916666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49174479166666674
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5204947916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5900260416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4847135416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5373697916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7042447916666668
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5501822916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6272135416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6898697916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5236197916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6067447916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6970572916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5369010416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6169791666666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6583072916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6798697916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6690885416666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6745572916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5239322916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5992447916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6664322916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6019010416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6341666666666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6873697916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5623697916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6248697916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6429947916666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4836197916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5633072916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6651822916666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5229947916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5940885416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7745572916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7851822916666668
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7798697916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7373697916666668
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6817447916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7095572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7559635416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7334635416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7447135416666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8198697916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8198697916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7873697916666668
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7873697916666668
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8036197916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8036197916666666
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6642447916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6642447916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6448697916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6448697916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6545572916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6545572916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6961197916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6961197916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6989322916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6989322916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6975260416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6975260416666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7692447916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7692447916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7154947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7154947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7423697916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7423697916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6748697916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6748697916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6464322916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6464322916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6606510416666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6606510416666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7187618371212121
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6443489583333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6924984681372549
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6916311553030303
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5811197916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6526271446078432
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7051964962121212
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.612734375
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6725628063725491
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8786197916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8633072916666668
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8709635416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8733072916666668
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8411197916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8572135416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8759635416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8522135416666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8640885416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6695572916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48330729166666664
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5764322916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5898697916666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001822916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5450260416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6297135416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49174479166666674
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5607291666666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8192447916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6486197916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7339322916666668
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8033072916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5883072916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6958072916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8112760416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6184635416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7148697916666668
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6117447916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7464322916666668
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6790885416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7198697916666668
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5417447916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6308072916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6658072916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6440885416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6549479166666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6939322916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6011197916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6475260416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6961197916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48393229166666674
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5900260416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6950260416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5425260416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6187760416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8408072916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8373697916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8390885416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8145572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7426822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7786197916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8276822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7900260416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8088541666666668
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8664322916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8664322916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8495572916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8495572916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8579947916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8579947916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7295572916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7295572916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7083072916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7083072916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7189322916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7189322916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8011197916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8011197916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7951822916666668
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7951822916666668
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7981510416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7981510416666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8811197916666668
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8811197916666668
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8045572916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8045572916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8428385416666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8428385416666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7708072916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7708072916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7376822916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7376822916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7542447916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7542447916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7784493371212121
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6966927083333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7495940563725491
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7629379734848485
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.616328125
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7111933210784314
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7706936553030302
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6565104166666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7303936887254903
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8808072916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8579947916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8694010416666668
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8748697916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8367447916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8558072916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8778385416666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8473697916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8626041666666668
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6576822916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48486979166666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5712760416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5836197916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49955729166666674
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5415885416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6206510416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49221354166666664
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5564322916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8101822916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6323697916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7212760416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7858072916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5748697916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6803385416666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7979947916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6036197916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7008072916666668
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5986197916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7339322916666668
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6662760416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7145572916666668
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5398697916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6272135416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6565885416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6369010416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6467447916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6851822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5867447916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6359635416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6892447916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4817447916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5854947916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6872135416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5342447916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6107291666666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8264322916666668
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8208072916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8236197916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7995572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7276822916666668
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7636197916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8129947916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7742447916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7936197916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8639322916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8639322916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8476822916666668
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8476822916666668
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8558072916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8558072916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7258072916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7258072916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7039322916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7039322916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7148697916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7148697916666668
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7801822916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7801822916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7854947916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7854947916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7828385416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7828385416666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8754947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8754947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8086197916666668
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8086197916666668
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8420572916666668
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8420572916666668
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7617447916666668
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7617447916666668
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7311197916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7311197916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7464322916666668
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7464322916666668
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.769642518939394
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6861197916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7401639093137254
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7567732007575758
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.610078125
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7049984681372549
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7632078598484849
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6480989583333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7225811887254903
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8876822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8779947916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8828385416666668
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8851822916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8514322916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8683072916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8864322916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8647135416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8755729166666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6776822916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48549479166666665
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5815885416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6120572916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49893229166666664
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5554947916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6448697916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49221354166666664
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5685416666666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8423697916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6708072916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7565885416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8279947916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5998697916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7139322916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8351822916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6353385416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7352604166666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5901822916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7639322916666668
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6770572916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7348697916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5489322916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6419010416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6625260416666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6564322916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6594791666666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6920572916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6179947916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6550260416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7092447916666668
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48674479166666673
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5979947916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7006510416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5523697916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6265104166666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8533072916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8517447916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8525260416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8295572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7595572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7945572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8414322916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8056510416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8235416666666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8742447916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8742447916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8654947916666668
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8654947916666668
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8698697916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8698697916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7508072916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7508072916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7242447916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7242447916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7375260416666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7375260416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8245572916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8245572916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8148697916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8148697916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8197135416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8197135416666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8904947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8904947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8251822916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8251822916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8578385416666666
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8578385416666666
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7917447916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7917447916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7595572916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7595572916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7756510416666668
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7756510416666668
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7886482007575759
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7113281250000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.761358762254902
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7807504734848485
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6242447916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7255131740196078
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7846993371212122
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6677864583333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.743435968137255
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6129947916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5936197916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6033072916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6167447916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6001822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6084635416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6148697916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5969010416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6058854166666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6179947916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5689322916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5934635416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5589322916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5733072916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5661197916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5884635416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5711197916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5797916666666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7061197916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6698697916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6879947916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6889322916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6473697916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6681510416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6975260416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6586197916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6780729166666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5976822916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6317447916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6147135416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5751822916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5276822916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5514322916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5864322916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5797135416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5830729166666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6292447916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5773697916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6033072916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5595572916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5167447916666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5381510416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5944010416666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5470572916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5707291666666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6789322916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6433072916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6611197916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6470572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6073697916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6272135416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6629947916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6253385416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6441666666666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7598697916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7598697916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7498697916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7498697916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7548697916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7548697916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6192447916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6192447916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6073697916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6073697916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6133072916666666
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6133072916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6523697916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6523697916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6295572916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6295572916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6409635416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6409635416666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6539322916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6539322916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6079947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6079947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6309635416666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6309635416666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6498697916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6498697916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6379947916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6379947916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6439322916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6439322916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6525686553030303
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.614140625
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6390058210784314
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6253811553030303
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5787760416666666
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6089322916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6389749053030304
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5964583333333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6239690563725491
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8892447916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8776822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8834635416666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8911197916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8536197916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8723697916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8901822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8656510416666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8779166666666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6942447916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858072916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5900260416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6129947916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49893229166666664
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5559635416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6536197916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4923697916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5729947916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8592447916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6767447916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7679947916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8414322916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6048697916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7231510416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8503385416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6408072916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7455729166666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6214322916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7729947916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6972135416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7383072916666669
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5489322916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6436197916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6798697916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6609635416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6704166666666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7083072916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6136197916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6609635416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7129947916666668
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48705729166666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6000260416666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7106510416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5503385416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6304947916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8661197916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8570572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8615885416666668
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8461197916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7648697916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8054947916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8561197916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8109635416666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8335416666666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8783072916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8783072916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8679947916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8679947916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731510416666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8731510416666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7558072916666666
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7558072916666666
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7292447916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7292447916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7425260416666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7425260416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8417447916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8417447916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8317447916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8317447916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8367447916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8367447916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9054947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.9054947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8317447916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8317447916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8686197916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8686197916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7989322916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7989322916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7689322916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7689322916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7839322916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7839322916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8017163825757576
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.713984375
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7707521446078431
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7884209280303031
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6263802083333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7312300857843138
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7950686553030303
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6701822916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7509911151960785
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8233072916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8267447916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8250260416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8336197916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8123697916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8229947916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8284635416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8195572916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8240104166666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6908072916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5345572916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6126822916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6873697916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5276822916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6075260416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6890885416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5311197916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6101041666666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8301822916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7420572916666668
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7861197916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8217447916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6933072916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7575260416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8259635416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7176822916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7718229166666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5792447916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8217447916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7004947916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7470572916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6379947916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6925260416666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6631510416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7298697916666668
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6965104166666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6770572916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6711197916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6740885416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6767447916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5426822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6097135416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6769010416666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6069010416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6419010416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8283072916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8111197916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8197135416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8123697916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7501822916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7812760416666668
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8203385416666668
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7806510416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8004947916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8511197916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8511197916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8461197916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8461197916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8486197916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8486197916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7592447916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7592447916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7383072916666669
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7383072916666669
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7487760416666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7487760416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8336197916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8336197916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8161197916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8161197916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8248697916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8248697916666666
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8464322916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8464322916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7729947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7729947916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8097135416666666
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8097135416666666
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7845572916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7845572916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7748697916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7748697916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7797135416666666
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7797135416666666
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7730800189393939
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7345572916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.759483762254902
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7752107007575759
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6607031250000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7347962622549019
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7741453598484849
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6976302083333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.747140012254902
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4645572916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46643229166666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46549479166666663
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4645572916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4658072916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4651822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4645572916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4661197916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46533854166666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48674479166666673
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45768229166666663
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47221354166666674
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47143229166666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4658072916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4686197916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4790885416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4617447916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4704166666666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45924479166666665
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4567447916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4579947916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4589322916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45768229166666663
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4583072916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4590885416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4572135416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45815104166666665
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4842447916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895572916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4869010416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49611979166666664
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4686197916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4823697916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4901822916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4790885416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48463541666666665
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5076822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47893229166666673
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49330729166666665
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5042447916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4595572916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4819010416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5059635416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46924479166666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4876041666666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4629947916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46330729166666673
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46315104166666665
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4651822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4608072916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4629947916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4640885416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46205729166666665
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46307291666666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5401822916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5401822916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5379947916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5379947916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5390885416666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5390885416666666
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48986979166666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48986979166666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48268229166666665
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48268229166666665
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4862760416666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4862760416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45580729166666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45580729166666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45549479166666673
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45549479166666673
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4556510416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4556510416666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4561197916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4561197916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4583072916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4583072916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4572135416666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4572135416666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46830729166666674
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46830729166666674
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4695572916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4695572916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4689322916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4689322916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47961410984848485
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46877604166666664
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4757889093137255
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4785913825757576
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46304687499999997
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47310508578431376
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47910274621212123
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.46591145833333336
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47444699754901964
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8758072916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8701822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8729947916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8792447916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8439322916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8615885416666668
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8775260416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8570572916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8672916666666668
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6420572916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858072916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5639322916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5795572916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4986197916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5390885416666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6108072916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49221354166666664
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5515104166666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8039322916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6492447916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7265885416666668
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7779947916666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5879947916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6829947916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7909635416666666
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6186197916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7047916666666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5895572916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7479947916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6687760416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7079947916666668
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5464322916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6272135416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6487760416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6472135416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6479947916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6695572916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6067447916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6381510416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6861197916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858072916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5859635416666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6778385416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5462760416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6120572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8295572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8404947916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8350260416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8036197916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7414322916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7725260416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8165885416666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7909635416666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8037760416666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8583072916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8583072916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8470572916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8470572916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8526822916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8526822916666666
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7261197916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7261197916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7029947916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7029947916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7145572916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7145572916666668
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7829947916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7829947916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7773697916666668
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7773697916666668
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7801822916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7801822916666666
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8620572916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8620572916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7986197916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7986197916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8303385416666668
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8303385416666668
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7620572916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7620572916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7311197916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7311197916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7465885416666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7465885416666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7638186553030303
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7000781250000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7413219975490197
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7537902462121212
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6173697916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7056418504901961
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7588044507575759
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6587239583333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7234819240196079
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8854947916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8773697916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8814322916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8851822916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8517447916666666
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8684635416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8853385416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8645572916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8749479166666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6808072916666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48486979166666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5828385416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6120572916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4986197916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5553385416666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6464322916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49174479166666674
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5690885416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8458072916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6751822916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7604947916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8276822916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6014322916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7145572916666668
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8367447916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6383072916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7375260416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5892447916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7679947916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6786197916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7389322916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5508072916666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6448697916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6640885416666666
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6594010416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6617447916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6929947916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6173697916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6551822916666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7095572916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864322916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5979947916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7012760416666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5519010416666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6265885416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8533072916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8508072916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8520572916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8326822916666666
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7626822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7976822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8429947916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8067447916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8248697916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8736197916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8736197916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8651822916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8651822916666666
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8694010416666668
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8694010416666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7520572916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7520572916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7251822916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7251822916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7386197916666668
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7386197916666668
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8292447916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8292447916666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8173697916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8173697916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8233072916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8233072916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8923697916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8923697916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8220572916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8220572916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8572135416666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.8572135416666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7929947916666668
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7929947916666668
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7592447916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7592447916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7761197916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7761197916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7898129734848486
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7122656250000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7624433210784314
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7813754734848485
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6252864583333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7262852328431373
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7855942234848484
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6687760416666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7443642769607843
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45580729166666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45549479166666673
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4573697916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4562760416666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45658854166666674
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45588541666666665
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4561197916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4556510416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4561197916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4556510416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4561197916666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4556510416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45549479166666673
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45705729166666664
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4562760416666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45533854166666665
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4561197916666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45572916666666663
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45549479166666673
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45533854166666665
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45533854166666665
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45526041666666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45549479166666673
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45549479166666673
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45533854166666665
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45533854166666665
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4551822916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45544270833333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4552742034313726
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4552391098484848
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4560677083333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45553155637254905
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.45521070075757575
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4557552083333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4554028799019608
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7806770833333333
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7715885416666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7761328125000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7805729166666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7540625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7673177083333333
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.780625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7628255208333333
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7717252604166667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6322395833333333
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49088541666666663
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5615625000000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.577421875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5391015625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6048307291666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5503320312500001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.74875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6255729166666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6871614583333333
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.734296875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5784375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6563671875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7415234375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6020052083333334
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6717643229166667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.580390625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6985416666666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6394661458333334
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6704166666666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.536953125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6036848958333333
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6254036458333333
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6177473958333334
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6215755208333333
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6494270833333333
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.584296875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6168619791666666
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.64640625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4879947916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5672005208333334
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6479166666666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5361458333333333
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.59203125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7605468750000001
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7559375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7582421874999999
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7399739583333333
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.684921875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7124479166666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7502604166666668
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7204296875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7353450520833335
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7931770833333334
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7931770833333334
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7823958333333333
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7823958333333333
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7877864583333333
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7877864583333333
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6819791666666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6819791666666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6626041666666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6626041666666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6722916666666666
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6722916666666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7322135416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7322135416666667
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7250260416666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7250260416666666
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7286197916666668
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7286197916666668
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7819270833333333
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7819270833333333
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7273958333333334
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7273958333333334
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7546614583333335
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7546614583333335
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7090885416666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7090885416666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6862760416666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6862760416666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6976822916666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6976822916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7136742424242425
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6544704861111111
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6927787990196078
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7029805871212123
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5905251736111111
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6632904411764706
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.7083274147727273
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6224978298611111
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.6780346200980393
    }
  ],
  "thresholds": {
    "0.05": {
      "abstracts": 2.1420420992512845e-10,
      "books": 0.9999999999720603,
      "news": 0.9999999997764826,
      "poetry": 0.005,
      "recipes": 0.9999999999860303,
      "reddit": 0.005,
      "reviews": 0.9999999999906868,
      "wiki": 0.9999999999487772
    },
    "0.01": {
      "abstracts": 0.9999999999813736,
      "books": 0.9999999999720603,
      "news": 0.9999999997764826,
      "poetry": 0.005,
      "recipes": 0.9999999999860303,
      "reddit": 0.005,
      "reviews": 0.9999999999906868,
      "wiki": 0.9999999999487772
    }
  },
  "fpr": {
    "0.05": {
      "abstracts": 0.020000000000000018,
      "books": 0.15500000000000003,
      "news": 0.11499999999999999,
      "poetry": 0.0050000000000000044,
      "recipes": 0.14,
      "reddit": 0.0050000000000000044,
      "reviews": 0.135,
      "wiki": 0.18000000000000005
    },
    "0.01": {
      "abstracts": 0.020000000000000018,
      "books": 0.15500000000000003,
      "news": 0.11499999999999999,
      "poetry": 0.0050000000000000044,
      "recipes": 0.14,
      "reddit": 0.0050000000000000044,
      "reviews": 0.135,
      "wiki": 0.18000000000000005
    }
  }
}