{
  "_autogen_note": "This file is automatically generated by the RAID leaderboard submission script. Do not edit this file manually or include it in new submissions' PRs.",
  "_submission_hash": "d601946f6543ece46144f798d4ace2cb43ba75a53d8c2a41c902eb7ac7b076f5",
  "_results_hash": "494f3ba0325c67593a00a03b35dc5cf789a191147ec2d85070e3225b86ff406b",
  "date_released": "2025-05-17",
  "detector_name": "Gaussian Extreme",
  "contact_info": "k.boenisch@outlook.com",
  "website": "https://www.texttechnologylab.org/",
  "paper_link": "",
  "huggingface_link": "",
  "github_link": "https://github.com/TheItCrOw/PrismAI",
  "additional_metadata": null,
  "score_agg": {
    "all": {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005147058823529
    },
    "no_adversarial": {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003860294117648
    }
  },
  "scores": [
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.483125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015340909090908
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010661764705882
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008522727272727
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011931818181818
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008455882352941
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.480625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.489375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.483125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.483125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4965340909090909
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49724264705882354
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013068181818181
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016544117647058
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49892045454545453
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4994485294117647
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5026838235294118
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016544117647058
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037499999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019886363636363
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501360294117647
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49880681818181816
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003308823529412
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003977272727274
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008455882352941
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022159090909091
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010661764705882
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003977272727274
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010661764705882
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013068181818181
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010661764705882
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5075
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017613636363636
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.502389705882353
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4999431818181818
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995955882352941
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008522727272727
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009926470588235
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003977272727274
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003308823529412
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.502389705882353
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005113636363636
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501360294117647
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017613636363636
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5026838235294118
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019886363636363
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004779411764706
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015808823529412
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037499999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.515625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.515625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010795454545455
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501360294117647
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5044886363636364
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5044485294117648
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027840909090909
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029044117647059
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.515625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015340909090908
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020955882352941
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5026704545454546
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022426470588236
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021022727272727
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021691176470588
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990340909090909
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000367647058823
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019886363636363
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016544117647058
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005113636363636
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008455882352941
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033522727272727
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018014705882353
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035795454545454
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018014705882353
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503465909090909
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018014705882353
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333334
    },
    {
      "domain": "abstracts",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49942708333333335
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666667
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019791666666666
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015104166666666
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5026041666666667
    },
    {
      "domain": "abstracts",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028645833333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007291666666667
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49885416666666665
    },
    {
      "domain": "abstracts",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002604166666667
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333334
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5054166666666666
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5038541666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5038541666666667
    },
    {
      "domain": "abstracts",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022395833333334
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "abstracts",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007291666666667
    },
    {
      "domain": "abstracts",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007291666666667
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037499999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037499999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375
    },
    {
      "domain": "abstracts",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "abstracts",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009848484848485
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010049019607843
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016477272727272
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015808823529412
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013162878787879
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "abstracts",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012928921568627
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4820833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49685606060606063
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49752450980392154
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498219696969697
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975378787878788
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49730392156862746
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49481060606060606
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4956127450980392
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49390151515151515
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4950245098039216
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49435606060606063
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4953186274509804
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4820833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4820833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49799242424242424
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989950980392157
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952651515151515
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4964950980392157
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49662878787878795
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977450980392157
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4820833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49799242424242424
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49375
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4964950980392157
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975378787878788
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4966421568627451
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977651515151515
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4965686274509804
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498219696969697
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49855392156862743
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975378787878788
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49541666666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4967892156862745
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49787878787878787
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.497671568627451
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49481060606060606
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4959469696969697
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4967892156862745
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49537878787878786
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49693627450980393
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4820833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47958333333333336
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498219696969697
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49855392156862743
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4976515151515152
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978186274509804
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47708333333333336
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495719696969697
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49291666666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49473039215686276
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49662878787878795
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978186274509804
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4961742424242424
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49627450980392157
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4984469696969697
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49855392156862743
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49799242424242424
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979656862745098
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498219696969697
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49825980392156866
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49799242424242424
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4981127450980392
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004924242424242
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013480392156863
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49924242424242427
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49973039215686277
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47958333333333336
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4986742424242424
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49723039215686277
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4936742424242424
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4953186274509804
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4961742424242424
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49627450980392157
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49799242424242424
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4981127450980392
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500719696969697
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4966666666666667
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4992892156862745
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49935606060606064
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4987009803921569
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49541666666666667
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49635416666666665
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49625
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "books",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49703125
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4960416666666667
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49635416666666665
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4959375
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "books",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49661458333333336
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4966666666666667
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49614583333333334
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49625
    },
    {
      "domain": "books",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49703125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49635416666666665
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4984375
    },
    {
      "domain": "books",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4973958333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998958333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4984375
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49822916666666667
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "books",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4973958333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "books",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49713541666666666
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "books",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4969791666666667
    },
    {
      "domain": "books",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4969791666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4976041666666667
    },
    {
      "domain": "books",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4976041666666667
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49677083333333333
    },
    {
      "domain": "books",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49677083333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49731060606060606
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49774305555555554
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4974632352941176
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49730392156862746
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971969696969697
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977256944444444
    },
    {
      "domain": "books",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49738357843137254
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.485625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.486875
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4994886363636364
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009191176470589
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4999431818181818
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000367647058823
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49971590909090907
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004779411764706
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035795454545454
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028308823529412
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015340909090908
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016544117647058
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025568181818182
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022426470588236
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022159090909091
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5047916666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001838235294118
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014204545454545
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016544117647058
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49971590909090907
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333334
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4994485294117647
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001704545454546
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000367647058823
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022159090909091
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022426470588236
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008522727272727
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995955882352941
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015340909090908
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009191176470589
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.485625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.485625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019485294117647
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49880681818181816
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995955882352941
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49971590909090907
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007720588235295
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978977272727273
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000367647058823
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5047916666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037132352941176
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005113636363636
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037499999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.489375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4925
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49721590909090907
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49724264705882354
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019886363636363
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018014705882353
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996022727272727
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995220588235294
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5118750000000001
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4999431818181818
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5047916666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016544117647058
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028977272727273
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029779411764705
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014204545454545
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023161764705882
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5118750000000001
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.509375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.470625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.470625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.486875
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.486875
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001704545454546
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012132352941177
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015340909090908
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020955882352941
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008522727272727
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016544117647058
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037499999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.488125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5131249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015340909090908
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025367647058824
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5026704545454546
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020955882352941
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021022727272727
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023161764705882
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037499999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.510625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.508125
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.485625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.490625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.495625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49312500000000004
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49880681818181816
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49988970588235293
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017613636363636
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019485294117647
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500284090909091
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009191176470589
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023958333333334
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5026041666666667
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "news",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50234375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011458333333333
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666667
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "news",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5032291666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023958333333334
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "news",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50265625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019791666666666
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666667
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017708333333333
    },
    {
      "domain": "news",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013020833333333
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "news",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008854166666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666667
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49802083333333336
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "news",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333334
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333334
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "news",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "news",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031249999999999
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5032291666666666
    },
    {
      "domain": "news",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5032291666666666
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49666666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49666666666666665
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333334
    },
    {
      "domain": "news",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333334
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003598484848485
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501188725490196
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012878787878787
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012152777777779
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012622549019607
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008238636363637
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019618055555555
    },
    {
      "domain": "news",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012254901960784
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4839583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48770833333333335
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4991856060606061
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49354166666666666
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971936274509804
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007765151515151
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011642156862745
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4999810606060606
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4991789215686275
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49020833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4839583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4839583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4839583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4839583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996401515151515
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004289215686274
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49782196969696973
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4985171568627451
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49873106060606065
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4994730392156863
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49020833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028219696969697
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010171568627452
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010037878787879
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49939950980392156
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019128787878788
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016856060606061
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018995098039215
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025946969696969
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017524509803921
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021401515151515
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012500000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018259803921569
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010037878787879
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004289215686274
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.497594696969697
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49763480392156867
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49929924242424245
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49903186274509803
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4839583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48770833333333335
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971401515151515
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49778186274509806
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007765151515151
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002818627450981
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4991666666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49903186274509803
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010037878787879
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008700980392158
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971401515151515
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4991053921568628
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990719696969697
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4999877450980392
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4839583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49020833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4839583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49827651515151516
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4982230392156863
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4994128787878788
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49925245098039217
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49884469696969697
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49873774509803925
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49020833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.497594696969697
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500094696969697
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002818627450981
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49884469696969697
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996200980392157
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49270833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49623106060606065
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49792892156862745
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4980492424242424
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49939950980392156
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971401515151515
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4986642156862745
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005492424242424
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4947916666666667
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4985171568627451
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500094696969697
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007230392156863
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003219696969697
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996200980392157
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4986642156862745
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025946969696969
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5032230392156862
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007765151515151
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012500000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009436274509804
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666667
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007291666666667
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "poetry",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008854166666666
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666667
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4994791666666667
    },
    {
      "domain": "poetry",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666667
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49687499999999996
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49822916666666667
    },
    {
      "domain": "poetry",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49859375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012500000000001
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "poetry",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666667
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011458333333333
    },
    {
      "domain": "poetry",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002604166666668
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "poetry",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49802083333333336
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011458333333333
    },
    {
      "domain": "poetry",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011458333333333
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "poetry",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998958333333334
    },
    {
      "domain": "poetry",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998958333333334
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012500000000001
    },
    {
      "domain": "poetry",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012500000000001
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49950757575757576
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49899305555555556
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49932598039215687
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998295454545455
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004861111111112
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500061274509804
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49966856060606063
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49973958333333335
    },
    {
      "domain": "poetry",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996936274509804
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5152083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48520833333333335
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48895833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4877083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4877083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.502935606060606
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028553921568627
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017992424242423
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034436274509804
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023674242424243
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031495098039216
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5047537878787879
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041789215686274
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035906862745099
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037310606060607
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5038848039215686
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017992424242423
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5024142156862744
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015719696969697
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501531862745098
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501685606060606
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019730392156863
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5177083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5139583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5054356060606061
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5047671568627451
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5054356060606061
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5046200980392157
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5054356060606061
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5046936274509803
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4877083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5054356060606061
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5047671568627451
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041789215686274
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5053219696969696
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5044730392156863
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48520833333333335
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4877083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49903186274509803
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.502935606060606
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034436274509804
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015719696969697
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012377450980392
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5177083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5152083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5152083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5054356060606061
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5044730392156863
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501344696969697
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49729166666666663
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4999142156862745
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033901515151514
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021936274509804
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48520833333333335
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5177083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4877083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4877083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017992424242423
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034436274509804
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017992424242423
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017992424242423
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5054166666666666
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030759803921568
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48270833333333335
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49145833333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5024810606060606
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030024509803922
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997537878787879
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009436274509804
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011174242424242
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019730392156863
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48520833333333335
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4877083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4864583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5152083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4877083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49395833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49793560606060605
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4999142156862745
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501875
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500796568627451
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990719696969697
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003553921568628
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5177083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5152083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5152083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5040719696969698
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5047916666666666
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5043259803921569
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020265151515151
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030492424242424
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503517156862745
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5127083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5089583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4927083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5102083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5077083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4902083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4952083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5177083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5177083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5114583333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5047537878787879
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5038848039215686
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5049810606060605
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501875
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5038848039215686
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5048674242424243
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5038848039215686
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037499999999999
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007291666666667
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019791666666666
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501875
    },
    {
      "domain": "recipes",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019270833333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5036458333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5036458333333333
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375
    },
    {
      "domain": "recipes",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030208333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.506875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501875
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5057291666666667
    },
    {
      "domain": "recipes",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5038020833333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5032291666666667
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501875
    },
    {
      "domain": "recipes",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50234375
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5047916666666666
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023958333333334
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037499999999999
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5026041666666666
    },
    {
      "domain": "recipes",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030729166666666
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5037499999999999
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666667
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501875
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030208333333334
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5026041666666666
    },
    {
      "domain": "recipes",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "recipes",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "recipes",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666667
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666667
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "recipes",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375
    },
    {
      "domain": "recipes",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030871212121212
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030902777777778
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030882352941176
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5024810606060606
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029513888888889
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5026470588235294
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027840909090908
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030208333333334
    },
    {
      "domain": "recipes",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028676470588235
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49520833333333336
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002651515151515
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49973039215686277
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500719696969697
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010539215686275
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004924242424242
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003921568627451
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018560606060606
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006127450980392
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4966287878787879
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49375
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4956127450980392
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49924242424242427
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49604166666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4981127450980392
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49981060606060607
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004656862745098
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014015151515152
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012009803921569
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006060606060606
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5145833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47958333333333336
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47958333333333336
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4991287878787879
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000245098039215
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004924242424242
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49973039215686277
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49981060606060607
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49987745098039216
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009469696969697
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007598039215686
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000378787878789
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004656862745098
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004924242424242
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006127450980392
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002651515151515
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004656862745098
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000378787878789
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4992892156862745
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001515151515151
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49987745098039216
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039015151515152
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016421568627452
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49685606060606063
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003787878787879
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49936274509803924
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498219696969697
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000245098039215
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000378787878789
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4992892156862745
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4991287878787879
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499656862745098
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014015151515152
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019362745098039
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014015151515152
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010539215686275
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014015151515152
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014950980392158
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4984469696969697
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4992892156862745
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49799242424242424
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49987745098039216
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498219696969697
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011742424242424
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49987745098039216
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011742424242424
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003186274509803
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011742424242424
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000980392156863
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014015151515152
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017892156862744
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000378787878789
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007598039215686
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500719696969697
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012745098039215
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333333
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "reddit",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011458333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011458333333334
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "reddit",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4994791666666667
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333334
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998958333333333
    },
    {
      "domain": "reddit",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007291666666667
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498125
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49927083333333333
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "reddit",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49994791666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998958333333333
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "reddit",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5035416666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013541666666667
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4984375
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reddit",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998958333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49885416666666665
    },
    {
      "domain": "reddit",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49885416666666665
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "reddit",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "reddit",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49864583333333334
    },
    {
      "domain": "reddit",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49864583333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005681818181817
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333334
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005514705882352
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997348484848485
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4994791666666667
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49964460784313725
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001515151515151
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "reddit",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000980392156863
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021969696969697
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018627450980392
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4981060606060606
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49862745098039213
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001515151515151
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002450980392157
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4883333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4977083333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501060606060606
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011274509803921
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4981060606060606
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000980392156863
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006127450980392
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015151515151515
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5024509803921569
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49856060606060604
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499656862745098
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000378787878788
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010539215686275
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4883333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011274509803921
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001515151515151
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49624999999999997
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4987745098039216
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004924242424242
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49995098039215685
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4883333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006060606060606
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49666666666666665
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4992156862745098
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012878787878787
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021568627450981
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009469696969697
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006862745098039
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4883333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4883333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666666
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998039215686274
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503560606060606
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028921568627451
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021969696969697
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49979166666666663
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013480392156863
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5026515151515152
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017156862745098
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504469696969697
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503560606060606
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025245098039215
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4883333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4883333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4858333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49789215686274507
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5049242424242424
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031862745098039
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003787878787879
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005392156862745
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4883333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4833333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003787878787879
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014215686274509
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012878787878787
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011274509803921
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012745098039215
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4987878787878788
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49906862745098035
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012745098039215
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499810606060606
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001715686274509
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.47833333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5133333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4883333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504469696969697
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5030392156862745
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501060606060606
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018627450980392
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027651515151514
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501875
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5024509803921569
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4883333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4908333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4933333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4958333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5031060606060606
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4983333333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014215686274509
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501969696969697
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50625
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034803921568627
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025378787878788
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5024509803921569
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "reviews",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501875
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49874999999999997
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998958333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49895833333333334
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333333
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49885416666666665
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015624999999999
    },
    {
      "domain": "reviews",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017708333333334
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015624999999999
    },
    {
      "domain": "reviews",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5022916666666667
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017708333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023958333333334
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019791666666666
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021874999999999
    },
    {
      "domain": "reviews",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49906249999999996
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49937499999999996
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49979166666666663
    },
    {
      "domain": "reviews",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49937499999999996
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666666
    },
    {
      "domain": "reviews",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003645833333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50625
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50625
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "reviews",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333333
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017708333333334
    },
    {
      "domain": "reviews",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017708333333334
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49854166666666666
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49979166666666663
    },
    {
      "domain": "reviews",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49979166666666663
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666666
    },
    {
      "domain": "reviews",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666666
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010227272727272
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333333
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500845588235294
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011931818181818
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017013888888889
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013725490196078
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011079545454545
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011111111111111
    },
    {
      "domain": "reviews",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501109068627451
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011742424242424
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500171568627451
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011742424242424
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028186274509804
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011742424242424
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014950980392158
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5108333333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5050378787878789
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028186274509804
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029656862745099
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503560606060606
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028921568627451
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5064583333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039015151515152
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5032598039215687
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009469696969697
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500906862745098
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5024242424242424
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49935606060606064
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49973039215686277
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49981060606060607
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003186274509803
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000245098039215
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49981060606060607
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013480392156863
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000378787878789
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014950980392158
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49992424242424244
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5041666666666667
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501421568627451
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5120833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49731060606060606
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49855392156862743
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4966287878787879
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49737745098039216
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49696969696969695
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979656862745098
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5052083333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49083333333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4845833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002651515151515
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49973039215686277
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004924242424242
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49987745098039216
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003787878787879
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49980392156862746
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5027083333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004924242424242
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006127450980392
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49935606060606064
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49973039215686277
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49992424242424244
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500171568627451
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48208333333333336
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.48833333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49935606060606064
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500171568627451
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4986742424242424
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49884803921568627
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990151515151515
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49950980392156863
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011742424242424
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012009803921569
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002651515151515
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49884803921568627
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500719696969697
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000245098039215
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4989583333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49981060606060607
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000245098039215
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002651515151515
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004656862745098
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000378787878789
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002450980392157
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4870833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49333333333333335
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49770833333333336
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4895833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49833333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49583333333333335
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5033333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5095833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5083333333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4920833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5070833333333333
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5058333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5045833333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004924242424242
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4945833333333333
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49840686274509804
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501628787878788
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010539215686275
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010606060606061
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4972916666666667
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49973039215686277
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4979166666666667
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49885416666666665
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "wiki",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49994791666666666
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5020833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014583333333333
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49916666666666665
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49645833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49802083333333336
    },
    {
      "domain": "wiki",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019791666666666
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016666666666666
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011458333333334
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007291666666667
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023958333333333
    },
    {
      "domain": "wiki",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666666
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007291666666667
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007291666666667
    },
    {
      "domain": "wiki",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5029166666666667
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017708333333334
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49666666666666665
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49822916666666667
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997916666666667
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "wiki",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004166666666666
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333334
    },
    {
      "domain": "wiki",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "wiki",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4995833333333333
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5039583333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017708333333334
    },
    {
      "domain": "wiki",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017708333333334
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "wiki",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4970833333333333
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49864583333333334
    },
    {
      "domain": "wiki",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49864583333333334
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006818181818181
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001736111111111
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005024509803921
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001136363636364
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009027777777778
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003921568627451
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003977272727274
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005381944444445
    },
    {
      "domain": "wiki",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004473039215687
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500859375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50203125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003906250000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49562500000000004
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49828125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49898437500000004
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49890625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5046875000000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5046875000000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004545454545455
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49963541666666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001654411764705
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001988636363637
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013541666666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006066176470588
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003267045454546
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004947916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "none",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003860294117648
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49765625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49890625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499140625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5046875000000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50328125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501328125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50203125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49796874999999996
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50265625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501796875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4965625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49671875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.498203125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50203125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50203125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500909090909091
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000520833333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006066176470588
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49926136363636364
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49988970588235293
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000852272727273
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005468750000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "whitespace",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002481617647059
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003906250000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49593750000000003
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49890625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023437500000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005468750000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5053124999999999
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50390625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5053124999999999
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023437500000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5053124999999999
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500234375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49890625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49890625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499140625
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5046875000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5046875000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50296875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50296875
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013352272727273
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019270833333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015441176470589
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002573529411765
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008238636363637
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "upper_lower",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009007352941176
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500234375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023437500000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49890625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49562500000000004
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49765625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49734375000000003
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49828125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50265625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50265625
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008806818181818
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007536764705883
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005681818181819
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500202205882353
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007244318181818
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000260416666666
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "synonym",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004779411764706
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023437500000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50265625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.502578125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50265625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501171875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500234375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49859375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5040625000000001
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50203125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500703125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5040625000000001
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5040625000000001
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5065625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5065625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50359375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50359375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4965625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4965625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013068181818182
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005729166666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501047794117647
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003693181818182
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500422794117647
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008380681818182
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005468750000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "perplexity_misspelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007352941176471
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.491875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4946875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49640625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49789062500000003
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4965625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49765625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499453125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023437500000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014843750000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49992187499999996
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499765625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500703125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49828125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49828125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49593750000000003
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49593750000000003
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4991193181818182
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005729166666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49963235294117647
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49982954545454544
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000520833333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49990808823529415
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49947443181818185
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "paraphrase",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997702205882353
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499765625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49890625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003906250000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50359375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50296875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501640625
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012215909090909
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003645833333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009191176470588
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001420454545455
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006818181818181
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004947916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "number",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006158088235294
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49859375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003906250000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50203125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014843750000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49593750000000003
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49796874999999996
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49765625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49859375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49796874999999996
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50328125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49593750000000003
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49671875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50265625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50265625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49703125000000004
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49703125000000004
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4986647727272727
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49935661764705885
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007670454545455
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005330882352942
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4997159090909091
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003645833333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "insert_paragraphs",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49994485294117647
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500703125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.496875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49890625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501171875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50328125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499453125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5053124999999999
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50296875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500234375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50203125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50203125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50359375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50359375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000852272727273
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023437500000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008823529411766
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008238636363637
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011979166666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009558823529412
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004545454545455
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5017708333333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "homoglyph",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009191176470588
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49890625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49929687500000003
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5053124999999999
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50265625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5053124999999999
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50296875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023437500000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49859375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499609375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.494375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49609375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49609375
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990340909090909
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5013541666666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998529411764706
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002556818181818
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016145833333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007352941176471
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49964488636363635
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014843750000001
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "article_deletion",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002941176470588
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50171875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4978125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005468750000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49562500000000004
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49796874999999996
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49859375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49992187499999996
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50203125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.505625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50359375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50203125
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50359375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49953125000000004
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49992187499999996
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4971875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011647727272728
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006985294117647
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003693181818182
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011458333333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006433823529411
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007670454545455
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004947916666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "alternative_spelling",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006709558823529
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990625
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5014062499999999
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005468750000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4965625
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5046875000000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5028125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49921875
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500859375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.503125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023437500000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4975
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49843750000000003
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50046875
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001562500000001
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50296875
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5025000000000001
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501796875
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500625
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5040625000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5040625000000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023437500000001
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5023437500000001
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4996875
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5034375000000001
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49812500000000004
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5040625000000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5040625000000001
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50109375
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5018750000000001
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.504375
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021875
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50328125
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50328125
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011079545454545
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499375
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004963235294118
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5021590909090909
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5015104166666667
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5019301470588236
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5016335227272727
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004427083333334
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "zero_width_space",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5012132352941177
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500234375
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002213541666667
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002864583333333
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333333
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004036458333333
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002604166666668
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003645833333333
    },
    {
      "domain": "all",
      "model": "llama-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008072916666666
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005598958333334
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500703125
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007552083333333
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007291666666667
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005078125000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007812500000001
    },
    {
      "domain": "all",
      "model": "mpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50064453125
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007552083333333
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004427083333334
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005989583333333
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009635416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500859375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009114583333333
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500859375
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006510416666667
    },
    {
      "domain": "all",
      "model": "mpt-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007552083333333
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501171875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007421875
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.500234375
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009114583333333
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005729166666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002734375000001
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5010416666666667
    },
    {
      "domain": "all",
      "model": "gpt2",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006575520833334
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008333333333334
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5002083333333334
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333333
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000520833333334
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5009375
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004947916666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004427083333334
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005729166666667
    },
    {
      "domain": "all",
      "model": "mistral",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005078125000001
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007552083333333
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003776041666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4990885416666667
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004427083333334
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499765625
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49954427083333336
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005989583333333
    },
    {
      "domain": "all",
      "model": "mistral-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5000716145833333
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.50125
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011458333333333
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011458333333333
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011979166666667
    },
    {
      "domain": "all",
      "model": "gpt3",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5011979166666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333333
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005208333333333
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5001041666666667
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "cohere",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49984375000000003
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501796875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501796875
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008203125
    },
    {
      "domain": "all",
      "model": "chatgpt",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5008203125
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501015625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.501015625
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003645833333333
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5003645833333333
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006901041666667
    },
    {
      "domain": "all",
      "model": "gpt4",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006901041666667
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499765625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.499765625
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998958333333334
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.4998958333333334
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49983072916666665
    },
    {
      "domain": "all",
      "model": "cohere-chat",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.49983072916666665
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004403409090908
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005989583333333
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "greedy",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004963235294118
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004214015151516
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5007378472222223
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "sampling",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005330882352942
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "no",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5004308712121212
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "yes",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5006684027777778
    },
    {
      "domain": "all",
      "model": "all",
      "decoding": "all",
      "repetition_penalty": "all",
      "attack": "all",
      "accuracy": {
        "0.05": null,
        "0.01": null
      },
      "auroc": 0.5005147058823529
    }
  ],
  "thresholds": {
    "0.05": {
      "abstracts": 0.9999999999895226,
      "books": 0.999999999795109,
      "news": 0.9999999999755529,
      "poetry": 0.9999999999895226,
      "recipes": 0.999999999795109,
      "reddit": 0.999999999795109,
      "reviews": 0.9999999999068678,
      "wiki": 0.9999999999254943
    },
    "0.01": {
      "abstracts": 0.9999999999895226,
      "books": 0.999999999795109,
      "news": 0.9999999999755529,
      "poetry": 0.9999999999895226,
      "recipes": 0.999999999795109,
      "reddit": 0.999999999795109,
      "reviews": 0.9999999999068678,
      "wiki": 0.9999999999254943
    }
  },
  "fpr": {
    "0.05": {
      "abstracts": 0.98,
      "books": 0.97,
      "news": 0.995,
      "poetry": 0.98,
      "recipes": 0.97,
      "reddit": 0.97,
      "reviews": 0.975,
      "wiki": 0.955
    },
    "0.01": {
      "abstracts": 0.98,
      "books": 0.97,
      "news": 0.995,
      "poetry": 0.98,
      "recipes": 0.97,
      "reddit": 0.97,
      "reviews": 0.975,
      "wiki": 0.955
    }
  }
}